% SciTeX Scholar Bibliography
% Generated: 2025-07-19 12:10:41
% Papers: 20

@misc{tshimanga2022overvi,
  title = {An overview of open source Deep Learning-based libraries for
  Neuroscience},
  author = {Louis Fabrice Tshimanga and Manfredo Atzori and Federico Del Pup and Maurizio Corbetta},
  year = {2022},
  eprint = {2301.05057v1},
  archivePrefix = {arXiv},
  abstract = {In recent years, deep learning revolutionized machine learning and its
applications, producing results comparable to human experts in several domains,
including neuroscience. Each year, hundreds of scientific publications present
applications of deep neural networks for biomedical data analysis. Due to the
fast growth of the domain, it could be a complicated and extremely
time-consuming task for worldwide researchers to have a clear perspective of
the most recent and advanced software libraries. This work contributes to
clarify the current situation in the domain, outlining the most useful
libraries that implement and facilitate deep learning application to
neuroscience, allowing scientists to identify the most suitable options for
their research or clinical projects. This paper summarizes the main
developments in Deep Learning and their relevance to Neuroscience; it then
reviews neuroinformatic toolboxes and libraries, collected from the literature
and from specific hubs of software projects oriented to neuroscience research.
The selected tools are presented in tables detailing key features grouped by
domain of application (e.g. data type, neuroscience area, task), model
engineering (e.g. programming language, model customization) and technological
aspect (e.g. interface, code source). The results show that, among a high
number of available software tools, several libraries are standing out in terms
of functionalities for neuroscience applications. The aggregation and
discussion of this information can help the neuroscience community to devolop
their research projects more efficiently and quickly, both by means of readily
available tools, and by knowing which modules may be improved, connected or
added.},
  keywords = {q-bio.QM, cs.LG, cs.NE},
  note = {Generated by SciTeX Scholar}
}

@misc{jensen2023introd,
  title = {An introduction to reinforcement learning for neuroscience},
  author = {Kristopher T. Jensen},
  year = {2023},
  eprint = {2311.07315v3},
  archivePrefix = {arXiv},
  abstract = {Reinforcement learning (RL) has a rich history in neuroscience, from early
work on dopamine as a reward prediction error signal (Schultz et al., 1997) to
recent work proposing that the brain could implement a form of 'distributional
reinforcement learning' popularized in machine learning (Dabney et al., 2020).
There has been a close link between theoretical advances in reinforcement
learning and neuroscience experiments throughout this literature, and the
theories describing the experimental data have therefore become increasingly
complex. Here, we provide an introduction and mathematical background to many
of the methods that have been used in systems neroscience. We start with an
overview of the RL problem and classical temporal difference algorithms,
followed by a discussion of 'model-free', 'model-based', and intermediate RL
algorithms. We then introduce deep reinforcement learning and discuss how this
framework has led to new insights in neuroscience. This includes a particular
focus on meta-reinforcement learning (Wang et al., 2018) and distributional RL
(Dabney et al., 2020). Finally, we discuss potential shortcomings of the RL
formalism for neuroscience and highlight open questions in the field. Code that
implements the methods discussed and generates the figures is also provided.},
  keywords = {q-bio.NC, cs.LG},
  note = {Generated by SciTeX Scholar}
}

@misc{schmidgall2022learni,
  title = {Learning to learn online with neuromodulated synaptic plasticity in
  spiking neural networks},
  author = {Samuel Schmidgall and Joe Hays},
  year = {2022},
  eprint = {2206.12520v2},
  archivePrefix = {arXiv},
  abstract = {We propose that in order to harness our understanding of neuroscience toward
machine learning, we must first have powerful tools for training brain-like
models of learning. Although substantial progress has been made toward
understanding the dynamics of learning in the brain, neuroscience-derived
models of learning have yet to demonstrate the same performance capabilities as
methods in deep learning such as gradient descent. Inspired by the successes of
machine learning using gradient descent, we demonstrate that models of
neuromodulated synaptic plasticity from neuroscience can be trained in Spiking
Neural Networks (SNNs) with a framework of learning to learn through gradient
descent to address challenging online learning problems. This framework opens a
new path toward developing neuroscience inspired online learning algorithms.},
  keywords = {cs.NE, cs.LG},
  note = {Generated by SciTeX Scholar}
}

@misc{storrs2019deep,
  title = {Deep Learning for Cognitive Neuroscience},
  author = {Katherine R. Storrs and Nikolaus Kriegeskorte},
  year = {2019},
  eprint = {1903.01458v1},
  archivePrefix = {arXiv},
  abstract = {Neural network models can now recognise images, understand text, translate
languages, and play many human games at human or superhuman levels. These
systems are highly abstracted, but are inspired by biological brains and use
only biologically plausible computations. In the coming years, neural networks
are likely to become less reliant on learning from massive labelled datasets,
and more robust and generalisable in their task performance. From their
successes and failures, we can learn about the computational requirements of
the different tasks at which brains excel. Deep learning also provides the
tools for testing cognitive theories. In order to test a theory, we need to
realise the proposed information-processing system at scale, so as to be able
to assess its feasibility and emergent behaviours. Deep learning allows us to
scale up from principles and circuit models to end-to-end trainable models
capable of performing complex tasks. There are many levels at which cognitive
neuroscientists can use deep learning in their work, from inspiring theories to
serving as full computational models. Ongoing advances in deep learning bring
us closer to understanding how cognition and perception may be implemented in
the brain -- the grand challenge at the core of cognitive neuroscience.},
  keywords = {q-bio.NC, cs.LG},
  note = {Generated by SciTeX Scholar}
}

@misc{saxe2020deep,
  title = {If deep learning is the answer, then what is the question?},
  author = {Andrew Saxe and Stephanie Nelli and Christopher Summerfield},
  year = {2020},
  eprint = {2004.07580v2},
  archivePrefix = {arXiv},
  abstract = {Neuroscience research is undergoing a minor revolution. Recent advances in
machine learning and artificial intelligence (AI) research have opened up new
ways of thinking about neural computation. Many researchers are excited by the
possibility that deep neural networks may offer theories of perception,
cognition and action for biological brains. This perspective has the potential
to radically reshape our approach to understanding neural systems, because the
computations performed by deep networks are learned from experience, not
endowed by the researcher. If so, how can neuroscientists use deep networks to
model and understand biological brains? What is the outlook for neuroscientists
who seek to characterise computations or neural codes, or who wish to
understand perception, attention, memory, and executive functions? In this
Perspective, our goal is to offer a roadmap for systems neuroscience research
in the age of deep learning. We discuss the conceptual and methodological
challenges of comparing behaviour, learning dynamics, and neural representation
in artificial and biological systems. We highlight new research questions that
have emerged for neuroscience as a direct consequence of recent advances in
machine learning.},
  keywords = {q-bio.NC},
  note = {Generated by SciTeX Scholar}
}

@misc{mathis2019deep,
  title = {Deep learning tools for the measurement of animal behavior in
  neuroscience},
  author = {Mackenzie W. Mathis and Alexander Mathis},
  year = {2019},
  eprint = {1909.13868v2},
  archivePrefix = {arXiv},
  abstract = {Recent advances in computer vision have made accurate, fast and robust
measurement of animal behavior a reality. In the past years powerful tools
specifically designed to aid the measurement of behavior have come to fruition.
Here we discuss how capturing the postures of animals - pose estimation - has
been rapidly advancing with new deep learning methods. While challenges still
remain, we envision that the fast-paced development of new deep learning tools
will rapidly change the landscape of realizable real-world neuroscience.},
  keywords = {cs.CV, q-bio.NC, q-bio.QM},
  note = {Generated by SciTeX Scholar}
}

@misc{vicente2019many,
  title = {The many faces of deep learning},
  author = {Raul Vicente},
  year = {2019},
  eprint = {1908.10206v1},
  archivePrefix = {arXiv},
  abstract = {Deep learning has sparked a network of mutual interactions between different
disciplines and AI. Naturally, each discipline focuses and interprets the
workings of deep learning in different ways. This diversity of perspectives on
deep learning, from neuroscience to statistical physics, is a rich source of
inspiration that fuels novel developments in the theory and applications of
machine learning. In this perspective, we collect and synthesize different
intuitions scattered across several communities as for how deep learning works.
In particular, we will briefly discuss the different perspectives that
disciplines across mathematics, physics, computation, and neuroscience take on
how deep learning does its tricks. Our discussion on each perspective is
necessarily shallow due to the multiple views that had to be covered. The
deepness in this case should come from putting all these faces of deep learning
together in the reader's mind, so that one can look at the same problem from
different angles.},
  keywords = {cs.LG, physics.data-an, q-bio.NC, stat.ML},
  note = {Generated by SciTeX Scholar}
}

@misc{dodigcrnkovic2020morpho,
  title = {Morphological Computation and Learning to Learn In Natural Intelligent
  Systems And AI},
  author = {Gordana Dodig-Crnkovic},
  year = {2020},
  eprint = {2004.02304v1},
  archivePrefix = {arXiv},
  abstract = {At present, artificial intelligence in the form of machine learning is making
impressive progress, especially the field of deep learning (DL) [1]. Deep
learning algorithms have been inspired from the beginning by nature,
specifically by the human brain, in spite of our incomplete knowledge about its
brain function. Learning from nature is a two-way process as discussed in
[2][3][4], computing is learning from neuroscience, while neuroscience is
quickly adopting information processing models. The question is, what can the
inspiration from computational nature at this stage of the development
contribute to deep learning and how much models and experiments in machine
learning can motivate, justify and lead research in neuroscience and cognitive
science and to practical applications of artificial intelligence.},
  keywords = {cs.AI},
  note = {Generated by SciTeX Scholar}
}

@misc{kabir2024deep,
  title = {Deep reinforcement learning with time-scale invariant memory},
  author = {Md Rysul Kabir and James Mochizuki-Freeman and Zoran Tiganj},
  year = {2024},
  eprint = {2412.15292v1},
  archivePrefix = {arXiv},
  abstract = {The ability to estimate temporal relationships is critical for both animals
and artificial agents. Cognitive science and neuroscience provide remarkable
insights into behavioral and neural aspects of temporal credit assignment. In
particular, scale invariance of learning dynamics, observed in behavior and
supported by neural data, is one of the key principles that governs animal
perception: proportional rescaling of temporal relationships does not alter the
overall learning efficiency. Here we integrate a computational neuroscience
model of scale invariant memory into deep reinforcement learning (RL) agents.
We first provide a theoretical analysis and then demonstrate through
experiments that such agents can learn robustly across a wide range of temporal
scales, unlike agents built with commonly used recurrent memory architectures
such as LSTM. This result illustrates that incorporating computational
principles from neuroscience and cognitive science into deep neural networks
can enhance adaptability to complex temporal dynamics, mirroring some of the
core properties of human learning.},
  keywords = {cs.AI, cs.LG},
  note = {Generated by SciTeX Scholar}
}

@misc{wang2020meta,
  title = {Meta-learning in natural and artificial intelligence},
  author = {Jane X. Wang},
  year = {2020},
  eprint = {2011.13464v1},
  archivePrefix = {arXiv},
  abstract = {Meta-learning, or learning to learn, has gained renewed interest in recent
years within the artificial intelligence community. However, meta-learning is
incredibly prevalent within nature, has deep roots in cognitive science and
psychology, and is currently studied in various forms within neuroscience. The
aim of this review is to recast previous lines of research in the study of
biological intelligence within the lens of meta-learning, placing these works
into a common framework. More recent points of interaction between AI and
neuroscience will be discussed, as well as interesting new directions that
arise under this perspective.},
  keywords = {cs.AI},
  note = {Generated by SciTeX Scholar}
}

@misc{livezey2020deep,
  title = {Deep learning approaches for neural decoding: from CNNs to LSTMs and
  spikes to fMRI},
  author = {Jesse A. Livezey and Joshua I. Glaser},
  year = {2020},
  eprint = {2005.09687v1},
  archivePrefix = {arXiv},
  abstract = {Decoding behavior, perception, or cognitive state directly from neural
signals has applications in brain-computer interface research as well as
implications for systems neuroscience. In the last decade, deep learning has
become the state-of-the-art method in many machine learning tasks ranging from
speech recognition to image segmentation. The success of deep networks in other
domains has led to a new wave of applications in neuroscience. In this article,
we review deep learning approaches to neural decoding. We describe the
architectures used for extracting useful features from neural recording
modalities ranging from spikes to EEG. Furthermore, we explore how deep
learning has been leveraged to predict common outputs including movement,
speech, and vision, with a focus on how pretrained deep networks can be
incorporated as priors for complex decoding targets like acoustic speech or
images. Deep learning has been shown to be a useful tool for improving the
accuracy and flexibility of neural decoding across a wide range of tasks, and
we point out areas for future scientific development.},
  keywords = {q-bio.NC, cs.LG},
  note = {Generated by SciTeX Scholar}
}

@misc{bessadok2021graph,
  title = {Graph Neural Networks in Network Neuroscience},
  author = {Alaa Bessadok and Mohamed Ali Mahjoub and Islem Rekik},
  year = {2021},
  eprint = {2106.03535v2},
  archivePrefix = {arXiv},
  abstract = {Noninvasive medical neuroimaging has yielded many discoveries about the brain
connectivity. Several substantial techniques mapping morphological, structural
and functional brain connectivities were developed to create a comprehensive
road map of neuronal activities in the human brain -namely brain graph. Relying
on its non-Euclidean data type, graph neural network (GNN) provides a clever
way of learning the deep graph structure and it is rapidly becoming the
state-of-the-art leading to enhanced performance in various network
neuroscience tasks. Here we review current GNN-based methods, highlighting the
ways that they have been used in several applications related to brain graphs
such as missing brain graph synthesis and disease classification. We conclude
by charting a path toward a better application of GNN models in network
neuroscience field for neurological disorder diagnosis and population graph
integration. The list of papers cited in our work is available at
https://github.com/basiralab/GNNs-in-Network-Neuroscience.},
  keywords = {cs.LG, q-bio.NC},
  note = {Generated by SciTeX Scholar}
}

@misc{elgazzar2024univer,
  title = {Universal Differential Equations as a Common Modeling Language for
  Neuroscience},
  author = {Ahmed ElGazzar and Marcel van Gerven},
  year = {2024},
  eprint = {2403.14510v1},
  archivePrefix = {arXiv},
  abstract = {The unprecedented availability of large-scale datasets in neuroscience has
spurred the exploration of artificial deep neural networks (DNNs) both as
empirical tools and as models of natural neural systems. Their appeal lies in
their ability to approximate arbitrary functions directly from observations,
circumventing the need for cumbersome mechanistic modeling. However, without
appropriate constraints, DNNs risk producing implausible models, diminishing
their scientific value. Moreover, the interpretability of DNNs poses a
significant challenge, particularly with the adoption of more complex
expressive architectures. In this perspective, we argue for universal
differential equations (UDEs) as a unifying approach for model development and
validation in neuroscience. UDEs view differential equations as
parameterizable, differentiable mathematical objects that can be augmented and
trained with scalable deep learning techniques. This synergy facilitates the
integration of decades of extensive literature in calculus, numerical analysis,
and neural modeling with emerging advancements in AI into a potent framework.
We provide a primer on this burgeoning topic in scientific machine learning and
demonstrate how UDEs fill in a critical gap between mechanistic,
phenomenological, and data-driven models in neuroscience. We outline a flexible
recipe for modeling neural systems with UDEs and discuss how they can offer
principled solutions to inherent challenges across diverse neuroscience
applications such as understanding neural computation, controlling neural
systems, neural decoding, and normative modeling.},
  keywords = {cs.CE},
  note = {Generated by SciTeX Scholar}
}

@misc{tanaka2019deep,
  title = {From deep learning to mechanistic understanding in neuroscience: the
  structure of retinal prediction},
  author = {Hidenori Tanaka and Aran Nayebi and Niru Maheswaranathan and Lane McIntosh and Stephen A. Baccus and Surya Ganguli},
  year = {2019},
  eprint = {1912.06207v1},
  archivePrefix = {arXiv},
  abstract = {Recently, deep feedforward neural networks have achieved considerable success
in modeling biological sensory processing, in terms of reproducing the
input-output map of sensory neurons. However, such models raise profound
questions about the very nature of explanation in neuroscience. Are we simply
replacing one complex system (a biological circuit) with another (a deep
network), without understanding either? Moreover, beyond neural
representations, are the deep network's computational mechanisms for generating
neural responses the same as those in the brain? Without a systematic approach
to extracting and understanding computational mechanisms from deep neural
network models, it can be difficult both to assess the degree of utility of
deep learning approaches in neuroscience, and to extract experimentally
testable hypotheses from deep networks. We develop such a systematic approach
by combining dimensionality reduction and modern attribution methods for
determining the relative importance of interneurons for specific visual
computations. We apply this approach to deep network models of the retina,
revealing a conceptual understanding of how the retina acts as a predictive
feature extractor that signals deviations from expectations for diverse
spatiotemporal stimuli. For each stimulus, our extracted computational
mechanisms are consistent with prior scientific literature, and in one case
yields a new mechanistic hypothesis. Thus overall, this work not only yields
insights into the computational mechanisms underlying the striking predictive
capabilities of the retina, but also places the framework of deep networks as
neuroscientific models on firmer theoretical foundations, by providing a new
roadmap to go beyond comparing neural representations to extracting and
understand computational mechanisms.},
  keywords = {q-bio.NC, cs.LG, physics.bio-ph},
  note = {Generated by SciTeX Scholar}
}

@misc{wang2020genera,
  title = {Generalizable Machine Learning in Neuroscience using Graph Neural
  Networks},
  author = {Paul Y. Wang and Sandalika Sapra and Vivek Kurien George and Gabriel A. Silva},
  year = {2020},
  eprint = {2010.08569v1},
  archivePrefix = {arXiv},
  abstract = {Although a number of studies have explored deep learning in neuroscience, the
application of these algorithms to neural systems on a microscopic scale, i.e.
parameters relevant to lower scales of organization, remains relatively novel.
Motivated by advances in whole-brain imaging, we examined the performance of
deep learning models on microscopic neural dynamics and resulting emergent
behaviors using calcium imaging data from the nematode C. elegans. We show that
neural networks perform remarkably well on both neuron-level dynamics
prediction, and behavioral state classification. In addition, we compared the
performance of structure agnostic neural networks and graph neural networks to
investigate if graph structure can be exploited as a favorable inductive bias.
To perform this experiment, we designed a graph neural network which explicitly
infers relations between neurons from neural activity and leverages the
inferred graph structure during computations. In our experiments, we found that
graph neural networks generally outperformed structure agnostic models and
excel in generalization on unseen organisms, implying a potential path to
generalizable machine learning in neuroscience.},
  keywords = {cs.LG, q-bio.NC},
  note = {Generated by SciTeX Scholar}
}

@misc{szelogowski2024simula,
  title = {Simulation of Neural Responses to Classical Music Using Organoid
  Intelligence Methods},
  author = {Daniel Szelogowski},
  year = {2024},
  eprint = {2407.18413v1},
  archivePrefix = {arXiv},
  abstract = {Music is a complex auditory stimulus capable of eliciting significant changes
in brain activity, influencing cognitive processes such as memory, attention,
and emotional regulation. However, the underlying mechanisms of music-induced
cognitive processes remain largely unknown. Organoid intelligence and deep
learning models show promise for simulating and analyzing these neural
responses to classical music, an area significantly unexplored in computational
neuroscience. Hence, we present the PyOrganoid library, an innovative tool that
facilitates the simulation of organoid learning models, integrating
sophisticated machine learning techniques with biologically inspired organoid
simulations. Our study features the development of the Pianoid model, a "deep
organoid learning" model that utilizes a Bidirectional LSTM network to predict
EEG responses based on audio features from classical music recordings. This
model demonstrates the feasibility of using computational methods to replicate
complex neural processes, providing valuable insights into music perception and
cognition. Likewise, our findings emphasize the utility of synthetic models in
neuroscience research and highlight the PyOrganoid library's potential as a
versatile tool for advancing studies in neuroscience and artificial
intelligence.},
  keywords = {cs.NE, cs.AI, cs.LG, cs.SD, eess.AS, I.2; I.6; J.3; J.4; J.5},
  note = {Generated by SciTeX Scholar}
}

@misc{marino2020predic,
  title = {Predictive Coding, Variational Autoencoders, and Biological Connections},
  author = {Joseph Marino},
  year = {2020},
  eprint = {2011.07464v2},
  archivePrefix = {arXiv},
  abstract = {This paper reviews predictive coding, from theoretical neuroscience, and
variational autoencoders, from machine learning, identifying the common origin
and mathematical framework underlying both areas. As each area is prominent
within its respective field, more firmly connecting these areas could prove
useful in the dialogue between neuroscience and machine learning. After
reviewing each area, we discuss two possible correspondences implied by this
perspective: cortical pyramidal dendrites as analogous to (non-linear) deep
networks and lateral inhibition as analogous to normalizing flows. These
connections may provide new directions for further investigations in each
field.},
  keywords = {cs.NE},
  note = {Generated by SciTeX Scholar}
}

@misc{botvinick2020deep,
  title = {Deep Reinforcement Learning and its Neuroscientific Implications},
  author = {Matthew Botvinick and Jane X. Wang and Will Dabney and Kevin J. Miller and Zeb Kurth-Nelson},
  year = {2020},
  eprint = {2007.03750v1},
  archivePrefix = {arXiv},
  abstract = {The emergence of powerful artificial intelligence is defining new research
directions in neuroscience. To date, this research has focused largely on deep
neural networks trained using supervised learning, in tasks such as image
classification. However, there is another area of recent AI work which has so
far received less attention from neuroscientists, but which may have profound
neuroscientific implications: deep reinforcement learning. Deep RL offers a
comprehensive framework for studying the interplay among learning,
representation and decision-making, offering to the brain sciences a new set of
research tools and a wide range of novel hypotheses. In the present review, we
provide a high-level introduction to deep RL, discuss some of its initial
applications to neuroscience, and survey its wider implications for research on
brain and behavior, concluding with a list of opportunities for next-stage
research.},
  keywords = {cs.AI, cs.LG, q-bio.NC},
  note = {Generated by SciTeX Scholar}
}

@misc{date2023supern,
  title = {SuperNeuro: A Fast and Scalable Simulator for Neuromorphic Computing},
  author = {Prasanna Date and Chathika Gunaratne and Shruti Kulkarni and Robert Patton and Mark Coletti and Thomas Potok},
  year = {2023},
  eprint = {2305.02510v1},
  archivePrefix = {arXiv},
  abstract = {In many neuromorphic workflows, simulators play a vital role for important
tasks such as training spiking neural networks (SNNs), running neuroscience
simulations, and designing, implementing and testing neuromorphic algorithms.
Currently available simulators are catered to either neuroscience workflows
(such as NEST and Brian2) or deep learning workflows (such as BindsNET). While
the neuroscience-based simulators are slow and not very scalable, the deep
learning-based simulators do not support certain functionalities such as
synaptic delay that are typical of neuromorphic workloads. In this paper, we
address this gap in the literature and present SuperNeuro, which is a fast and
scalable simulator for neuromorphic computing, capable of both homogeneous and
heterogeneous simulations as well as GPU acceleration. We also present
preliminary results comparing SuperNeuro to widely used neuromorphic simulators
such as NEST, Brian2 and BindsNET in terms of computation times. We demonstrate
that SuperNeuro can be approximately 10--300 times faster than some of the
other simulators for small sparse networks. On large sparse and large dense
networks, SuperNeuro can be approximately 2.2 and 3.4 times faster than the
other simulators respectively.},
  keywords = {cs.NE, cs.ET, D.0},
  note = {Generated by SciTeX Scholar}
}

@misc{marblestone2016toward,
  title = {Towards an integration of deep learning and neuroscience},
  author = {Adam Marblestone and Greg Wayne and Konrad Kording},
  year = {2016},
  eprint = {1606.03813v1},
  archivePrefix = {arXiv},
  abstract = {Neuroscience has focused on the detailed implementation of computation,
studying neural codes, dynamics and circuits. In machine learning, however,
artificial neural networks tend to eschew precisely designed codes, dynamics or
circuits in favor of brute force optimization of a cost function, often using
simple and relatively uniform initial architectures. Two recent developments
have emerged within machine learning that create an opportunity to connect
these seemingly divergent perspectives. First, structured architectures are
used, including dedicated systems for attention, recursion and various forms of
short- and long-term memory storage. Second, cost functions and training
procedures have become more complex and are varied across layers and over time.
Here we think about the brain in terms of these ideas. We hypothesize that (1)
the brain optimizes cost functions, (2) these cost functions are diverse and
differ across brain locations and over development, and (3) optimization
operates within a pre-structured architecture matched to the computational
problems posed by behavior. Such a heterogeneously optimized system, enabled by
a series of interacting cost functions, serves to make learning data-efficient
and precisely targeted to the needs of the organism. We suggest directions by
which neuroscience could seek to refine and test these hypotheses.},
  keywords = {q-bio.NC},
  note = {Generated by SciTeX Scholar}
}