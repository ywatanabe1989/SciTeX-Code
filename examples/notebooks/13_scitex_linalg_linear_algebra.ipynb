{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SciTeX Linear Algebra Utilities\n",
    "\n",
    "This notebook demonstrates the linear algebra utilities provided by the `scitex.linalg` module, which offers efficient and NaN-aware implementations of common linear algebra operations for scientific computing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scitex as stx\n",
    "\n",
    "# Set up reproducible environment\n",
    "stx.repro.fix_seeds(42)\n",
    "\n",
    "# Configure visualization\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print(f\"SciTeX version: {stx.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Distance Computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample data points\n",
    "n_points = 100\n",
    "n_dims = 3\n",
    "\n",
    "# Create clusters in 3D space\n",
    "cluster1 = np.random.randn(n_points // 2, n_dims) + [2, 2, 2]\n",
    "cluster2 = np.random.randn(n_points // 2, n_dims) + [-2, -2, -2]\n",
    "points = np.vstack([cluster1, cluster2])\n",
    "\n",
    "print(f\"Data shape: {points.shape}\")\n",
    "print(f\"Data range: [{points.min():.2f}, {points.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Euclidean distance between two points\n",
    "point_a = points[0]\n",
    "point_b = points[50]\n",
    "\n",
    "# Using stx.linalg.euclidean_distance\n",
    "dist = stx.linalg.euclidean_distance(point_a, point_b)\n",
    "print(f\"Distance between point A and B: {dist:.4f}\")\n",
    "\n",
    "# Alternative using edist (shorthand)\n",
    "dist_edist = stx.linalg.edist(point_a, point_b)\n",
    "print(f\"Distance using edist: {dist_edist:.4f}\")\n",
    "\n",
    "# Visualize the points\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(cluster1[:, 0], cluster1[:, 1], cluster1[:, 2], c='blue', label='Cluster 1', alpha=0.6)\n",
    "ax.scatter(cluster2[:, 0], cluster2[:, 1], cluster2[:, 2], c='red', label='Cluster 2', alpha=0.6)\n",
    "ax.scatter(*point_a, c='cyan', s=200, marker='*', label='Point A')\n",
    "ax.scatter(*point_b, c='magenta', s=200, marker='*', label='Point B')\n",
    "\n",
    "# Draw line between points\n",
    "ax.plot([point_a[0], point_b[0]], \n",
    "        [point_a[1], point_b[1]], \n",
    "        [point_a[2], point_b[2]], 'k--', linewidth=2)\n",
    "\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "ax.legend()\n",
    "plt.title(f'Euclidean Distance: {dist:.4f}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute pairwise distances using cdist\n",
    "# Select subset for visualization\n",
    "subset_indices = np.random.choice(len(points), 20, replace=False)\n",
    "subset_points = points[subset_indices]\n",
    "\n",
    "# Compute distance matrix\n",
    "dist_matrix = stx.linalg.cdist(subset_points, subset_points)\n",
    "\n",
    "# Visualize distance matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "im = plt.imshow(dist_matrix, cmap='viridis', aspect='auto')\n",
    "plt.colorbar(im, label='Distance')\n",
    "plt.xlabel('Point Index')\n",
    "plt.ylabel('Point Index')\n",
    "plt.title('Pairwise Distance Matrix')\n",
    "\n",
    "# Add text annotations for small matrix\n",
    "if len(subset_points) <= 10:\n",
    "    for i in range(len(subset_points)):\n",
    "        for j in range(len(subset_points)):\n",
    "            plt.text(j, i, f'{dist_matrix[i, j]:.2f}', \n",
    "                    ha='center', va='center', color='white')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Distance matrix shape: {dist_matrix.shape}\")\n",
    "print(f\"Min distance (non-zero): {dist_matrix[dist_matrix > 0].min():.4f}\")\n",
    "print(f\"Max distance: {dist_matrix.max():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Geometric Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geometric median is robust to outliers\n",
    "# Create data with outliers\n",
    "normal_points = np.random.randn(50, 2)\n",
    "outliers = np.array([[10, 10], [-10, -10], [10, -10]])\n",
    "all_points = np.vstack([normal_points, outliers])\n",
    "\n",
    "# Compute mean and geometric median\n",
    "mean_point = np.mean(all_points, axis=0)\n",
    "geometric_median_point = stx.linalg.geometric_median(all_points)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(normal_points[:, 0], normal_points[:, 1], \n",
    "           alpha=0.6, label='Normal points', s=50)\n",
    "plt.scatter(outliers[:, 0], outliers[:, 1], \n",
    "           color='red', s=100, label='Outliers', marker='^')\n",
    "plt.scatter(*mean_point, color='orange', s=200, \n",
    "           marker='s', label='Mean', edgecolor='black')\n",
    "plt.scatter(*geometric_median_point, color='green', s=200, \n",
    "           marker='*', label='Geometric Median', edgecolor='black')\n",
    "\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.legend()\n",
    "plt.title('Geometric Median vs Mean (Robustness to Outliers)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axis('equal')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Mean position: {mean_point}\")\n",
    "print(f\"Geometric median: {geometric_median_point}\")\n",
    "print(f\"Distance between mean and geometric median: {np.linalg.norm(mean_point - geometric_median_point):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine similarity for measuring angular similarity\n",
    "# Create vectors with different magnitudes but similar directions\n",
    "vec1 = np.array([1, 2, 3])\n",
    "vec2 = np.array([2, 4, 6])  # Same direction, different magnitude\n",
    "vec3 = np.array([-1, -2, -3])  # Opposite direction\n",
    "vec4 = np.array([3, -1, 2])  # Different direction\n",
    "\n",
    "# Compute cosine similarities\n",
    "cos_sim_12 = stx.linalg.cosine(vec1, vec2)\n",
    "cos_sim_13 = stx.linalg.cosine(vec1, vec3)\n",
    "cos_sim_14 = stx.linalg.cosine(vec1, vec4)\n",
    "\n",
    "print(\"Cosine Similarities:\")\n",
    "print(f\"vec1 vs vec2 (same direction): {cos_sim_12:.4f}\")\n",
    "print(f\"vec1 vs vec3 (opposite direction): {cos_sim_13:.4f}\")\n",
    "print(f\"vec1 vs vec4 (different direction): {cos_sim_14:.4f}\")\n",
    "\n",
    "# Visualize vectors in 3D\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Origin\n",
    "origin = np.zeros(3)\n",
    "\n",
    "# Plot vectors\n",
    "vectors = [vec1, vec2, vec3, vec4]\n",
    "colors = ['blue', 'green', 'red', 'orange']\n",
    "labels = ['vec1', 'vec2 (2Ã—vec1)', 'vec3 (-vec1)', 'vec4']\n",
    "\n",
    "for vec, color, label in zip(vectors, colors, labels):\n",
    "    ax.quiver(0, 0, 0, vec[0], vec[1], vec[2], \n",
    "             color=color, arrow_length_ratio=0.1, linewidth=3, label=label)\n",
    "\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "ax.legend()\n",
    "ax.set_title('Vector Directions and Cosine Similarity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. NaN-Aware Norm Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data with NaN values\n",
    "data_with_nan = np.array([\n",
    "    [1.0, 2.0, 3.0],\n",
    "    [4.0, np.nan, 6.0],\n",
    "    [7.0, 8.0, 9.0],\n",
    "    [np.nan, np.nan, 12.0]\n",
    "])\n",
    "\n",
    "print(\"Data with NaN values:\")\n",
    "print(data_with_nan)\n",
    "print()\n",
    "\n",
    "# Compare standard norm vs NaN-aware norm\n",
    "for i, row in enumerate(data_with_nan):\n",
    "    # Standard norm (will return NaN if any element is NaN)\n",
    "    standard_norm = np.linalg.norm(row)\n",
    "    \n",
    "    # NaN-aware norm (ignores NaN values)\n",
    "    nan_aware_norm = stx.linalg.nannorm(row)\n",
    "    \n",
    "    print(f\"Row {i}: {row}\")\n",
    "    print(f\"  Standard norm: {standard_norm:.4f}\")\n",
    "    print(f\"  NaN-aware norm: {nan_aware_norm:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Vector Rebasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rebase vector to new minimum value\n",
    "# Useful for shifting data ranges\n",
    "original_vec = np.array([5, 10, 15, 20, 25])\n",
    "new_base = 100\n",
    "\n",
    "rebased_vec = stx.linalg.rebase_a_vec(original_vec, new_base)\n",
    "\n",
    "print(f\"Original vector: {original_vec}\")\n",
    "print(f\"Original min: {original_vec.min()}\")\n",
    "print(f\"Rebased vector: {rebased_vec}\")\n",
    "print(f\"New min: {rebased_vec.min()}\")\n",
    "print(f\"Shift applied: {rebased_vec[0] - original_vec[0]}\")\n",
    "\n",
    "# Visualize rebasing\n",
    "plt.figure(figsize=(10, 6))\n",
    "x = np.arange(len(original_vec))\n",
    "plt.plot(x, original_vec, 'bo-', label='Original', markersize=10, linewidth=2)\n",
    "plt.plot(x, rebased_vec, 'ro-', label=f'Rebased (base={new_base})', markersize=10, linewidth=2)\n",
    "plt.axhline(y=original_vec.min(), color='blue', linestyle='--', alpha=0.5, label=f'Original min: {original_vec.min()}')\n",
    "plt.axhline(y=new_base, color='red', linestyle='--', alpha=0.5, label=f'New base: {new_base}')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Vector Rebasing')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Triangle Coordinate Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert three line lengths to triangle coordinates\n",
    "# Useful for geometric computations\n",
    "# Example: Triangle with sides 3, 4, 5 (right triangle)\n",
    "side_lengths = [3, 4, 5]\n",
    "\n",
    "coords = stx.linalg.three_line_lengths_to_coords(side_lengths)\n",
    "\n",
    "print(f\"Side lengths: {side_lengths}\")\n",
    "print(f\"\\nComputed coordinates:\")\n",
    "for i, coord in enumerate(coords):\n",
    "    print(f\"  Point {i}: {coord}\")\n",
    "\n",
    "# Verify the distances\n",
    "print(f\"\\nVerification:\")\n",
    "dist_01 = np.linalg.norm(coords[0] - coords[1])\n",
    "dist_12 = np.linalg.norm(coords[1] - coords[2])\n",
    "dist_02 = np.linalg.norm(coords[0] - coords[2])\n",
    "print(f\"  Distance 0-1: {dist_01:.4f} (expected: {side_lengths[0]})\")\n",
    "print(f\"  Distance 1-2: {dist_12:.4f} (expected: {side_lengths[1]})\")\n",
    "print(f\"  Distance 0-2: {dist_02:.4f} (expected: {side_lengths[2]})\")\n",
    "\n",
    "# Visualize triangle\n",
    "plt.figure(figsize=(8, 8))\n",
    "triangle = plt.Polygon(coords, fill=False, edgecolor='blue', linewidth=2)\n",
    "plt.gca().add_patch(triangle)\n",
    "\n",
    "# Plot points\n",
    "for i, coord in enumerate(coords):\n",
    "    plt.plot(coord[0], coord[1], 'ro', markersize=10)\n",
    "    plt.text(coord[0] + 0.1, coord[1] + 0.1, f'P{i}', fontsize=12)\n",
    "\n",
    "# Add side length labels\n",
    "mid_01 = (coords[0] + coords[1]) / 2\n",
    "mid_12 = (coords[1] + coords[2]) / 2\n",
    "mid_02 = (coords[0] + coords[2]) / 2\n",
    "\n",
    "plt.text(mid_01[0], mid_01[1] - 0.2, f'{side_lengths[0]}', fontsize=10, ha='center')\n",
    "plt.text(mid_12[0] + 0.2, mid_12[1], f'{side_lengths[1]}', fontsize=10)\n",
    "plt.text(mid_02[0], mid_02[1] + 0.2, f'{side_lengths[2]}', fontsize=10, ha='center')\n",
    "\n",
    "plt.axis('equal')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Triangle from Side Lengths (3-4-5 Right Triangle)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Advanced Distance Computations with Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing data in distance computations\n",
    "# Create dataset with missing values\n",
    "n_samples = 50\n",
    "n_features = 5\n",
    "\n",
    "# Generate complete data\n",
    "complete_data = np.random.randn(n_samples, n_features)\n",
    "\n",
    "# Introduce missing values randomly\n",
    "missing_mask = np.random.random((n_samples, n_features)) < 0.2\n",
    "data_with_missing = complete_data.copy()\n",
    "data_with_missing[missing_mask] = np.nan\n",
    "\n",
    "print(f\"Data shape: {data_with_missing.shape}\")\n",
    "print(f\"Missing values: {np.isnan(data_with_missing).sum()} ({np.isnan(data_with_missing).mean()*100:.1f}%)\")\n",
    "\n",
    "# Select two samples with missing values\n",
    "sample1 = data_with_missing[0]\n",
    "sample2 = data_with_missing[1]\n",
    "\n",
    "print(f\"\\nSample 1: {sample1}\")\n",
    "print(f\"Sample 2: {sample2}\")\n",
    "\n",
    "# Compute distance ignoring NaN values\n",
    "# Only use dimensions where both samples have values\n",
    "valid_dims = ~(np.isnan(sample1) | np.isnan(sample2))\n",
    "if valid_dims.any():\n",
    "    distance = stx.linalg.euclidean_distance(sample1[valid_dims], sample2[valid_dims])\n",
    "    print(f\"\\nDistance using {valid_dims.sum()} valid dimensions: {distance:.4f}\")\n",
    "else:\n",
    "    print(\"\\nNo valid dimensions for comparison\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare performance of different distance computation methods\n",
    "import time\n",
    "\n",
    "# Generate larger dataset\n",
    "n_points = 1000\n",
    "n_dims = 100\n",
    "data = np.random.randn(n_points, n_dims)\n",
    "\n",
    "# Method 1: SciTeX cdist\n",
    "start_time = time.time()\n",
    "dist_matrix_stx = stx.linalg.cdist(data[:100], data[:100])\n",
    "stx_time = time.time() - start_time\n",
    "\n",
    "# Method 2: NumPy manual computation\n",
    "start_time = time.time()\n",
    "dist_matrix_np = np.zeros((100, 100))\n",
    "for i in range(100):\n",
    "    for j in range(100):\n",
    "        dist_matrix_np[i, j] = np.linalg.norm(data[i] - data[j])\n",
    "np_time = time.time() - start_time\n",
    "\n",
    "print(f\"SciTeX cdist time: {stx_time:.4f} seconds\")\n",
    "print(f\"NumPy manual time: {np_time:.4f} seconds\")\n",
    "print(f\"Speedup: {np_time/stx_time:.2f}x\")\n",
    "print(f\"\\nResults match: {np.allclose(dist_matrix_stx, dist_matrix_np)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Integration Example: Clustering with Custom Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use linear algebra utilities for clustering analysis\n",
    "# Generate synthetic dataset with 3 clusters\n",
    "np.random.seed(42)\n",
    "n_points_per_cluster = 50\n",
    "\n",
    "# Create clusters with different characteristics\n",
    "cluster1 = np.random.randn(n_points_per_cluster, 2) * 0.5 + [0, 0]\n",
    "cluster2 = np.random.randn(n_points_per_cluster, 2) * 0.8 + [5, 5]\n",
    "cluster3 = np.random.randn(n_points_per_cluster, 2) * 0.6 + [5, -5]\n",
    "\n",
    "all_data = np.vstack([cluster1, cluster2, cluster3])\n",
    "labels = np.array([0]*n_points_per_cluster + [1]*n_points_per_cluster + [2]*n_points_per_cluster)\n",
    "\n",
    "# Compute cluster centers using geometric median (robust to outliers)\n",
    "centers_median = []\n",
    "centers_mean = []\n",
    "\n",
    "for label in range(3):\n",
    "    cluster_points = all_data[labels == label]\n",
    "    centers_median.append(stx.linalg.geometric_median(cluster_points))\n",
    "    centers_mean.append(np.mean(cluster_points, axis=0))\n",
    "\n",
    "centers_median = np.array(centers_median)\n",
    "centers_mean = np.array(centers_mean)\n",
    "\n",
    "# Add some outliers\n",
    "outlier_indices = np.random.choice(len(all_data), 5, replace=False)\n",
    "all_data[outlier_indices] += np.random.randn(5, 2) * 5\n",
    "\n",
    "# Visualize clusters and centers\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot points\n",
    "colors = ['blue', 'red', 'green']\n",
    "for i in range(3):\n",
    "    mask = labels == i\n",
    "    plt.scatter(all_data[mask, 0], all_data[mask, 1], \n",
    "               c=colors[i], alpha=0.6, label=f'Cluster {i}', s=50)\n",
    "\n",
    "# Mark outliers\n",
    "plt.scatter(all_data[outlier_indices, 0], all_data[outlier_indices, 1],\n",
    "           c='black', marker='x', s=200, linewidths=3, label='Outliers')\n",
    "\n",
    "# Plot centers\n",
    "plt.scatter(centers_mean[:, 0], centers_mean[:, 1], \n",
    "           c='orange', marker='s', s=200, edgecolor='black', linewidth=2, label='Mean Centers')\n",
    "plt.scatter(centers_median[:, 0], centers_median[:, 1], \n",
    "           c='yellow', marker='*', s=300, edgecolor='black', linewidth=2, label='Geometric Median Centers')\n",
    "\n",
    "# Compute and show inter-cluster distances\n",
    "inter_cluster_dist = stx.linalg.cdist(centers_median, centers_median)\n",
    "\n",
    "# Draw lines between cluster centers\n",
    "for i in range(3):\n",
    "    for j in range(i+1, 3):\n",
    "        plt.plot([centers_median[i, 0], centers_median[j, 0]],\n",
    "                [centers_median[i, 1], centers_median[j, 1]],\n",
    "                'k--', alpha=0.3, linewidth=1)\n",
    "        mid_x = (centers_median[i, 0] + centers_median[j, 0]) / 2\n",
    "        mid_y = (centers_median[i, 1] + centers_median[j, 1]) / 2\n",
    "        plt.text(mid_x, mid_y, f'{inter_cluster_dist[i, j]:.2f}', \n",
    "                fontsize=10, ha='center', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Clustering with Robust Center Estimation')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axis('equal')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print statistics\n",
    "print(\"Inter-cluster distances (using geometric median centers):\")\n",
    "print(inter_cluster_dist)\n",
    "print(f\"\\nMean inter-cluster distance: {inter_cluster_dist[inter_cluster_dist > 0].mean():.4f}\")\n",
    "\n",
    "# Compare robustness\n",
    "print(\"\\nCenter differences (Mean vs Geometric Median):\")\n",
    "for i in range(3):\n",
    "    diff = np.linalg.norm(centers_mean[i] - centers_median[i])\n",
    "    print(f\"  Cluster {i}: {diff:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The `scitex.linalg` module provides essential linear algebra utilities for scientific computing:\n",
    "\n",
    "1. **Distance Computations**: Efficient Euclidean distance and pairwise distance matrix calculations\n",
    "2. **Geometric Median**: Robust center estimation that is less sensitive to outliers than the mean\n",
    "3. **Cosine Similarity**: Measure angular similarity between vectors regardless of magnitude\n",
    "4. **NaN-Aware Operations**: Handle missing data gracefully in norm computations\n",
    "5. **Vector Utilities**: Rebase vectors and convert geometric descriptions to coordinates\n",
    "\n",
    "These utilities are particularly useful for:\n",
    "- Clustering and classification tasks\n",
    "- Robust statistical analysis\n",
    "- Geometric computations in scientific applications\n",
    "- Handling real-world data with missing values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}