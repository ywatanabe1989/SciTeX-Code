{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SciTeX Neural Network Components\n",
    "\n",
    "This notebook demonstrates the neural network components provided by the `scitex.nn` module, which offers specialized layers and models for scientific computing, particularly for signal processing and neuroscience applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "import scitex as stx\n",
    "\n",
    "# Set up reproducible environment\n",
    "stx.repro.fix_seeds(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Configure visualization\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"SciTeX version: {stx.__version__}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Signal Filtering Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic signal with multiple frequency components\n",
    "fs = 1000  # Sampling frequency\n",
    "t = np.linspace(0, 2, 2 * fs)\n",
    "# Signal with 10Hz, 50Hz, and 100Hz components + noise\n",
    "signal_np = (np.sin(2 * np.pi * 10 * t) + \n",
    "             0.5 * np.sin(2 * np.pi * 50 * t) + \n",
    "             0.3 * np.sin(2 * np.pi * 100 * t) +\n",
    "             0.2 * np.random.randn(len(t)))\n",
    "\n",
    "# Convert to torch tensor\n",
    "signal_torch = torch.tensor(signal_np, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "print(f\"Signal shape: {signal_torch.shape} (batch, channels, time)\")\n",
    "\n",
    "# Visualize original signal\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Time domain\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(t[:500], signal_np[:500])\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('Original Signal (First 0.5s)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Frequency domain\n",
    "plt.subplot(2, 1, 2)\n",
    "freqs, psd = signal.welch(signal_np, fs=fs, nperseg=256)\n",
    "plt.semilogy(freqs, psd)\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('PSD')\n",
    "plt.title('Power Spectral Density')\n",
    "plt.xlim([0, 200])\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply different filters\n",
    "# Low-pass filter (keep only low frequencies)\n",
    "low_pass = stx.nn.LowPassFilter(cutoff_freq=30, fs=fs, order=4)\n",
    "signal_low = low_pass(signal_torch)\n",
    "\n",
    "# Band-pass filter (keep specific frequency band)\n",
    "band_pass = stx.nn.BandPassFilter(low_freq=40, high_freq=60, fs=fs, order=4)\n",
    "signal_band = band_pass(signal_torch)\n",
    "\n",
    "# High-pass filter (keep only high frequencies)\n",
    "high_pass = stx.nn.HighPassFilter(cutoff_freq=80, fs=fs, order=4)\n",
    "signal_high = high_pass(signal_torch)\n",
    "\n",
    "# Visualize filtered signals\n",
    "fig, axes = plt.subplots(4, 2, figsize=(14, 12))\n",
    "\n",
    "signals = [\n",
    "    (signal_torch, \"Original\"),\n",
    "    (signal_low, \"Low-pass (<30Hz)\"),\n",
    "    (signal_band, \"Band-pass (40-60Hz)\"),\n",
    "    (signal_high, \"High-pass (>80Hz)\")\n",
    "]\n",
    "\n",
    "for i, (sig, title) in enumerate(signals):\n",
    "    sig_np = sig.squeeze().numpy()\n",
    "    \n",
    "    # Time domain\n",
    "    axes[i, 0].plot(t[:500], sig_np[:500])\n",
    "    axes[i, 0].set_xlabel('Time (s)')\n",
    "    axes[i, 0].set_ylabel('Amplitude')\n",
    "    axes[i, 0].set_title(f'{title} - Time Domain')\n",
    "    axes[i, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Frequency domain\n",
    "    freqs, psd = signal.welch(sig_np, fs=fs, nperseg=256)\n",
    "    axes[i, 1].semilogy(freqs, psd)\n",
    "    axes[i, 1].set_xlabel('Frequency (Hz)')\n",
    "    axes[i, 1].set_ylabel('PSD')\n",
    "    axes[i, 1].set_title(f'{title} - Frequency Domain')\n",
    "    axes[i, 1].set_xlim([0, 200])\n",
    "    axes[i, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Spectrogram and Time-Frequency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a chirp signal (frequency increases over time)\n",
    "t_chirp = np.linspace(0, 2, 2 * fs)\n",
    "f0, f1 = 10, 100  # Start and end frequencies\n",
    "chirp_signal = signal.chirp(t_chirp, f0, t_chirp[-1], f1, method='linear')\n",
    "chirp_torch = torch.tensor(chirp_signal, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "# Compute spectrogram using SciTeX\n",
    "spectrogram_layer = stx.nn.Spectrogram(\n",
    "    n_fft=256,\n",
    "    hop_length=64,\n",
    "    win_length=256,\n",
    "    normalized=True\n",
    ")\n",
    "\n",
    "spec = spectrogram_layer(chirp_torch)\n",
    "spec_db = 20 * torch.log10(spec.abs() + 1e-10)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Original signal\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(t_chirp, chirp_signal)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('Chirp Signal (10-100 Hz)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Spectrogram\n",
    "plt.subplot(2, 1, 2)\n",
    "spec_np = spec_db.squeeze().numpy()\n",
    "plt.imshow(spec_np, aspect='auto', origin='lower', \n",
    "           extent=[0, 2, 0, fs/2], cmap='viridis')\n",
    "plt.colorbar(label='Magnitude (dB)')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Frequency (Hz)')\n",
    "plt.title('Spectrogram')\n",
    "plt.ylim([0, 150])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Spectrogram shape: {spec.shape} (batch, freq_bins, time_frames)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hilbert Transform and Analytical Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate amplitude-modulated signal\n",
    "carrier_freq = 100  # Hz\n",
    "modulation_freq = 5  # Hz\n",
    "t_am = np.linspace(0, 1, fs)\n",
    "carrier = np.sin(2 * np.pi * carrier_freq * t_am)\n",
    "modulation = 1 + 0.5 * np.sin(2 * np.pi * modulation_freq * t_am)\n",
    "am_signal = modulation * carrier\n",
    "\n",
    "am_torch = torch.tensor(am_signal, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "# Apply Hilbert transform\n",
    "hilbert_layer = stx.nn.Hilbert()\n",
    "analytic_signal = hilbert_layer(am_torch)\n",
    "\n",
    "# Extract envelope (instantaneous amplitude)\n",
    "envelope = torch.abs(analytic_signal)\n",
    "\n",
    "# Extract instantaneous phase\n",
    "phase = torch.angle(analytic_signal)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Original signal and envelope\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(t_am[:200], am_signal[:200], 'b-', label='AM Signal', alpha=0.7)\n",
    "plt.plot(t_am[:200], envelope.squeeze().numpy()[:200], 'r-', linewidth=2, label='Envelope')\n",
    "plt.plot(t_am[:200], -envelope.squeeze().numpy()[:200], 'r-', linewidth=2)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('Amplitude Modulated Signal with Envelope')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Instantaneous phase\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(t_am[:200], phase.squeeze().numpy()[:200])\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Phase (rad)')\n",
    "plt.title('Instantaneous Phase')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Modulation extraction\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(t_am, modulation, 'g-', linewidth=2, label='True Modulation')\n",
    "plt.plot(t_am, envelope.squeeze().numpy(), 'r--', label='Extracted Envelope')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('Modulation Extraction Comparison')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Phase-Amplitude Coupling (PAC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic signal with phase-amplitude coupling\n",
    "# Low frequency phase modulates high frequency amplitude\n",
    "t_pac = np.linspace(0, 5, 5 * fs)\n",
    "phase_freq = 6  # Hz (theta band)\n",
    "amp_freq = 50   # Hz (gamma band)\n",
    "\n",
    "# Phase signal\n",
    "phase_signal = np.sin(2 * np.pi * phase_freq * t_pac)\n",
    "\n",
    "# Amplitude modulation based on phase\n",
    "amp_modulation = 1 + 0.5 * (1 + phase_signal)\n",
    "\n",
    "# High frequency signal with modulated amplitude\n",
    "amp_signal = amp_modulation * np.sin(2 * np.pi * amp_freq * t_pac)\n",
    "\n",
    "# Combined signal\n",
    "pac_signal = phase_signal + amp_signal + 0.1 * np.random.randn(len(t_pac))\n",
    "pac_torch = torch.tensor(pac_signal, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "# Compute PAC\n",
    "pac_layer = stx.nn.PAC(\n",
    "    phase_freq_band=(4, 8),    # Theta band\n",
    "    amp_freq_band=(40, 60),    # Gamma band\n",
    "    fs=fs\n",
    ")\n",
    "\n",
    "pac_value = pac_layer(pac_torch)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# Original signal\n",
    "plt.subplot(4, 1, 1)\n",
    "plt.plot(t_pac[:1000], pac_signal[:1000])\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('Signal with Phase-Amplitude Coupling')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Phase component\n",
    "plt.subplot(4, 1, 2)\n",
    "plt.plot(t_pac[:1000], phase_signal[:1000], 'b-', label=f'{phase_freq}Hz Phase')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('Low Frequency Phase Component')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Amplitude component\n",
    "plt.subplot(4, 1, 3)\n",
    "plt.plot(t_pac[:1000], amp_signal[:1000], 'r-', alpha=0.7, label=f'{amp_freq}Hz Amplitude')\n",
    "plt.plot(t_pac[:1000], amp_modulation[:1000], 'g--', linewidth=2, label='Modulation Envelope')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('High Frequency Amplitude Component')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Spectrogram\n",
    "plt.subplot(4, 1, 4)\n",
    "f, t_spec, Sxx = signal.spectrogram(pac_signal, fs=fs, nperseg=256, noverlap=200)\n",
    "plt.pcolormesh(t_spec, f, 10 * np.log10(Sxx + 1e-10), cmap='viridis')\n",
    "plt.ylabel('Frequency (Hz)')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.title('Spectrogram showing PAC')\n",
    "plt.ylim([0, 100])\n",
    "plt.colorbar(label='Power (dB)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Phase-Amplitude Coupling value: {pac_value.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Specialized Dropout Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multi-channel signal\n",
    "n_channels = 8\n",
    "n_timepoints = 1000\n",
    "multi_channel_signal = torch.randn(1, n_channels, n_timepoints)\n",
    "\n",
    "# Apply different dropout strategies\n",
    "# Standard dropout\n",
    "standard_dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "# Channel-wise dropout (drops entire channels)\n",
    "channel_dropout = stx.nn.DropoutChannels(p=0.3)\n",
    "\n",
    "# Axis-wise dropout (drops along specific axis)\n",
    "axiswise_dropout = stx.nn.AxiswiseDropout(p=0.3, axis=2)  # Drop time points\n",
    "\n",
    "# Apply dropouts in training mode\n",
    "standard_dropout.train()\n",
    "channel_dropout.train()\n",
    "axiswise_dropout.train()\n",
    "\n",
    "signal_standard = standard_dropout(multi_channel_signal.clone())\n",
    "signal_channel = channel_dropout(multi_channel_signal.clone())\n",
    "signal_axiswise = axiswise_dropout(multi_channel_signal.clone())\n",
    "\n",
    "# Visualize dropout effects\n",
    "fig, axes = plt.subplots(4, 1, figsize=(14, 12))\n",
    "\n",
    "# Original\n",
    "im0 = axes[0].imshow(multi_channel_signal.squeeze().numpy(), \n",
    "                     aspect='auto', cmap='viridis')\n",
    "axes[0].set_title('Original Multi-channel Signal')\n",
    "axes[0].set_ylabel('Channel')\n",
    "plt.colorbar(im0, ax=axes[0])\n",
    "\n",
    "# Standard dropout\n",
    "im1 = axes[1].imshow(signal_standard.squeeze().numpy(), \n",
    "                     aspect='auto', cmap='viridis')\n",
    "axes[1].set_title('Standard Dropout (p=0.5)')\n",
    "axes[1].set_ylabel('Channel')\n",
    "plt.colorbar(im1, ax=axes[1])\n",
    "\n",
    "# Channel dropout\n",
    "im2 = axes[2].imshow(signal_channel.squeeze().numpy(), \n",
    "                     aspect='auto', cmap='viridis')\n",
    "axes[2].set_title('Channel Dropout (p=0.3) - Entire channels dropped')\n",
    "axes[2].set_ylabel('Channel')\n",
    "plt.colorbar(im2, ax=axes[2])\n",
    "\n",
    "# Axiswise dropout\n",
    "im3 = axes[3].imshow(signal_axiswise.squeeze().numpy(), \n",
    "                     aspect='auto', cmap='viridis')\n",
    "axes[3].set_title('Axiswise Dropout (p=0.3, axis=time) - Time points dropped')\n",
    "axes[3].set_ylabel('Channel')\n",
    "axes[3].set_xlabel('Time')\n",
    "plt.colorbar(im3, ax=axes[3])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Check which channels were dropped\n",
    "dropped_channels = torch.all(signal_channel.squeeze() == 0, dim=1)\n",
    "print(f\"Dropped channels: {torch.where(dropped_channels)[0].tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ResNet1D for Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ResNet1D model for time series classification\n",
    "model = stx.nn.ResNet1D(\n",
    "    in_channels=n_channels,\n",
    "    num_classes=4,\n",
    "    block_sizes=[2, 2, 2, 2],  # Number of residual blocks in each stage\n",
    "    channels=[64, 128, 256, 512]  # Channels in each stage\n",
    ")\n",
    "\n",
    "# Generate synthetic data\n",
    "batch_size = 16\n",
    "seq_length = 1000\n",
    "x = torch.randn(batch_size, n_channels, seq_length)\n",
    "\n",
    "# Forward pass\n",
    "output = model(x)\n",
    "\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"\\nModel architecture:\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# Visualize intermediate feature maps\n",
    "# Hook to capture intermediate outputs\n",
    "intermediate_outputs = []\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    intermediate_outputs.append(output.detach())\n",
    "\n",
    "# Register hooks on each stage\n",
    "hooks = []\n",
    "for i, stage in enumerate([model.conv1, model.stage1, model.stage2, model.stage3, model.stage4]):\n",
    "    hooks.append(stage.register_forward_hook(hook_fn))\n",
    "\n",
    "# Forward pass with hooks\n",
    "_ = model(x[:1])  # Single sample\n",
    "\n",
    "# Remove hooks\n",
    "for hook in hooks:\n",
    "    hook.remove()\n",
    "\n",
    "# Visualize feature evolution\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "titles = ['Input Conv', 'Stage 1', 'Stage 2', 'Stage 3', 'Stage 4', 'Global Avg Pool']\n",
    "\n",
    "for i, (feat, title) in enumerate(zip(intermediate_outputs[:6], titles)):\n",
    "    if i < 5:\n",
    "        # Show first few channels\n",
    "        feat_vis = feat[0, :min(8, feat.shape[1])].numpy()\n",
    "        im = axes[i].imshow(feat_vis, aspect='auto', cmap='viridis')\n",
    "        axes[i].set_title(f'{title}\\nShape: {list(feat.shape)}')\n",
    "        axes[i].set_ylabel('Channel')\n",
    "        axes[i].set_xlabel('Time')\n",
    "        plt.colorbar(im, ax=axes[i])\n",
    "\n",
    "# Hide last subplot\n",
    "axes[-1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Spatial Attention for Multi-channel Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create spatial attention module\n",
    "spatial_attention = stx.nn.SpatialAttention(\n",
    "    in_channels=n_channels,\n",
    "    reduction_ratio=2\n",
    ")\n",
    "\n",
    "# Generate data with different importance across channels\n",
    "important_channels = [1, 3, 5]  # Channels with signal\n",
    "noise_channels = [0, 2, 4, 6, 7]  # Channels with mostly noise\n",
    "\n",
    "data = torch.randn(batch_size, n_channels, seq_length) * 0.1\n",
    "\n",
    "# Add signal to important channels\n",
    "for ch in important_channels:\n",
    "    freq = 10 + ch * 5  # Different frequency for each channel\n",
    "    t = torch.linspace(0, 1, seq_length)\n",
    "    signal_ch = torch.sin(2 * np.pi * freq * t)\n",
    "    data[:, ch, :] += signal_ch\n",
    "\n",
    "# Apply spatial attention\n",
    "attended_data, attention_weights = spatial_attention(data, return_attention=True)\n",
    "\n",
    "# Visualize attention weights\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Original data (single sample)\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.imshow(data[0].numpy(), aspect='auto', cmap='viridis')\n",
    "plt.colorbar(label='Amplitude')\n",
    "plt.ylabel('Channel')\n",
    "plt.title('Original Multi-channel Data')\n",
    "\n",
    "# Attention weights\n",
    "plt.subplot(3, 1, 2)\n",
    "avg_attention = attention_weights.mean(dim=0).squeeze().numpy()\n",
    "plt.bar(range(n_channels), avg_attention)\n",
    "plt.xlabel('Channel')\n",
    "plt.ylabel('Attention Weight')\n",
    "plt.title('Learned Spatial Attention Weights')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add labels for important channels\n",
    "for ch in important_channels:\n",
    "    plt.text(ch, avg_attention[ch] + 0.01, 'Signal', ha='center', fontsize=8)\n",
    "for ch in noise_channels:\n",
    "    plt.text(ch, avg_attention[ch] + 0.01, 'Noise', ha='center', fontsize=8)\n",
    "\n",
    "# Attended data\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.imshow(attended_data[0].detach().numpy(), aspect='auto', cmap='viridis')\n",
    "plt.colorbar(label='Amplitude')\n",
    "plt.ylabel('Channel')\n",
    "plt.xlabel('Time')\n",
    "plt.title('Data After Spatial Attention')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Attention weights shape: {attention_weights.shape}\")\n",
    "print(f\"Channels with highest attention: {avg_attention.argsort()[-3:][::-1].tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Power Spectral Density (PSD) Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PSD layer\n",
    "psd_layer = stx.nn.PSD(\n",
    "    n_fft=256,\n",
    "    hop_length=128,\n",
    "    normalized=True\n",
    ")\n",
    "\n",
    "# Generate multi-band signal\n",
    "fs = 1000\n",
    "t = np.linspace(0, 2, 2 * fs)\n",
    "\n",
    "# Different frequency bands\n",
    "delta = 0.5 * np.sin(2 * np.pi * 2 * t)    # 2 Hz\n",
    "theta = 0.7 * np.sin(2 * np.pi * 6 * t)    # 6 Hz\n",
    "alpha = 1.0 * np.sin(2 * np.pi * 10 * t)   # 10 Hz\n",
    "beta = 0.6 * np.sin(2 * np.pi * 25 * t)    # 25 Hz\n",
    "gamma = 0.4 * np.sin(2 * np.pi * 50 * t)   # 50 Hz\n",
    "\n",
    "eeg_signal = delta + theta + alpha + beta + gamma + 0.2 * np.random.randn(len(t))\n",
    "eeg_torch = torch.tensor(eeg_signal, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "# Compute PSD\n",
    "psd = psd_layer(eeg_torch)\n",
    "\n",
    "# Frequency bins\n",
    "freq_bins = torch.linspace(0, fs/2, psd.shape[-1])\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# Time series\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(t[:500], eeg_signal[:500])\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('EEG-like Signal with Multiple Frequency Bands')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# PSD\n",
    "plt.subplot(3, 1, 2)\n",
    "psd_db = 10 * torch.log10(psd.squeeze() + 1e-10)\n",
    "plt.plot(freq_bins, psd_db)\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Power (dB)')\n",
    "plt.title('Power Spectral Density')\n",
    "plt.xlim([0, 100])\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Annotate frequency bands\n",
    "bands = [\n",
    "    ('Delta', 0.5, 4, 'blue'),\n",
    "    ('Theta', 4, 8, 'green'),\n",
    "    ('Alpha', 8, 13, 'orange'),\n",
    "    ('Beta', 13, 30, 'red'),\n",
    "    ('Gamma', 30, 100, 'purple')\n",
    "]\n",
    "\n",
    "for name, f_low, f_high, color in bands:\n",
    "    plt.axvspan(f_low, f_high, alpha=0.2, color=color, label=name)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "# Band power\n",
    "plt.subplot(3, 1, 3)\n",
    "band_powers = []\n",
    "band_names = []\n",
    "\n",
    "for name, f_low, f_high, color in bands:\n",
    "    # Find frequency indices\n",
    "    mask = (freq_bins >= f_low) & (freq_bins < f_high)\n",
    "    band_power = psd.squeeze()[mask].mean().item()\n",
    "    band_powers.append(band_power)\n",
    "    band_names.append(name)\n",
    "\n",
    "plt.bar(band_names, band_powers, color=[b[3] for b in bands])\n",
    "plt.xlabel('Frequency Band')\n",
    "plt.ylabel('Average Power')\n",
    "plt.title('Power Distribution Across Frequency Bands')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Integration Example: Multi-Modal Signal Processing Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a complete signal processing network\n",
    "class SignalProcessingNetwork(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, fs=1000):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Preprocessing layers\n",
    "        self.bandpass = stx.nn.BandPassFilter(low_freq=1, high_freq=100, fs=fs)\n",
    "        self.spatial_attention = stx.nn.SpatialAttention(n_channels)\n",
    "        \n",
    "        # Feature extraction\n",
    "        self.spectrogram = stx.nn.Spectrogram(n_fft=256, hop_length=64)\n",
    "        self.psd = stx.nn.PSD(n_fft=256)\n",
    "        \n",
    "        # Channel augmentation during training\n",
    "        self.channel_dropout = stx.nn.DropoutChannels(p=0.2)\n",
    "        \n",
    "        # Temporal feature extraction\n",
    "        self.resnet = stx.nn.ResNet1D(\n",
    "            in_channels=n_channels,\n",
    "            num_classes=128,  # Feature dimension\n",
    "            block_sizes=[1, 1, 1, 1],\n",
    "            channels=[32, 64, 128, 256]\n",
    "        )\n",
    "        \n",
    "        # Combine features for classification\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(128 + 129 + 129, 256),  # ResNet + Spec + PSD features\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, n_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Preprocessing\n",
    "        x = self.bandpass(x)\n",
    "        x, attention = self.spatial_attention(x, return_attention=True)\n",
    "        \n",
    "        # Apply channel dropout during training\n",
    "        if self.training:\n",
    "            x = self.channel_dropout(x)\n",
    "        \n",
    "        # Extract different features\n",
    "        # 1. Temporal features from ResNet\n",
    "        temporal_features = self.resnet(x)\n",
    "        \n",
    "        # 2. Spectral features\n",
    "        spec = self.spectrogram(x)\n",
    "        spec_features = spec.mean(dim=-1).squeeze()  # Average over time\n",
    "        \n",
    "        # 3. PSD features\n",
    "        psd = self.psd(x)\n",
    "        psd_features = psd.squeeze()\n",
    "        \n",
    "        # Combine all features\n",
    "        combined_features = torch.cat([\n",
    "            temporal_features,\n",
    "            spec_features.mean(dim=1),  # Average over channels\n",
    "            psd_features.mean(dim=1)     # Average over channels\n",
    "        ], dim=-1)\n",
    "        \n",
    "        # Classification\n",
    "        output = self.classifier(combined_features)\n",
    "        \n",
    "        return output, attention\n",
    "\n",
    "# Create model\n",
    "model = SignalProcessingNetwork(n_channels=8, n_classes=4, fs=1000)\n",
    "\n",
    "# Test with synthetic data\n",
    "test_data = torch.randn(4, 8, 2000)  # batch_size=4, channels=8, time=2000\n",
    "output, attention = model(test_data)\n",
    "\n",
    "print(\"Signal Processing Network Summary:\")\n",
    "print(f\"Input shape: {test_data.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"Attention shape: {attention.shape}\")\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# Visualize attention patterns\n",
    "plt.figure(figsize=(10, 6))\n",
    "attention_avg = attention.mean(dim=0).squeeze().detach().numpy()\n",
    "plt.imshow(attention_avg.reshape(1, -1), aspect='auto', cmap='hot')\n",
    "plt.colorbar(label='Attention Weight')\n",
    "plt.xlabel('Channel')\n",
    "plt.ylabel('Sample')\n",
    "plt.title('Learned Spatial Attention Patterns')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The `scitex.nn` module provides specialized neural network components for scientific computing:\n",
    "\n",
    "1. **Signal Filtering**: Differentiable filters (low-pass, high-pass, band-pass) for preprocessing\n",
    "2. **Time-Frequency Analysis**: Spectrogram and PSD layers for spectral feature extraction\n",
    "3. **Advanced Signal Processing**: Hilbert transform, phase-amplitude coupling (PAC)\n",
    "4. **Specialized Architectures**: ResNet1D for time series, spatial attention for multi-channel data\n",
    "5. **Regularization**: Channel dropout and axis-wise dropout for robust training\n",
    "\n",
    "These components are particularly useful for:\n",
    "- EEG/MEG signal analysis\n",
    "- Time series classification\n",
    "- Biomedical signal processing\n",
    "- Multi-channel sensor data analysis\n",
    "- Real-time signal processing applications"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}