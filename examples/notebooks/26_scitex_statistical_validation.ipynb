{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Validation with SciTeX\n",
    "\n",
    "This notebook demonstrates the statistical validation framework in SciTeX, which helps ensure the scientific validity of your statistical analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scitex.stats import StatisticalValidator, EffectSizeCalculator\n",
    "import scitex as stx\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Checking Statistical Assumptions\n",
    "\n",
    "Before running statistical tests, it's crucial to check that your data meets the test assumptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Normality Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate example data\n",
    "normal_data = np.random.normal(loc=100, scale=15, size=100)\n",
    "skewed_data = np.random.exponential(scale=10, size=100)\n",
    "\n",
    "# Check normality\n",
    "is_normal, p_value, stats = StatisticalValidator.check_normality(normal_data)\n",
    "print(\"Normal distribution:\")\n",
    "print(f\"  Normally distributed: {is_normal}\")\n",
    "print(f\"  P-value: {p_value:.4f}\")\n",
    "print(f\"  Skewness: {stats['skew']:.3f}\")\n",
    "print(f\"  Kurtosis: {stats['kurtosis']:.3f}\\n\")\n",
    "\n",
    "is_normal, p_value, stats = StatisticalValidator.check_normality(skewed_data)\n",
    "print(\"Exponential distribution:\")\n",
    "print(f\"  Normally distributed: {is_normal}\")\n",
    "print(f\"  P-value: {p_value:.4f}\")\n",
    "print(f\"  Skewness: {stats['skew']:.3f}\")\n",
    "print(f\"  Kurtosis: {stats['kurtosis']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the distributions\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ax1.hist(normal_data, bins=20, density=True, alpha=0.7, edgecolor='black')\n",
    "ax1.set_title('Normal Distribution')\n",
    "ax1.set_xlabel('Value')\n",
    "ax1.set_ylabel('Density')\n",
    "\n",
    "ax2.hist(skewed_data, bins=20, density=True, alpha=0.7, edgecolor='black')\n",
    "ax2.set_title('Exponential Distribution (Skewed)')\n",
    "ax2.set_xlabel('Value')\n",
    "ax2.set_ylabel('Density')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Homoscedasticity Testing (Equal Variances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groups with equal variances\n",
    "group1_equal = np.random.normal(100, 10, 50)\n",
    "group2_equal = np.random.normal(105, 11, 50)\n",
    "\n",
    "# Groups with unequal variances\n",
    "group1_unequal = np.random.normal(100, 10, 50)\n",
    "group2_unequal = np.random.normal(105, 30, 50)\n",
    "\n",
    "# Test equal variances\n",
    "is_homo, p_value, stats = StatisticalValidator.check_homoscedasticity(group1_equal, group2_equal)\n",
    "print(\"Groups with similar variances:\")\n",
    "print(f\"  Homoscedastic: {is_homo}\")\n",
    "print(f\"  P-value: {p_value:.4f}\")\n",
    "print(f\"  Variance ratio: {stats['variance_ratio']:.2f}\\n\")\n",
    "\n",
    "# Test unequal variances\n",
    "is_homo, p_value, stats = StatisticalValidator.check_homoscedasticity(group1_unequal, group2_unequal)\n",
    "print(\"Groups with different variances:\")\n",
    "print(f\"  Homoscedastic: {is_homo}\")\n",
    "print(f\"  P-value: {p_value:.4f}\")\n",
    "print(f\"  Variance ratio: {stats['variance_ratio']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Sample Size Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check sample size for different tests\n",
    "small_sample = np.random.normal(100, 15, 20)\n",
    "medium_sample = np.random.normal(100, 15, 50)\n",
    "\n",
    "# For t-test\n",
    "is_adequate, info = StatisticalValidator.validate_sample_size(small_sample, 't_test')\n",
    "print(f\"T-test with n={len(small_sample)}:\")\n",
    "print(f\"  Adequate: {is_adequate}\")\n",
    "print(f\"  Recommendation: {info.get('power_recommendation', 'Sample size OK')}\\n\")\n",
    "\n",
    "# For correlation\n",
    "is_adequate, info = StatisticalValidator.validate_sample_size(medium_sample, 'correlation')\n",
    "print(f\"Correlation with n={len(medium_sample)}:\")\n",
    "print(f\"  Adequate: {is_adequate}\")\n",
    "print(f\"  Recommendation: {info.get('power_recommendation', 'Sample size OK')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Choosing the Right Statistical Test\n",
    "\n",
    "The validator can suggest appropriate tests based on your data characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Normal data with equal variances\n",
    "data_chars = {\n",
    "    'is_normal': True,\n",
    "    'is_homoscedastic': True,\n",
    "    'n_groups': 2,\n",
    "    'is_paired': False,\n",
    "    'sample_size': 50\n",
    "}\n",
    "\n",
    "suggestions = StatisticalValidator.suggest_test(data_chars, 'two_sample')\n",
    "print(\"Scenario 1: Normal data, equal variances\")\n",
    "print(f\"  Recommended test: {suggestions['primary']}\")\n",
    "print(f\"  Alternatives: {suggestions['alternatives']}\\n\")\n",
    "\n",
    "# Example 2: Non-normal data\n",
    "data_chars['is_normal'] = False\n",
    "suggestions = StatisticalValidator.suggest_test(data_chars, 'two_sample')\n",
    "print(\"Scenario 2: Non-normal data\")\n",
    "print(f\"  Recommended test: {suggestions['primary']}\")\n",
    "print(f\"  Rationale: {suggestions['rationale'][0]}\\n\")\n",
    "\n",
    "# Example 3: Paired data\n",
    "data_chars['is_paired'] = True\n",
    "suggestions = StatisticalValidator.suggest_test(data_chars, 'two_sample')\n",
    "print(\"Scenario 3: Paired non-normal data\")\n",
    "print(f\"  Recommended test: {suggestions['primary']}\")\n",
    "print(f\"  Alternatives: {suggestions['alternatives']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Effect Size Calculations\n",
    "\n",
    "P-values tell you if an effect exists, but effect sizes tell you how large it is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Cohen's d for Two Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small effect (d ≈ 0.2)\n",
    "control_small = np.random.normal(100, 15, 100)\n",
    "treatment_small = np.random.normal(103, 15, 100)\n",
    "\n",
    "# Large effect (d ≈ 0.8)\n",
    "control_large = np.random.normal(100, 15, 100)\n",
    "treatment_large = np.random.normal(112, 15, 100)\n",
    "\n",
    "# Calculate effect sizes\n",
    "small_effect = EffectSizeCalculator.cohens_d(treatment_small, control_small)\n",
    "large_effect = EffectSizeCalculator.cohens_d(treatment_large, control_large)\n",
    "\n",
    "print(\"Small effect:\")\n",
    "print(f\"  Cohen's d = {small_effect['d']:.3f} ({small_effect['interpretation']})\")\n",
    "print(f\"  Mean difference = {small_effect['mean_diff']:.2f}\")\n",
    "print(f\"  95% CI: [{small_effect['ci_lower']:.3f}, {small_effect['ci_upper']:.3f}]\\n\")\n",
    "\n",
    "print(\"Large effect:\")\n",
    "print(f\"  Cohen's d = {large_effect['d']:.3f} ({large_effect['interpretation']})\")\n",
    "print(f\"  Mean difference = {large_effect['mean_diff']:.2f}\")\n",
    "print(f\"  95% CI: [{large_effect['ci_lower']:.3f}, {large_effect['ci_upper']:.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize effect sizes\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Small effect\n",
    "ax1.hist(control_small, bins=20, alpha=0.5, label='Control', density=True)\n",
    "ax1.hist(treatment_small, bins=20, alpha=0.5, label='Treatment', density=True)\n",
    "ax1.axvline(control_small.mean(), color='blue', linestyle='--')\n",
    "ax1.axvline(treatment_small.mean(), color='orange', linestyle='--')\n",
    "ax1.set_title(f'Small Effect (d = {small_effect[\"d\"]:.2f})')\n",
    "ax1.legend()\n",
    "\n",
    "# Large effect\n",
    "ax2.hist(control_large, bins=20, alpha=0.5, label='Control', density=True)\n",
    "ax2.hist(treatment_large, bins=20, alpha=0.5, label='Treatment', density=True)\n",
    "ax2.axvline(control_large.mean(), color='blue', linestyle='--')\n",
    "ax2.axvline(treatment_large.mean(), color='orange', linestyle='--')\n",
    "ax2.set_title(f'Large Effect (d = {large_effect[\"d\"]:.2f})')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Effect Sizes for ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three groups with medium effect\n",
    "groups = [\n",
    "    np.random.normal(100, 15, 50),  # Control\n",
    "    np.random.normal(105, 15, 50),  # Treatment 1\n",
    "    np.random.normal(110, 15, 50),  # Treatment 2\n",
    "]\n",
    "\n",
    "# Calculate eta-squared and omega-squared\n",
    "eta_result = EffectSizeCalculator.eta_squared(groups)\n",
    "omega_result = EffectSizeCalculator.omega_squared(groups)\n",
    "\n",
    "print(\"ANOVA Effect Sizes:\")\n",
    "print(f\"  Eta-squared = {eta_result['eta_squared']:.3f} ({eta_result['interpretation']})\")\n",
    "print(f\"  Omega-squared = {omega_result['omega_squared']:.3f} ({omega_result['interpretation']})\")\n",
    "print(f\"\\nNote: Omega-squared is less biased for small samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Effect Sizes for Contingency Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2x2 contingency table\n",
    "# Rows: Treatment/Control, Columns: Success/Failure\n",
    "contingency_table = np.array([\n",
    "    [45, 15],  # Treatment: 45 success, 15 failure\n",
    "    [30, 30]   # Control: 30 success, 30 failure\n",
    "])\n",
    "\n",
    "# Calculate odds ratio and relative risk\n",
    "or_result = EffectSizeCalculator.odds_ratio(contingency_table)\n",
    "rr_result = EffectSizeCalculator.relative_risk(contingency_table)\n",
    "\n",
    "print(\"Contingency Table:\")\n",
    "print(contingency_table)\n",
    "print(f\"\\nOdds Ratio = {or_result['odds_ratio']:.2f}\")\n",
    "print(f\"  95% CI: [{or_result['ci_lower']:.2f}, {or_result['ci_upper']:.2f}]\")\n",
    "print(f\"  Interpretation: {or_result['interpretation']}\")\n",
    "print(f\"\\nRelative Risk = {rr_result['relative_risk']:.2f}\")\n",
    "print(f\"  95% CI: [{rr_result['ci_lower']:.2f}, {rr_result['ci_upper']:.2f}]\")\n",
    "print(f\"  Interpretation: {rr_result['interpretation']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Practical Example: Complete Analysis Workflow\n",
    "\n",
    "Let's walk through a complete analysis with validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate experimental data\n",
    "np.random.seed(123)\n",
    "\n",
    "# Control group: baseline performance\n",
    "control = np.random.normal(75, 12, 25)\n",
    "\n",
    "# Treatment group: new intervention\n",
    "treatment = np.random.normal(82, 15, 28)\n",
    "\n",
    "print(\"Step 1: Check assumptions\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Check normality\n",
    "control_normal, _, _ = StatisticalValidator.check_normality(control)\n",
    "treatment_normal, _, _ = StatisticalValidator.check_normality(treatment)\n",
    "print(f\"Control group normal: {control_normal}\")\n",
    "print(f\"Treatment group normal: {treatment_normal}\")\n",
    "\n",
    "# Check equal variances\n",
    "is_homo, p_homo, _ = StatisticalValidator.check_homoscedasticity(control, treatment)\n",
    "print(f\"Equal variances: {is_homo} (p={p_homo:.3f})\")\n",
    "\n",
    "# Check sample size\n",
    "is_adequate, size_info = StatisticalValidator.validate_sample_size([control, treatment], 't_test')\n",
    "print(f\"Sample size adequate: {is_adequate}\")\n",
    "print(f\"Group sizes: {size_info['group_sizes']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nStep 2: Choose appropriate test\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Get test recommendation\n",
    "data_characteristics = {\n",
    "    'is_normal': control_normal and treatment_normal,\n",
    "    'is_homoscedastic': is_homo,\n",
    "    'n_groups': 2,\n",
    "    'is_paired': False,\n",
    "    'sample_size': min(len(control), len(treatment))\n",
    "}\n",
    "\n",
    "test_suggestion = StatisticalValidator.suggest_test(data_characteristics, 'two_sample')\n",
    "print(f\"Recommended test: {test_suggestion['primary']}\")\n",
    "print(f\"Alternatives: {test_suggestion['alternatives']}\")\n",
    "\n",
    "# Run the appropriate test\n",
    "from scipy import stats\n",
    "if test_suggestion['primary'] == 'independent_t_test':\n",
    "    stat, p_value = stats.ttest_ind(control, treatment)\n",
    "    test_name = \"Independent t-test\"\n",
    "elif test_suggestion['primary'] == 'welch_t_test':\n",
    "    stat, p_value = stats.ttest_ind(control, treatment, equal_var=False)\n",
    "    test_name = \"Welch's t-test\"\n",
    "else:\n",
    "    # Use SciTeX's Brunner-Munzel test\n",
    "    from scitex.stats import brunner_munzel\n",
    "    result = brunner_munzel(control, treatment)\n",
    "    stat, p_value = result['statistic'], result['pvalue']\n",
    "    test_name = \"Brunner-Munzel test\"\n",
    "\n",
    "print(f\"\\nTest: {test_name}\")\n",
    "print(f\"Statistic: {stat:.3f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nStep 3: Calculate effect size\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Cohen's d\n",
    "effect = EffectSizeCalculator.cohens_d(treatment, control)\n",
    "print(f\"Cohen's d = {effect['d']:.3f} ({effect['interpretation']})\")\n",
    "print(f\"95% CI: [{effect['ci_lower']:.3f}, {effect['ci_upper']:.3f}]\")\n",
    "print(f\"Mean difference: {effect['mean_diff']:.2f} points\")\n",
    "\n",
    "# Hedges' g (for smaller samples)\n",
    "hedges = EffectSizeCalculator.hedges_g(treatment, control)\n",
    "print(f\"\\nHedges' g = {hedges['g']:.3f} (bias-corrected)\")\n",
    "\n",
    "# Interpretation\n",
    "print(f\"\\nConclusion:\")\n",
    "if p_value < 0.05:\n",
    "    print(f\"✓ Statistically significant difference (p={p_value:.4f})\")\n",
    "else:\n",
    "    print(f\"✗ No statistically significant difference (p={p_value:.4f})\")\n",
    "print(f\"✓ Effect size is {effect['interpretation']} (d={effect['d']:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Box plot\n",
    "ax1.boxplot([control, treatment], labels=['Control', 'Treatment'])\n",
    "ax1.set_ylabel('Score')\n",
    "ax1.set_title('Group Comparison')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Effect size visualization\n",
    "x = np.linspace(40, 120, 1000)\n",
    "control_curve = stats.norm.pdf(x, control.mean(), control.std())\n",
    "treatment_curve = stats.norm.pdf(x, treatment.mean(), treatment.std())\n",
    "\n",
    "ax2.fill_between(x, control_curve, alpha=0.3, label='Control')\n",
    "ax2.fill_between(x, treatment_curve, alpha=0.3, label='Treatment')\n",
    "ax2.axvline(control.mean(), color='blue', linestyle='--', alpha=0.7)\n",
    "ax2.axvline(treatment.mean(), color='orange', linestyle='--', alpha=0.7)\n",
    "ax2.set_xlabel('Score')\n",
    "ax2.set_ylabel('Density')\n",
    "ax2.set_title(f'Effect Size: d = {effect[\"d\"]:.2f}')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Best Practices Summary\n",
    "\n",
    "1. **Always check assumptions** before running statistical tests\n",
    "2. **Report effect sizes** along with p-values\n",
    "3. **Use appropriate tests** based on data characteristics\n",
    "4. **Consider sample size** and statistical power\n",
    "5. **Visualize your data** to understand patterns\n",
    "\n",
    "The statistical validation framework in SciTeX helps ensure your analyses are scientifically valid and your conclusions are well-supported."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}