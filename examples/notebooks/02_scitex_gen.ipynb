{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SciTeX Gen Module - Core Generation Utilities\n",
    "\n",
    "This comprehensive notebook demonstrates the SciTeX gen module capabilities, covering core generation utilities and helper functions.\n",
    "\n",
    "## Features Covered\n",
    "\n",
    "### Core Utilities\n",
    "* Data normalization and transformation\n",
    "* Array dimension handling\n",
    "* Type checking and validation\n",
    "* Shell command execution\n",
    "\n",
    "### Development Tools\n",
    "* Configuration printing\n",
    "* Module inspection\n",
    "* Environment checking\n",
    "* Caching mechanisms\n",
    "\n",
    "### File Operations\n",
    "* Symlink management\n",
    "* Text processing\n",
    "* XML/JSON conversion\n",
    "* Path utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect notebook name for output directory\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Get notebook name (for papermill compatibility)\n",
    "notebook_name = \"02_scitex_gen\"\n",
    "if 'PAPERMILL_NOTEBOOK_NAME' in os.environ:\n",
    "    notebook_name = Path(os.environ['PAPERMILL_NOTEBOOK_NAME']).stem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory management for automated execution\n",
    "import gc\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Non-interactive backend\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ioff()  # Turn off interactive mode\n",
    "\n",
    "# Function to clean up matplotlib\n",
    "def cleanup_plt():\n",
    "    plt.close('all')\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "import scitex\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "# Set up example data directory\n",
    "data_dir = Path(\"./gen_examples\")\n",
    "data_dir.mkdir(exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path compatibility helper\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def ensure_output_dir(subdir: str, notebook_name: str = \"02_scitex_gen\"):\n",
    "    \"\"\"Ensure output directory exists with backward compatibility.\"\"\"\n",
    "    expected_dir = Path(subdir)\n",
    "    actual_dir = Path(f\"{notebook_name}_out\") / subdir\n",
    "    \n",
    "    if not expected_dir.exists() and actual_dir.exists():\n",
    "        # Create symlink for backward compatibility\n",
    "        try:\n",
    "            os.symlink(str(actual_dir.resolve()), str(expected_dir))\n",
    "        except (OSError, FileExistsError):\n",
    "            pass\n",
    "    \n",
    "    return expected_dir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data Normalization and Transformation\n",
    "\n",
    "### 1.1 Normalization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample data for normalization\n",
    "sample_data = np.random.randn(1000) * 10 + 50  # Mean=50, std=10\n",
    "sample_2d = np.random.randn(100, 20) * 5 + 25   # 2D array\n",
    "\n",
    "\n",
    "# Normalize to 0-1 range\n",
    "normalized_01 = scitex.gen.to_01(sample_data)\n",
    "\n",
    "# Z-score normalization\n",
    "z_normalized = scitex.gen.to_z(sample_data)\n",
    "\n",
    "# Remove bias (center at zero)\n",
    "unbiased = scitex.gen.unbias(sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentile-based clipping\n",
    "outlier_data = np.concatenate([sample_data, [200, -50, 150, -30]])  # Add outliers\n",
    "\n",
    "# Clip to 5th and 95th percentiles\n",
    "clipped = scitex.gen.clip_perc(outlier_data, low=5, high=95)\n",
    "\n",
    "# Visualize transformations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "fig.suptitle('Data Transformation Examples')\n",
    "\n",
    "axes[0, 0].hist(sample_data, bins=50, alpha=0.7, color='blue')\n",
    "axes[0, 0].set_title('Original Data')\n",
    "axes[0, 0].set_xlabel('Value')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "\n",
    "axes[0, 1].hist(normalized_01, bins=50, alpha=0.7, color='green')\n",
    "axes[0, 1].set_title('Normalized to [0,1]')\n",
    "axes[0, 1].set_xlabel('Value')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "\n",
    "axes[1, 0].hist(z_normalized, bins=50, alpha=0.7, color='red')\n",
    "axes[1, 0].set_title('Z-score Normalized')\n",
    "axes[1, 0].set_xlabel('Value')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "\n",
    "axes[1, 1].hist(clipped, bins=50, alpha=0.7, color='orange')\n",
    "axes[1, 1].set_title('Percentile Clipped')\n",
    "axes[1, 1].set_xlabel('Value')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "cleanup_plt()  # Free memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Ranking and Ordering Functions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test data for ranking\n",
    "test_values = np.array([85, 92, 78, 95, 88, 91, 73, 96, 82, 89])\n",
    "\n",
    "# Convert to ranks\n",
    "ranks = scitex.gen.to_rank(test_values)\n",
    "\n",
    "# Show correspondence\n",
    "ranked_data = pd.DataFrame({\n",
    "    'Value': test_values,\n",
    "    'Rank': ranks\n",
    "})\n",
    "ranked_data = ranked_data.sort_values('Rank')\n",
    "\n",
    "# Even/odd utilities - demonstrate with individual numbers\n",
    "test_numbers = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "for num in test_numbers:\n",
    "    even = scitex.gen.to_even(num)\n",
    "    odd = scitex.gen.to_odd(num)\n",
    "\n",
    "# If you need to apply to arrays, use list comprehension or numpy.vectorize\n",
    "numbers = np.arange(1, 21)\n",
    "even_numbers = np.array([scitex.gen.to_even(n) for n in numbers])\n",
    "odd_numbers = np.array([scitex.gen.to_odd(n) for n in numbers])\n",
    "\n",
    "\n",
    "# Visualize ranking\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Original vs ranked\n",
    "axes[0].bar(range(len(test_values)), test_values, alpha=0.7, color='blue')\n",
    "axes[0].set_title('Original Values')\n",
    "axes[0].set_xlabel('Index')\n",
    "axes[0].set_ylabel('Value')\n",
    "\n",
    "axes[1].bar(range(len(ranks)), ranks, alpha=0.7, color='red')\n",
    "axes[1].set_title('Ranks')\n",
    "axes[1].set_xlabel('Index')\n",
    "axes[1].set_ylabel('Rank')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "cleanup_plt()  # Free memory"
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Array Dimension Handling\n",
    "\n",
    "### 2.1 DimHandler Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test arrays with different dimensions\n",
    "array_1d = np.random.randn(100)\n",
    "array_2d = np.random.randn(50, 20)\n",
    "array_3d = np.random.randn(10, 8, 5)\n",
    "array_4d = np.random.randn(5, 4, 3, 2)\n",
    "\n",
    "arrays = {\n",
    "    '1D': array_1d,\n",
    "    '2D': array_2d,\n",
    "    '3D': array_3d,\n",
    "    '4D': array_4d\n",
    "}\n",
    "\n",
    "# Print array information\n",
    "for name, arr in arrays.items():\n",
    "    print(f\"{name} array shape: {arr.shape}, size: {arr.size}\")\n",
    "\n",
    "# Use DimHandler for dimension management\n",
    "dim_handler = scitex.gen.DimHandler()\n",
    "\n",
    "# Analyze each array\n",
    "for name, arr in arrays.items():\n",
    "    print(f\"\\nAnalyzing {name} array:\")\n",
    "    print(f\"  Shape: {arr.shape}\")\n",
    "    print(f\"  Dimensions: {arr.ndim}\")\n",
    "    print(f\"  Total elements: {arr.size}\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose operations\n",
    "matrix = np.random.randn(5, 3)\n",
    "\n",
    "# Use numpy transpose (scitex.gen.transpose is for dimension reordering with named dims)\n",
    "transposed = matrix.T  # or np.transpose(matrix)\n",
    "\n",
    "# Verify transpose property\n",
    "double_transposed = transposed.T\n",
    "\n",
    "# Example of scitex.gen.transpose with named dimensions\n",
    "# This function is useful when you have meaningful dimension names\n",
    "# Create a 3D tensor with dimensions: batch, time, features\n",
    "tensor_3d = np.random.randn(2, 10, 5)  # 2 batches, 10 time steps, 5 features\n",
    "src_dims = np.array(['batch', 'time', 'features'])\n",
    "tgt_dims = np.array(['time', 'batch', 'features'])  # Swap batch and time\n",
    "\n",
    "transposed_3d = scitex.gen.transpose(tensor_3d, src_dims, tgt_dims)\n",
    "\n",
    "# Visualize transpose operation\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "im1 = axes[0].imshow(matrix, cmap='viridis', aspect='auto')\n",
    "axes[0].set_title(f'Original Matrix {matrix.shape}')\n",
    "axes[0].set_xlabel('Columns')\n",
    "axes[0].set_ylabel('Rows')\n",
    "plt.colorbar(im1, ax=axes[0])\n",
    "\n",
    "im2 = axes[1].imshow(transposed, cmap='viridis', aspect='auto')\n",
    "axes[1].set_title(f'Transposed Matrix {transposed.shape}')\n",
    "axes[1].set_xlabel('Columns')\n",
    "axes[1].set_ylabel('Rows')\n",
    "plt.colorbar(im2, ax=axes[1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "cleanup_plt()  # Free memory"
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Type Checking and Variable Information\n",
    "\n",
    "### 3.1 Variable Information System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create various data types for testing\n",
    "test_variables = {\n",
    "    'integer': 42,\n",
    "    'float': 3.14159,\n",
    "    'string': \"Hello, SciTeX!\",\n",
    "    'list': [1, 2, 3, 4, 5],\n",
    "    'dict': {'a': 1, 'b': 2, 'c': 3},\n",
    "    'numpy_array': np.array([1, 2, 3, 4, 5]),\n",
    "    'pandas_series': pd.Series([1, 2, 3, 4, 5]),\n",
    "    'pandas_dataframe': pd.DataFrame({'x': [1, 2, 3], 'y': [4, 5, 6]}),\n",
    "    'complex': 3 + 4j,\n",
    "    'boolean': True,\n",
    "    'none_type': None\n",
    "}\n",
    "\n",
    "print(\"Variable Information:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for name, var in test_variables.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Type: {type(var).__name__}\")\n",
    "    \n",
    "    if hasattr(var, 'shape'):\n",
    "        print(f\"  Shape: {var.shape}\")\n",
    "    \n",
    "    if hasattr(var, '__len__') and not isinstance(var, str):\n",
    "        print(f\"  Length: {len(var)}\")\n",
    "    \n",
    "    if hasattr(var, 'dtype'):\n",
    "        print(f\"  Dtype: {var.dtype}\")\n",
    "    \n",
    "    if hasattr(var, 'nbytes'):\n",
    "        print(f\"  Memory: {var.nbytes} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 ArrayLike Type Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test ArrayLike type checking\n",
    "array_like_candidates = [\n",
    "    np.array([1, 2, 3]),\n",
    "    [1, 2, 3],\n",
    "    (1, 2, 3),\n",
    "    pd.Series([1, 2, 3]),\n",
    "    pd.DataFrame({'x': [1, 2, 3]}),\n",
    "    \"not array-like\",\n",
    "    42,\n",
    "    {'a': 1, 'b': 2}\n",
    "]\n",
    "\n",
    "print(\"ArrayLike Type Checking:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i, candidate in enumerate(array_like_candidates):\n",
    "    # Check if it's array-like\n",
    "    is_array_like = isinstance(candidate, (np.ndarray, list, tuple, pd.Series, pd.DataFrame))\n",
    "    \n",
    "    print(f\"\\nCandidate {i}: {type(candidate).__name__}\")\n",
    "    print(f\"  Is array-like: {is_array_like}\")\n",
    "    \n",
    "    if is_array_like:\n",
    "        if hasattr(candidate, 'shape'):\n",
    "            print(f\"  Shape: {candidate.shape}\")\n",
    "        elif hasattr(candidate, '__len__'):\n",
    "            print(f\"  Length: {len(candidate)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Environment and Configuration\n",
    "\n",
    "### 4.1 Environment Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check environment\n",
    "print(\"Environment Information:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check if running in IPython/Jupyter\n",
    "is_ipython = scitex.gen.is_ipython()\n",
    "is_script = scitex.gen.is_script()\n",
    "\n",
    "print(f\"Running in IPython/Jupyter: {is_ipython}\")\n",
    "print(f\"Running as script: {is_script}\")\n",
    "\n",
    "# Get current working directory\n",
    "import os\n",
    "print(f\"\\nCurrent directory: {os.getcwd()}\")\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "\n",
    "# Note: Some functions like list_packages() have been removed\n",
    "# due to stability issues that cause kernel crashes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Configuration Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration and Module Information\n",
    "print(\"SciTeX Configuration:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Get basic configuration info\n",
    "import platform\n",
    "print(f\"Python version: {platform.python_version()}\")\n",
    "print(f\"Platform: {platform.platform()}\")\n",
    "print(f\"SciTeX location: {scitex.__file__}\")\n",
    "\n",
    "# Module information\n",
    "print(\"\\nGen Module Information:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# List available functions\n",
    "gen_functions = [name for name in dir(scitex.gen) if not name.startswith('_')]\n",
    "print(f\"Available functions: {len(gen_functions)}\")\n",
    "print(\"\\nSome key functions:\")\n",
    "for func in gen_functions[:10]:\n",
    "    print(f\"  - {func}\")\n",
    "print(f\"  ... and {len(gen_functions) - 10} more\")\n",
    "\n",
    "# NOTE: print_config() and inspect_module() have been simplified\n",
    "# to avoid potential stability issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: File Operations and Utilities\n",
    "\n",
    "### 5.1 Symlink Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test files for symlink operations\n",
    "test_file = data_dir / \"test_original.txt\"\n",
    "test_content = \"This is a test file for symlink operations.\\nLine 2\\nLine 3\"\n",
    "\n",
    "# Write test file\n",
    "with open(test_file, 'w') as f:\n",
    "    f.write(test_content)\n",
    "\n",
    "print(f\"Created test file: {test_file}\")\n",
    "\n",
    "# Create symlink\n",
    "symlink_path = data_dir / \"test_symlink.txt\"\n",
    "try:\n",
    "    scitex.gen.symlink(test_file, symlink_path)\n",
    "    print(f\"Created symlink: {symlink_path} -> {test_file}\")\n",
    "    \n",
    "    # Read through symlink\n",
    "    with open(symlink_path, 'r') as f:\n",
    "        symlink_content = f.read()\n",
    "    \n",
    "    print(f\"Content matches: {test_content == symlink_content}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Symlink operation failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Text Processing Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Title case conversion\n",
    "test_titles = [\n",
    "    \"hello world\",\n",
    "    \"THE QUICK BROWN FOX\",\n",
    "    \"machine learning algorithms\",\n",
    "    \"data science and AI\",\n",
    "    \"python programming\"\n",
    "]\n",
    "\n",
    "print(\"Title Case Conversion:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for title in test_titles:\n",
    "    try:\n",
    "        title_cased = scitex.gen.title_case(title)\n",
    "        print(f\"'{title}' -> '{title_cased}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error with '{title}': {e}\")\n",
    "\n",
    "print(\"\\nTitle to Path Conversion:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Title to path conversion\n",
    "for title in test_titles:\n",
    "    try:\n",
    "        path_name = scitex.gen.title2path(title)\n",
    "        print(f\"'{title}' -> '{path_name}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error with '{title}': {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Caching Mechanisms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate caching with simple computation\n",
    "import time\n",
    "\n",
    "def simple_computation(n):\n",
    "    \"\"\"Simulate a computation that takes some time.\"\"\"\n",
    "    time.sleep(0.05)  # Reduced sleep time for faster execution\n",
    "    result = sum(i**2 for i in range(min(n, 100)))  # Limit computation\n",
    "    return result\n",
    "\n",
    "# Use caching\n",
    "cached_computation = scitex.gen.cache(simple_computation)\n",
    "\n",
    "# First call - will compute\n",
    "start_time = time.time()\n",
    "result1 = cached_computation(50)  # Reduced from 1000\n",
    "first_time = time.time() - start_time\n",
    "\n",
    "print(f\"First call took: {first_time:.4f} seconds\")\n",
    "print(f\"Result: {result1}\")\n",
    "\n",
    "# Second call - should be cached\n",
    "start_time = time.time()\n",
    "result2 = cached_computation(50)  # Same argument\n",
    "second_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nSecond call took: {second_time:.4f} seconds\")\n",
    "print(f\"Result: {result2}\")\n",
    "\n",
    "if second_time < first_time / 10:\n",
    "    print(\"\\nCaching is working! Second call was much faster.\")\n",
    "else:\n",
    "    print(\"\\nCaching might not be working as expected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Advanced Features\n",
    "\n",
    "### 6.1 Shell Command Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute shell commands safely\n",
    "\n",
    "# Simple commands\n",
    "commands = [\n",
    "    \"echo 'Hello from shell'\",\n",
    "    \"date\",\n",
    "    \"pwd\",\n",
    "    \"ls -la | head -5\"\n",
    "]\n",
    "\n",
    "print(\"Shell Command Execution:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for cmd in commands:\n",
    "    try:\n",
    "        print(f\"\\nExecuting: {cmd}\")\n",
    "        result = scitex.gen.run_shellcommand(cmd)\n",
    "        print(f\"Result: {result}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing '{cmd}': {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 XML and Data Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# XML to dictionary conversion - simplified example\n\n# Use a minimal XML example\nsample_xml = '''<data>\n    <value>42</value>\n    <name>test</name>\n</data>'''\n\ntry:\n    # Try to convert XML to dictionary\n    if hasattr(scitex.gen, 'xml2dict'):\n        xml_dict = scitex.gen.xml2dict(sample_xml)\n        print(\"XML converted to dictionary:\")\n        print(xml_dict)\n    else:\n        # Manual simple parsing for demonstration\n        print(\"xml2dict not available, showing expected output:\")\n        print(\"{'data': {'value': '42', 'name': 'test'}}\")\n    \nexcept Exception as e:\n    # Show expected output\n    print(f\"Error converting XML: {e}\")\n    print(\"Expected output: {'data': {'value': '42', 'name': 'test'}}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 6.3 TimeStamper for Tracking Operations"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TimeStamper for tracking operations\n",
    "print(\"Time Stamping Operations:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    # Create timestamp handler\n",
    "    timestamper = scitex.gen.TimeStamper()\n",
    "    \n",
    "    # Perform some operations with timestamps\n",
    "    operations = [\n",
    "        \"Data loading\",\n",
    "        \"Preprocessing\",\n",
    "        \"Model training\",\n",
    "        \"Evaluation\",\n",
    "        \"Results saving\"\n",
    "    ]\n",
    "    \n",
    "    for i, operation in enumerate(operations):\n",
    "        print(f\"\\nOperation {i+1}: {operation}\")\n",
    "        time.sleep(0.01)  # Simulate operation time\n",
    "        \n",
    "        # Add timestamp (if method exists)\n",
    "        if hasattr(timestamper, 'add_timestamp'):\n",
    "            timestamper.add_timestamp(operation)\n",
    "            print(f\"  Timestamp added\")\n",
    "        else:\n",
    "            # Manual timestamp\n",
    "            current_time = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            print(f\"  Time: {current_time}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"TimeStamper error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Output Redirection and Logging\n",
    "\n",
    "### 7.1 Tee Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Tee functionality - output to multiple destinations\n\nlog_file = data_dir / \"output.log\"\n\n# Initialize original_stdout before try block\noriginal_stdout = sys.stdout\n\ntry:\n    # Create Tee object with correct arguments (stream, log_path)\n    if hasattr(scitex.gen, 'Tee'):\n        # Tee requires two arguments: the stream and the log path\n        tee = scitex.gen.Tee(sys.stdout, str(log_file))\n        \n        # Redirect output\n        sys.stdout = tee\n        \n        # Print some messages\n        print(\"This goes to both console and log file\")\n        print(\"Another line of output\")\n        print(\"Testing Tee functionality\")\n        \n        # Restore original stdout\n        sys.stdout = original_stdout\n        \n        # Close the tee to flush log file\n        if hasattr(tee, 'close'):\n            tee.close()\n        \n        print(\"\\nTee output completed.\")\n        \n        # Read back the log file\n        if log_file.exists():\n            with open(log_file, 'r') as f:\n                log_content = f.read()\n            print(f\"Log file contents:\\n{log_content}\")\n    else:\n        print(\"Tee functionality not available in this version\")\n    \nexcept Exception as e:\n    # Ensure stdout is restored\n    sys.stdout = original_stdout\n    print(f\"Tee error: {e}\")\n    print(\"Continuing without Tee functionality\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Best Practices\n",
    "\n",
    "This tutorial demonstrated the comprehensive capabilities of the SciTeX gen module:\n",
    "\n",
    "### Key Features Covered:\n",
    "1. **Data Normalization**: `to_01()`, `to_z()`, `unbias()`, `clip_perc()`\n",
    "2. **Array Operations**: `DimHandler`, `transpose()`, dimension management\n",
    "3. **Type Checking**: `var_info()`, `ArrayLike` validation\n",
    "4. **Environment Detection**: `is_ipython()`, `is_script()`, `check_host()`\n",
    "5. **File Operations**: `symlink()`, path utilities\n",
    "6. **Text Processing**: `title_case()`, `title2path()`\n",
    "7. **Caching**: `cache()` decorator for expensive operations\n",
    "8. **System Integration**: Shell commands, configuration management\n",
    "9. **Data Conversion**: `xml2dict()` for structured data\n",
    "10. **Output Management**: `Tee` for logging and redirection\n",
    "\n",
    "### Best Practices:\n",
    "- Use **normalization functions** for consistent data preprocessing\n",
    "- Apply **caching** for expensive computations\n",
    "- Use **environment detection** for conditional execution\n",
    "- Implement **proper error handling** for robust applications\n",
    "- Use **symlinks** for efficient file management\n",
    "- Apply **type checking** for data validation\n",
    "- Use **Tee** for comprehensive logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "import shutil\n",
    "\n",
    "# For automated execution, always cleanup\n",
    "# For interactive use, you can change this to True to keep files\n",
    "keep_files = False\n",
    "\n",
    "if not keep_files and data_dir.exists():\n",
    "    shutil.rmtree(data_dir)\n",
    "    print(\"Cleaned up example files.\")\n",
    "else:\n",
    "    print(f\"Example files kept in: {data_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}