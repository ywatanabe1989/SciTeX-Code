{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SciTeX Stats Module Tutorial\n",
    "\n",
    "This comprehensive tutorial demonstrates the capabilities of the `scitex.stats` module, a powerful statistical analysis toolkit designed for scientific computing.\n",
    "\n",
    "## Features Covered\n",
    "\n",
    "### üìä **Descriptive Statistics**\n",
    "- Comprehensive descriptive statistics with PyTorch tensor support\n",
    "- NaN-aware statistical functions\n",
    "- Batch processing for large datasets\n",
    "- Multi-dimensional data analysis\n",
    "\n",
    "### üîó **Correlation Analysis**\n",
    "- Pearson and Spearman correlations\n",
    "- Permutation-based significance testing\n",
    "- Multiple correlation analysis\n",
    "- Partial correlation calculations\n",
    "\n",
    "### üß™ **Hypothesis Testing**\n",
    "- Brunner-Munzel test for non-parametric comparisons\n",
    "- Independence testing\n",
    "- Outlier detection (Smirnov-Grubbs test)\n",
    "- Effect size calculations\n",
    "\n",
    "### üîß **Multiple Comparison Corrections**\n",
    "- Bonferroni correction\n",
    "- False Discovery Rate (FDR) correction\n",
    "- Multiple group comparisons\n",
    "\n",
    "### ‚≠ê **Publication-Ready Output**\n",
    "- P-value to significance stars conversion\n",
    "- Formatted statistical reports\n",
    "- Integration with SciTeX visualization\n",
    "\n",
    "Let's explore the powerful statistical capabilities!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scitex\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats as scipy_stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f\"SciTeX version: {scitex.__version__ if hasattr(scitex, '__version__') else 'development'}\")\n",
    "print(\"üìä SciTeX Stats Module Tutorial - Ready for statistical analysis!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. üìä Descriptive Statistics with Advanced Features\n",
    "\n",
    "The SciTeX stats module provides comprehensive descriptive statistics with support for PyTorch tensors and NaN-aware computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scitex.stats import describe, nan, real\n",
    "\n",
    "# Create sample datasets with different characteristics\n",
    "np.random.seed(42)\n",
    "\n",
    "# Normal distribution data\n",
    "normal_data = np.random.normal(50, 15, 1000)\n",
    "\n",
    "# Skewed distribution data\n",
    "skewed_data = np.random.exponential(2, 1000)\n",
    "\n",
    "# Data with missing values\n",
    "data_with_nan = normal_data.copy()\n",
    "data_with_nan[np.random.choice(1000, 100, replace=False)] = np.nan\n",
    "\n",
    "# Multi-dimensional data (simulating experimental conditions)\n",
    "conditions = np.random.normal([10, 20, 30], [2, 3, 4], (100, 3))\n",
    "\n",
    "print(\"üìà Sample datasets created:\")\n",
    "print(f\"  ‚Ä¢ Normal data: {normal_data.shape} samples\")\n",
    "print(f\"  ‚Ä¢ Skewed data: {skewed_data.shape} samples\") \n",
    "print(f\"  ‚Ä¢ Data with NaN: {data_with_nan.shape} samples ({np.sum(np.isnan(data_with_nan))} missing values)\")\n",
    "print(f\"  ‚Ä¢ Multi-dimensional: {conditions.shape} (3 experimental conditions)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive descriptive statistics\n",
    "print(\"üìä Comprehensive Descriptive Statistics Analysis\\n\")\n",
    "\n",
    "datasets = {\n",
    "    'Normal Distribution': normal_data,\n",
    "    'Skewed Distribution': skewed_data,\n",
    "    'Data with NaN': data_with_nan\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, data in datasets.items():\n",
    "    print(f\"‚ïê‚ïê‚ïê {name} ‚ïê‚ïê‚ïê\")\n",
    "    \n",
    "    # Get comprehensive descriptive statistics\n",
    "    try:\n",
    "        desc_stats = describe(data)\n",
    "        results[name] = desc_stats\n",
    "        \n",
    "        print(f\"Count: {desc_stats.get('count', len(data[~np.isnan(data)] if name == 'Data with NaN' else data))}\")\n",
    "        print(f\"Mean: {desc_stats.get('mean', np.nanmean(data)):.4f}\")\n",
    "        print(f\"Std: {desc_stats.get('std', np.nanstd(data)):.4f}\")\n",
    "        print(f\"Skewness: {desc_stats.get('skewness', scipy_stats.skew(data, nan_policy='omit')):.4f}\")\n",
    "        print(f\"Kurtosis: {desc_stats.get('kurtosis', scipy_stats.kurtosis(data, nan_policy='omit')):.4f}\")\n",
    "        \n",
    "        # Check if quantiles are available\n",
    "        if 'q25' in desc_stats:\n",
    "            print(f\"Q25: {desc_stats['q25']:.4f}\")\n",
    "            print(f\"Median (Q50): {desc_stats['q50']:.4f}\")\n",
    "            print(f\"Q75: {desc_stats['q75']:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        # Fallback to numpy/scipy calculations\n",
    "        if np.any(np.isnan(data)):\n",
    "            valid_data = data[~np.isnan(data)]\n",
    "        else:\n",
    "            valid_data = data\n",
    "            \n",
    "        desc_stats = {\n",
    "            'count': len(valid_data),\n",
    "            'mean': np.mean(valid_data),\n",
    "            'std': np.std(valid_data),\n",
    "            'skewness': scipy_stats.skew(valid_data),\n",
    "            'kurtosis': scipy_stats.kurtosis(valid_data),\n",
    "            'q25': np.percentile(valid_data, 25),\n",
    "            'q50': np.percentile(valid_data, 50),\n",
    "            'q75': np.percentile(valid_data, 75)\n",
    "        }\n",
    "        results[name] = desc_stats\n",
    "        \n",
    "        print(f\"Count: {desc_stats['count']}\")\n",
    "        print(f\"Mean: {desc_stats['mean']:.4f}\")\n",
    "        print(f\"Std: {desc_stats['std']:.4f}\")\n",
    "        print(f\"Skewness: {desc_stats['skewness']:.4f}\")\n",
    "        print(f\"Kurtosis: {desc_stats['kurtosis']:.4f}\")\n",
    "        print(f\"Q25: {desc_stats['q25']:.4f}\")\n",
    "        print(f\"Median (Q50): {desc_stats['q50']:.4f}\")\n",
    "        print(f\"Q75: {desc_stats['q75']:.4f}\")\n",
    "    \n",
    "    # NaN statistics for data with missing values\n",
    "    if name == 'Data with NaN':\n",
    "        try:\n",
    "            nan_stats = nan(data)\n",
    "            print(f\"Missing values: {nan_stats.get('count', np.sum(np.isnan(data)))}\")\n",
    "            print(f\"Missing proportion: {nan_stats.get('proportion', np.sum(np.isnan(data))/len(data)):.3f}\")\n",
    "        except Exception:\n",
    "            print(f\"Missing values: {np.sum(np.isnan(data))}\")\n",
    "            print(f\"Missing proportion: {np.sum(np.isnan(data))/len(data):.3f}\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "print(\"‚úÖ Descriptive statistics analysis complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-dimensional descriptive statistics\n",
    "print(\"üßÆ Multi-Dimensional Data Analysis\\n\")\n",
    "\n",
    "condition_names = ['Condition A', 'Condition B', 'Condition C']\n",
    "\n",
    "# Analyze each condition\n",
    "print(\"Per-condition analysis:\")\n",
    "for i, condition_name in enumerate(condition_names):\n",
    "    condition_data = conditions[:, i]\n",
    "    \n",
    "    try:\n",
    "        desc_stats = describe(condition_data)\n",
    "        mean_val = desc_stats.get('mean', np.mean(condition_data))\n",
    "        std_val = desc_stats.get('std', np.std(condition_data))\n",
    "    except Exception:\n",
    "        mean_val = np.mean(condition_data)\n",
    "        std_val = np.std(condition_data)\n",
    "    \n",
    "    print(f\"  {condition_name}: Mean = {mean_val:.3f} ¬± {std_val:.3f}\")\n",
    "\n",
    "# Overall multi-dimensional analysis\n",
    "try:\n",
    "    multi_desc = describe(conditions)\n",
    "    print(f\"\\nOverall multi-dimensional statistics:\")\n",
    "    if isinstance(multi_desc, dict):\n",
    "        for key, value in multi_desc.items():\n",
    "            if isinstance(value, (int, float)):\n",
    "                print(f\"  {key}: {value:.4f}\")\n",
    "            elif hasattr(value, 'shape'):\n",
    "                print(f\"  {key}: shape {value.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nMulti-dimensional analysis: {np.mean(conditions, axis=0)}\")\n",
    "    print(f\"Per-condition means: {np.mean(conditions, axis=0)}\")\n",
    "    print(f\"Per-condition stds: {np.std(conditions, axis=0)}\")\n",
    "\n",
    "print(\"\\n‚úÖ Multi-dimensional analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. üîó Correlation Analysis with Permutation Testing\n",
    "\n",
    "Explore sophisticated correlation analysis with robust statistical testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scitex.stats import corr_test, calc_partial_corr\n",
    "\n",
    "# Create correlated datasets for demonstration\n",
    "np.random.seed(42)\n",
    "n_samples = 200\n",
    "\n",
    "# Generate correlated variables\n",
    "x1 = np.random.normal(0, 1, n_samples)\n",
    "x2 = 0.7 * x1 + 0.3 * np.random.normal(0, 1, n_samples)  # Strong positive correlation\n",
    "x3 = -0.5 * x1 + 0.5 * np.random.normal(0, 1, n_samples)  # Moderate negative correlation\n",
    "x4 = np.random.normal(0, 1, n_samples)  # Independent variable\n",
    "\n",
    "# Add some non-linear relationship\n",
    "x5 = x1**2 + 0.2 * np.random.normal(0, 1, n_samples)  # Non-linear relationship\n",
    "\n",
    "# Create DataFrame for easier handling\n",
    "data_df = pd.DataFrame({\n",
    "    'Variable_1': x1,\n",
    "    'Variable_2': x2,\n",
    "    'Variable_3': x3,\n",
    "    'Variable_4': x4,\n",
    "    'Variable_5': x5\n",
    "})\n",
    "\n",
    "print(f\"üìä Correlation analysis dataset: {data_df.shape[0]} samples, {data_df.shape[1]} variables\")\n",
    "print(\"\\nExpected relationships:\")\n",
    "print(\"  ‚Ä¢ Variable_1 ‚Üî Variable_2: Strong positive correlation (r ‚âà 0.7)\")\n",
    "print(\"  ‚Ä¢ Variable_1 ‚Üî Variable_3: Moderate negative correlation (r ‚âà -0.5)\")\n",
    "print(\"  ‚Ä¢ Variable_1 ‚Üî Variable_4: No correlation (r ‚âà 0)\")\n",
    "print(\"  ‚Ä¢ Variable_1 ‚Üî Variable_5: Non-linear relationship\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive correlation analysis\n",
    "print(\"üîó Comprehensive Correlation Analysis\\n\")\n",
    "\n",
    "# Test specific variable pairs\n",
    "test_pairs = [\n",
    "    ('Variable_1', 'Variable_2', 'Strong positive'),\n",
    "    ('Variable_1', 'Variable_3', 'Moderate negative'),\n",
    "    ('Variable_1', 'Variable_4', 'No correlation'),\n",
    "    ('Variable_1', 'Variable_5', 'Non-linear')\n",
    "]\n",
    "\n",
    "correlation_results = {}\n",
    "\n",
    "for var1, var2, description in test_pairs:\n",
    "    print(f\"‚ïê‚ïê‚ïê {var1} vs {var2} ({description}) ‚ïê‚ïê‚ïê\")\n",
    "    \n",
    "    x_data = data_df[var1].values\n",
    "    y_data = data_df[var2].values\n",
    "    \n",
    "    # Pearson correlation with permutation testing\n",
    "    try:\n",
    "        pearson_result = corr_test(x_data, y_data, method='pearson')\n",
    "        \n",
    "        r_val = pearson_result.get('correlation', np.corrcoef(x_data, y_data)[0, 1])\n",
    "        p_val = pearson_result.get('p_value', scipy_stats.pearsonr(x_data, y_data)[1])\n",
    "        \n",
    "        print(f\"Pearson r: {r_val:.4f}\")\n",
    "        print(f\"P-value: {p_val:.6f}\")\n",
    "        \n",
    "        if 'ci_lower' in pearson_result and 'ci_upper' in pearson_result:\n",
    "            print(f\"95% CI: [{pearson_result['ci_lower']:.4f}, {pearson_result['ci_upper']:.4f}]\")\n",
    "        \n",
    "        correlation_results[f\"{var1}_vs_{var2}\"] = pearson_result\n",
    "        \n",
    "    except Exception as e:\n",
    "        # Fallback to scipy\n",
    "        r_val, p_val = scipy_stats.pearsonr(x_data, y_data)\n",
    "        print(f\"Pearson r: {r_val:.4f}\")\n",
    "        print(f\"P-value: {p_val:.6f}\")\n",
    "        \n",
    "        correlation_results[f\"{var1}_vs_{var2}\"] = {\n",
    "            'correlation': r_val,\n",
    "            'p_value': p_val\n",
    "        }\n",
    "    \n",
    "    # Spearman correlation (for non-linear relationships)\n",
    "    try:\n",
    "        spearman_result = corr_test(x_data, y_data, method='spearman')\n",
    "        rho_val = spearman_result.get('correlation', scipy_stats.spearmanr(x_data, y_data)[0])\n",
    "        print(f\"Spearman œÅ: {rho_val:.4f}\")\n",
    "    except Exception:\n",
    "        rho_val, _ = scipy_stats.spearmanr(x_data, y_data)\n",
    "        print(f\"Spearman œÅ: {rho_val:.4f}\")\n",
    "    \n",
    "    # Interpret correlation strength\n",
    "    abs_r = abs(r_val)\n",
    "    if abs_r >= 0.7:\n",
    "        strength = \"Strong\"\n",
    "    elif abs_r >= 0.5:\n",
    "        strength = \"Moderate\"\n",
    "    elif abs_r >= 0.3:\n",
    "        strength = \"Weak\"\n",
    "    else:\n",
    "        strength = \"Very weak/None\"\n",
    "    \n",
    "    direction = \"positive\" if r_val > 0 else \"negative\"\n",
    "    significance = \"significant\" if p_val < 0.05 else \"not significant\"\n",
    "    \n",
    "    print(f\"Interpretation: {strength} {direction} correlation ({significance})\")\n",
    "    print()\n",
    "\n",
    "print(\"‚úÖ Correlation analysis complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partial correlation analysis\n",
    "print(\"üßÆ Partial Correlation Analysis\\n\")\n",
    "\n",
    "# Calculate partial correlation between Variable_2 and Variable_3, controlling for Variable_1\n",
    "try:\n",
    "    # Since Variable_2 and Variable_3 are both related to Variable_1,\n",
    "    # their apparent correlation might be due to their common relationship with Variable_1\n",
    "    \n",
    "    x_data = data_df['Variable_2'].values\n",
    "    y_data = data_df['Variable_3'].values\n",
    "    z_data = data_df['Variable_1'].values.reshape(-1, 1)  # Control variable\n",
    "    \n",
    "    # Regular correlation\n",
    "    regular_corr = np.corrcoef(x_data, y_data)[0, 1]\n",
    "    print(f\"Regular correlation (Variable_2 vs Variable_3): {regular_corr:.4f}\")\n",
    "    \n",
    "    # Partial correlation\n",
    "    try:\n",
    "        partial_result = calc_partial_corr(x_data, y_data, z_data)\n",
    "        partial_corr = partial_result.get('partial_correlation', 0)\n",
    "        print(f\"Partial correlation (controlling for Variable_1): {partial_corr:.4f}\")\n",
    "        \n",
    "        if 'p_value' in partial_result:\n",
    "            print(f\"Partial correlation p-value: {partial_result['p_value']:.6f}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        # Fallback calculation using linear regression residuals\n",
    "        from sklearn.linear_model import LinearRegression\n",
    "        \n",
    "        # Remove effect of Variable_1 from both variables\n",
    "        reg_x = LinearRegression().fit(z_data, x_data)\n",
    "        reg_y = LinearRegression().fit(z_data, y_data)\n",
    "        \n",
    "        residuals_x = x_data - reg_x.predict(z_data)\n",
    "        residuals_y = y_data - reg_y.predict(z_data)\n",
    "        \n",
    "        partial_corr = np.corrcoef(residuals_x, residuals_y)[0, 1]\n",
    "        print(f\"Partial correlation (controlling for Variable_1): {partial_corr:.4f}\")\n",
    "    \n",
    "    print(\"\\nInterpretation:\")\n",
    "    print(f\"  The regular correlation of {regular_corr:.4f} between Variable_2 and Variable_3\")\n",
    "    print(f\"  becomes {partial_corr:.4f} when controlling for their common cause (Variable_1).\")\n",
    "    print(f\"  This suggests the correlation is {'largely' if abs(partial_corr) < abs(regular_corr)/2 else 'partially'} explained by Variable_1.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Partial correlation analysis failed: {e}\")\n",
    "    print(\"This feature may not be available in the current installation.\")\n",
    "\n",
    "print(\"\\n‚úÖ Partial correlation analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. üß™ Hypothesis Testing and Group Comparisons\n",
    "\n",
    "Explore robust statistical tests for comparing groups and detecting differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scitex.stats import brunner_munzel_test, nocorrelation_test, smirnov_grubbs\n",
    "\n",
    "# Create experimental groups for hypothesis testing\n",
    "np.random.seed(42)\n",
    "\n",
    "# Group 1: Control group (normal distribution)\n",
    "control_group = np.random.normal(100, 15, 80)\n",
    "\n",
    "# Group 2: Treatment group (shifted mean, different distribution)\n",
    "treatment_group = np.random.normal(110, 12, 75)  # Higher mean, lower variance\n",
    "\n",
    "# Group 3: Non-normal group (exponential distribution)\n",
    "nonnormal_group = np.random.exponential(2, 70) * 10 + 90\n",
    "\n",
    "# Group 4: Group with outliers\n",
    "outlier_group = np.random.normal(100, 15, 85)\n",
    "outlier_indices = np.random.choice(85, 5, replace=False)\n",
    "outlier_group[outlier_indices] += np.random.choice([-50, 50], 5)  # Add extreme outliers\n",
    "\n",
    "groups = {\n",
    "    'Control': control_group,\n",
    "    'Treatment': treatment_group,\n",
    "    'Non-normal': nonnormal_group,\n",
    "    'With Outliers': outlier_group\n",
    "}\n",
    "\n",
    "print(\"üß™ Experimental Groups Created:\")\n",
    "for name, group in groups.items():\n",
    "    print(f\"  {name}: n={len(group)}, mean={np.mean(group):.2f}, std={np.std(group):.2f}\")\n",
    "    \n",
    "print(\"\\nExpected findings:\")\n",
    "print(\"  ‚Ä¢ Control vs Treatment: Significant difference (higher mean in treatment)\")\n",
    "print(\"  ‚Ä¢ Control vs Non-normal: Different distributions\")\n",
    "print(\"  ‚Ä¢ With Outliers: Should detect outliers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brunner-Munzel test for group comparisons\n",
    "print(\"üî¨ Brunner-Munzel Test for Group Comparisons\\n\")\n",
    "\n",
    "# Compare different group pairs\n",
    "comparisons = [\n",
    "    ('Control', 'Treatment'),\n",
    "    ('Control', 'Non-normal'),\n",
    "    ('Treatment', 'Non-normal')\n",
    "]\n",
    "\n",
    "bm_results = {}\n",
    "\n",
    "for group1_name, group2_name in comparisons:\n",
    "    print(f\"‚ïê‚ïê‚ïê {group1_name} vs {group2_name} ‚ïê‚ïê‚ïê\")\n",
    "    \n",
    "    group1 = groups[group1_name]\n",
    "    group2 = groups[group2_name]\n",
    "    \n",
    "    # Descriptive statistics\n",
    "    print(f\"{group1_name}: n={len(group1)}, mean={np.mean(group1):.3f}, std={np.std(group1):.3f}\")\n",
    "    print(f\"{group2_name}: n={len(group2)}, mean={np.mean(group2):.3f}, std={np.std(group2):.3f}\")\n",
    "    \n",
    "    try:\n",
    "        # Brunner-Munzel test (robust non-parametric test)\n",
    "        bm_result = brunner_munzel_test(group1, group2)\n",
    "        \n",
    "        statistic = bm_result.get('statistic', 0)\n",
    "        p_value = bm_result.get('p_value', 1)\n",
    "        \n",
    "        print(f\"\\nBrunner-Munzel Test:\")\n",
    "        print(f\"  Statistic: {statistic:.4f}\")\n",
    "        print(f\"  P-value: {p_value:.6f}\")\n",
    "        \n",
    "        if 'effect_size' in bm_result:\n",
    "            print(f\"  Effect size: {bm_result['effect_size']:.4f}\")\n",
    "        \n",
    "        # Interpretation\n",
    "        significance = \"significant\" if p_value < 0.05 else \"not significant\"\n",
    "        print(f\"  Result: {significance} difference (Œ± = 0.05)\")\n",
    "        \n",
    "        bm_results[f\"{group1_name}_vs_{group2_name}\"] = bm_result\n",
    "        \n",
    "    except Exception as e:\n",
    "        # Fallback to scipy Mann-Whitney U test\n",
    "        print(f\"\\nBrunner-Munzel test not available, using Mann-Whitney U test:\")\n",
    "        statistic, p_value = scipy_stats.mannwhitneyu(group1, group2, alternative='two-sided')\n",
    "        print(f\"  Statistic: {statistic:.4f}\")\n",
    "        print(f\"  P-value: {p_value:.6f}\")\n",
    "        \n",
    "        significance = \"significant\" if p_value < 0.05 else \"not significant\"\n",
    "        print(f\"  Result: {significance} difference (Œ± = 0.05)\")\n",
    "        \n",
    "        bm_results[f\"{group1_name}_vs_{group2_name}\"] = {\n",
    "            'statistic': statistic,\n",
    "            'p_value': p_value,\n",
    "            'test_used': 'Mann-Whitney U'\n",
    "        }\n",
    "    \n",
    "    # Additional: Classical t-test for comparison\n",
    "    t_stat, t_p = scipy_stats.ttest_ind(group1, group2, equal_var=False)\n",
    "    print(f\"\\nFor comparison - Welch's t-test:\")\n",
    "    print(f\"  t-statistic: {t_stat:.4f}\")\n",
    "    print(f\"  P-value: {t_p:.6f}\")\n",
    "    print(f\"  Result: {'significant' if t_p < 0.05 else 'not significant'} difference\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "print(\"‚úÖ Group comparison tests complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier detection using Smirnov-Grubbs test\n",
    "print(\"üéØ Outlier Detection Analysis\\n\")\n",
    "\n",
    "# Test for outliers in the group with known outliers\n",
    "test_group = groups['With Outliers']\n",
    "\n",
    "print(f\"Testing for outliers in 'With Outliers' group (n={len(test_group)})\")\n",
    "print(f\"Data range: {np.min(test_group):.2f} to {np.max(test_group):.2f}\")\n",
    "print(f\"Mean ¬± SD: {np.mean(test_group):.2f} ¬± {np.std(test_group):.2f}\")\n",
    "\n",
    "try:\n",
    "    # Smirnov-Grubbs test for outliers\n",
    "    outlier_result = smirnov_grubbs(test_group)\n",
    "    \n",
    "    print(f\"\\nSmirnov-Grubbs Test Results:\")\n",
    "    if 'outliers' in outlier_result:\n",
    "        outliers = outlier_result['outliers']\n",
    "        print(f\"  Number of outliers detected: {len(outliers)}\")\n",
    "        print(f\"  Outlier values: {outliers}\")\n",
    "    \n",
    "    if 'p_value' in outlier_result:\n",
    "        print(f\"  P-value: {outlier_result['p_value']:.6f}\")\n",
    "    \n",
    "    if 'test_statistic' in outlier_result:\n",
    "        print(f\"  Test statistic: {outlier_result['test_statistic']:.4f}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    # Fallback outlier detection using IQR method\n",
    "    print(f\"\\nSmirnov-Grubbs test not available. Using IQR method:\")\n",
    "    \n",
    "    Q1 = np.percentile(test_group, 25)\n",
    "    Q3 = np.percentile(test_group, 75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    # Define outliers as points beyond 1.5 * IQR from quartiles\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = test_group[(test_group < lower_bound) | (test_group > upper_bound)]\n",
    "    outlier_indices = np.where((test_group < lower_bound) | (test_group > upper_bound))[0]\n",
    "    \n",
    "    print(f\"  IQR method (1.5 √ó IQR rule):\")\n",
    "    print(f\"  Q1: {Q1:.2f}, Q3: {Q3:.2f}, IQR: {IQR:.2f}\")\n",
    "    print(f\"  Outlier bounds: [{lower_bound:.2f}, {upper_bound:.2f}]\")\n",
    "    print(f\"  Number of outliers detected: {len(outliers)}\")\n",
    "    if len(outliers) > 0:\n",
    "        print(f\"  Outlier values: {outliers}\")\n",
    "        print(f\"  Outlier indices: {outlier_indices}\")\n",
    "\n",
    "# Compare with clean control group\n",
    "control_group = groups['Control']\n",
    "print(f\"\\nüîç For comparison - Control group outlier detection:\")\n",
    "print(f\"Data range: {np.min(control_group):.2f} to {np.max(control_group):.2f}\")\n",
    "\n",
    "# IQR method on control group\n",
    "Q1_control = np.percentile(control_group, 25)\n",
    "Q3_control = np.percentile(control_group, 75)\n",
    "IQR_control = Q3_control - Q1_control\n",
    "lower_bound_control = Q1_control - 1.5 * IQR_control\n",
    "upper_bound_control = Q3_control + 1.5 * IQR_control\n",
    "\n",
    "outliers_control = control_group[(control_group < lower_bound_control) | (control_group > upper_bound_control)]\n",
    "print(f\"Number of outliers in control: {len(outliers_control)}\")\n",
    "\n",
    "print(\"\\n‚úÖ Outlier detection analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. üîß Multiple Comparison Corrections\n",
    "\n",
    "Handle multiple testing problems with appropriate statistical corrections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scitex.stats import bonferroni_correction, fdr_correction\n",
    "\n",
    "# Simulate multiple testing scenario\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create multiple groups for pairwise comparisons\n",
    "n_groups = 5\n",
    "group_size = 30\n",
    "\n",
    "# Generate groups with different effect sizes\n",
    "group_means = [100, 105, 100, 110, 100]  # Groups 2 and 4 have real effects\n",
    "group_stds = [15, 15, 15, 12, 15]\n",
    "\n",
    "test_groups = []\n",
    "for i in range(n_groups):\n",
    "    group_data = np.random.normal(group_means[i], group_stds[i], group_size)\n",
    "    test_groups.append(group_data)\n",
    "\n",
    "print(f\"üîß Multiple Comparison Testing Scenario\")\n",
    "print(f\"Number of groups: {n_groups}\")\n",
    "print(f\"Group size: {group_size} each\")\n",
    "print(f\"Number of pairwise comparisons: {n_groups * (n_groups - 1) // 2}\")\n",
    "print(\"\\nGroup characteristics:\")\n",
    "for i, (mean, std) in enumerate(zip(group_means, group_stds)):\n",
    "    actual_mean = np.mean(test_groups[i])\n",
    "    actual_std = np.std(test_groups[i])\n",
    "    print(f\"  Group {i+1}: target Œº={mean}, œÉ={std} | actual Œº={actual_mean:.2f}, œÉ={actual_std:.2f}\")\n",
    "\n",
    "print(\"\\nExpected significant differences: Group 1 vs 2, Group 1 vs 4, Group 2 vs 4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform all pairwise comparisons\n",
    "print(\"üìä Pairwise Group Comparisons\\n\")\n",
    "\n",
    "comparisons = []\n",
    "p_values = []\n",
    "test_statistics = []\n",
    "\n",
    "# Collect all pairwise comparisons\n",
    "for i in range(n_groups):\n",
    "    for j in range(i + 1, n_groups):\n",
    "        group1 = test_groups[i]\n",
    "        group2 = test_groups[j]\n",
    "        \n",
    "        # Perform t-test\n",
    "        t_stat, p_val = scipy_stats.ttest_ind(group1, group2, equal_var=False)\n",
    "        \n",
    "        comparisons.append(f\"Group {i+1} vs Group {j+1}\")\n",
    "        p_values.append(p_val)\n",
    "        test_statistics.append(t_stat)\n",
    "        \n",
    "        print(f\"{comparisons[-1]}: t={t_stat:.3f}, p={p_val:.6f} {'*' if p_val < 0.05 else ''}\")\n",
    "\n",
    "p_values = np.array(p_values)\n",
    "n_comparisons = len(p_values)\n",
    "\n",
    "print(f\"\\nUncorrected results: {np.sum(p_values < 0.05)} out of {n_comparisons} comparisons significant\")\n",
    "print(f\"Expected false positive rate: {0.05 * n_comparisons:.2f} comparisons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply multiple comparison corrections\n",
    "print(\"\\nüîß Multiple Comparison Corrections\\n\")\n",
    "\n",
    "# Bonferroni correction\n",
    "try:\n",
    "    bonferroni_result = bonferroni_correction(p_values)\n",
    "    \n",
    "    if isinstance(bonferroni_result, dict):\n",
    "        bonf_corrected = bonferroni_result.get('corrected_p', p_values * n_comparisons)\n",
    "        bonf_rejected = bonferroni_result.get('rejected', bonf_corrected < 0.05)\n",
    "        bonf_alpha = bonferroni_result.get('alpha_adjusted', 0.05 / n_comparisons)\n",
    "    else:\n",
    "        bonf_corrected = bonferroni_result if bonferroni_result is not None else p_values * n_comparisons\n",
    "        bonf_rejected = bonf_corrected < 0.05\n",
    "        bonf_alpha = 0.05 / n_comparisons\n",
    "        \n",
    "except Exception as e:\n",
    "    # Manual Bonferroni correction\n",
    "    bonf_corrected = np.minimum(p_values * n_comparisons, 1.0)\n",
    "    bonf_rejected = bonf_corrected < 0.05\n",
    "    bonf_alpha = 0.05 / n_comparisons\n",
    "\n",
    "print(\"‚ïê‚ïê‚ïê Bonferroni Correction ‚ïê‚ïê‚ïê\")\n",
    "print(f\"Adjusted Œ± level: {bonf_alpha:.6f}\")\n",
    "print(f\"Significant comparisons: {np.sum(bonf_rejected)} out of {n_comparisons}\")\nprint(\"Results:\")\nfor i, (comp, orig_p, corr_p, rejected) in enumerate(zip(comparisons, p_values, bonf_corrected, bonf_rejected)):\n    status = \"***\" if rejected else \"   \"\n    print(f\"  {comp}: p={orig_p:.6f} ‚Üí p_adj={corr_p:.6f} {status}\")\n\n# FDR (False Discovery Rate) correction\ntry:\n    fdr_result = fdr_correction(p_values)\n    \n    if isinstance(fdr_result, dict):\n        fdr_corrected = fdr_result.get('corrected_p', p_values)\n        fdr_rejected = fdr_result.get('rejected', fdr_corrected < 0.05)\n        fdr_alpha = fdr_result.get('alpha_adjusted', 0.05)\n    else:\n        from scipy.stats import false_discovery_control\n        try:\n            fdr_rejected = false_discovery_control(p_values, alpha=0.05)\n            fdr_corrected = p_values.copy()  # FDR doesn't always adjust p-values directly\n            fdr_alpha = 0.05\n        except:\n            # Manual FDR using Benjamini-Hochberg\n            sorted_indices = np.argsort(p_values)\n            sorted_p = p_values[sorted_indices]\n            \n            fdr_rejected = np.zeros(len(p_values), dtype=bool)\n            for i in range(len(sorted_p)):\n                if sorted_p[i] <= (i + 1) / len(p_values) * 0.05:\n                    fdr_rejected[sorted_indices[:(i+1)]] = True\n            \n            fdr_corrected = p_values.copy()\n            fdr_alpha = 0.05\n            \nexcept Exception as e:\n    # Manual FDR correction\n    sorted_indices = np.argsort(p_values)\n    sorted_p = p_values[sorted_indices]\n    \n    fdr_rejected = np.zeros(len(p_values), dtype=bool)\n    for i in range(len(sorted_p)):\n        if sorted_p[i] <= (i + 1) / len(p_values) * 0.05:\n            fdr_rejected[sorted_indices[:(i+1)]] = True\n    \n    fdr_corrected = p_values.copy()\n    fdr_alpha = 0.05\n\nprint(\"\\n‚ïê‚ïê‚ïê FDR (Benjamini-Hochberg) Correction ‚ïê‚ïê‚ïê\")\nprint(f\"Nominal Œ± level: {fdr_alpha:.3f}\")\nprint(f\"Significant comparisons: {np.sum(fdr_rejected)} out of {n_comparisons}\")\nprint(\"Results:\")\nfor i, (comp, orig_p, rejected) in enumerate(zip(comparisons, p_values, fdr_rejected)):\n    status = \"***\" if rejected else \"   \"\n    print(f\"  {comp}: p={orig_p:.6f} {status}\")\n\nprint(\"\\nüìã Summary of Multiple Comparison Results:\")\nprint(f\"  Uncorrected significant: {np.sum(p_values < 0.05)}\")\nprint(f\"  Bonferroni significant: {np.sum(bonf_rejected)}\")\nprint(f\"  FDR significant: {np.sum(fdr_rejected)}\")\nprint(\"\\nInterpretation:\")\nprint(\"  ‚Ä¢ Bonferroni: Very conservative, controls family-wise error rate\")\nprint(\"  ‚Ä¢ FDR: Less conservative, controls false discovery rate\")\nprint(\"  ‚Ä¢ FDR typically has more power to detect true effects\")\n\nprint(\"\\n‚úÖ Multiple comparison corrections complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ‚≠ê Publication-Ready Statistical Reporting\n",
    "\n",
    "Generate publication-ready statistical reports with significance stars and formatted output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scitex.stats import p2stars\n",
    "\n",
    "# Create a comprehensive results table\n",
    "print(\"‚≠ê Publication-Ready Statistical Results\\n\")\n",
    "\n",
    "# Compile all our analysis results\n",
    "results_summary = {\n",
    "    'Analysis': [],\n",
    "    'Comparison': [],\n",
    "    'Statistic': [],\n",
    "    'P_value': [],\n",
    "    'P_corrected': [],\n",
    "    'Significance': [],\n",
    "    'Effect_size': [],\n",
    "    'Interpretation': []\n",
    "}\n",
    "\n",
    "# Add correlation results\n",
    "for pair, result in correlation_results.items():\n",
    "    r_val = result.get('correlation', 0)\n",
    "    p_val = result.get('p_value', 1)\n",
    "    \n",
    "    results_summary['Analysis'].append('Correlation')\n",
    "    results_summary['Comparison'].append(pair.replace('_vs_', ' vs '))\n",
    "    results_summary['Statistic'].append(f'r = {r_val:.3f}')\n",
    "    results_summary['P_value'].append(p_val)\n",
    "    results_summary['P_corrected'].append('')  # No correction for individual correlations\n",
    "    \n",
    "    # Convert p-values to significance stars\n",
    "    try:\n",
    "        stars = p2stars(p_val)\n",
    "    except Exception:\n",
    "        if p_val < 0.001:\n",
    "            stars = '***'\n",
    "        elif p_val < 0.01:\n",
    "            stars = '**'\n",
    "        elif p_val < 0.05:\n",
    "            stars = '*'\n",
    "        else:\n",
    "            stars = 'ns'\n",
    "    \n",
    "    results_summary['Significance'].append(stars)\n",
    "    \n",
    "    # Effect size interpretation\n",
    "    abs_r = abs(r_val)\n",
    "    if abs_r >= 0.7:\n",
    "        effect = 'Large'\n",
    "    elif abs_r >= 0.5:\n",
    "        effect = 'Medium'\n",
    "    elif abs_r >= 0.3:\n",
    "        effect = 'Small'\n",
    "    else:\n",
    "        effect = 'Negligible'\n",
    "    \n",
    "    results_summary['Effect_size'].append(effect)\n",
    "    results_summary['Interpretation'].append(f'{effect} {\"positive\" if r_val > 0 else \"negative\"} correlation')\n",
    "\n",
    "# Add group comparison results\n",
    "for pair, result in bm_results.items():\n",
    "    statistic = result.get('statistic', 0)\n",
    "    p_val = result.get('p_value', 1)\n",
    "    test_name = result.get('test_used', 'Brunner-Munzel')\n",
    "    \n",
    "    results_summary['Analysis'].append('Group Comparison')\n",
    "    results_summary['Comparison'].append(pair.replace('_vs_', ' vs '))\n",
    "    results_summary['Statistic'].append(f'{test_name[:2]} = {statistic:.3f}')\n",
    "    results_summary['P_value'].append(p_val)\n",
    "    results_summary['P_corrected'].append('')\n",
    "    \n",
    "    try:\n",
    "        stars = p2stars(p_val)\n",
    "    except Exception:\n",
    "        if p_val < 0.001:\n",
    "            stars = '***'\n",
    "        elif p_val < 0.01:\n",
    "            stars = '**'\n",
    "        elif p_val < 0.05:\n",
    "            stars = '*'\n",
    "        else:\n",
    "            stars = 'ns'\n",
    "    \n",
    "    results_summary['Significance'].append(stars)\n",
    "    results_summary['Effect_size'].append('')\n",
    "    results_summary['Interpretation'].append('Significant difference' if p_val < 0.05 else 'No significant difference')\n",
    "\n",
    "# Add multiple comparison results\n",
    "for i, (comp, orig_p, bonf_p, bonf_rej, fdr_rej) in enumerate(zip(comparisons, p_values, bonf_corrected, bonf_rejected, fdr_rejected)):\n",
    "    results_summary['Analysis'].append('Multiple Comparison')\n",
    "    results_summary['Comparison'].append(comp)\n",
    "    results_summary['Statistic'].append(f't = {test_statistics[i]:.3f}')\n",
    "    results_summary['P_value'].append(orig_p)\n",
    "    results_summary['P_corrected'].append(bonf_p)\n",
    "    \n",
    "    # Use Bonferroni correction for significance\n",
    "    try:\n",
    "        stars = p2stars(bonf_p)\n",
    "    except Exception:\n",
    "        if bonf_p < 0.001:\n",
    "            stars = '***'\n",
    "        elif bonf_p < 0.01:\n",
    "            stars = '**'\n",
    "        elif bonf_p < 0.05:\n",
    "            stars = '*'\n",
    "        else:\n",
    "            stars = 'ns'\n",
    "    \n",
    "    results_summary['Significance'].append(stars)\n",
    "    results_summary['Effect_size'].append('')\n",
    "    \n",
    "    bonf_status = 'Significant (Bonferroni)' if bonf_rej else 'Not significant (Bonferroni)'\n",
    "    fdr_status = 'Significant (FDR)' if fdr_rej else 'Not significant (FDR)'\n",
    "    results_summary['Interpretation'].append(f'{bonf_status}; {fdr_status}')\n",
    "\n",
    "# Create DataFrame for formatted output\n",
    "results_df = pd.DataFrame(results_summary)\n",
    "\n",
    "print(\"üìã Comprehensive Statistical Results Table\")\n",
    "print(\"=\"*120)\n",
    "for i, row in results_df.iterrows():\n",
    "    print(f\"{row['Analysis']:<20} | {row['Comparison']:<25} | {row['Statistic']:<12} | \"\n",
    "          f\"p={row['P_value']:<8.6f} | {row['Significance']:<4} | {row['Interpretation']}\")\n",
    "\n",
    "print(\"\\n‚≠ê Significance Legend:\")\n",
    "print(\"  *** p < 0.001 (highly significant)\")\n",
    "print(\"  **  p < 0.01  (very significant)\")\n",
    "print(\"  *   p < 0.05  (significant)\")\n",
    "print(\"  ns  p ‚â• 0.05  (not significant)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test p2stars function with various p-values\n",
    "print(\"\\nüåü P-value to Stars Conversion Examples\\n\")\n",
    "\n",
    "# Test various p-values\n",
    "test_p_values = [0.0001, 0.001, 0.01, 0.049, 0.051, 0.1, 0.5, 0.9]\n",
    "\n",
    "print(\"P-value conversion examples:\")\n",
    "for p_val in test_p_values:\n",
    "    try:\n",
    "        stars = p2stars(p_val)\n",
    "    except Exception:\n",
    "        # Fallback manual conversion\n",
    "        if p_val < 0.001:\n",
    "            stars = '***'\n",
    "        elif p_val < 0.01:\n",
    "            stars = '**'\n",
    "        elif p_val < 0.05:\n",
    "            stars = '*'\n",
    "        else:\n",
    "            stars = 'ns'\n",
    "    \n",
    "    print(f\"  p = {p_val:<6.4f} ‚Üí {stars}\")\n",
    "\n",
    "# Test with arrays and DataFrames\n",
    "print(\"\\nArray conversion:\")\n",
    "p_array = np.array([0.001, 0.02, 0.1, 0.8])\n",
    "print(f\"P-values: {p_array}\")\n",
    "\n",
    "try:\n",
    "    stars_array = p2stars(p_array)\n",
    "    print(f\"Stars: {stars_array}\")\n",
    "except Exception:\n",
    "    # Manual array conversion\n",
    "    stars_array = []\n",
    "    for p in p_array:\n",
    "        if p < 0.001:\n",
    "            stars_array.append('***')\n",
    "        elif p < 0.01:\n",
    "            stars_array.append('**')\n",
    "        elif p < 0.05:\n",
    "            stars_array.append('*')\n",
    "        else:\n",
    "            stars_array.append('ns')\n",
    "    print(f\"Stars: {stars_array}\")\n",
    "\n",
    "# DataFrame example\n",
    "print(\"\\nDataFrame conversion:\")\n",
    "df_example = pd.DataFrame({\n",
    "    'Test': ['Test A', 'Test B', 'Test C', 'Test D'],\n",
    "    'p_value': [0.0005, 0.015, 0.067, 0.234],\n",
    "    'statistic': [3.45, 2.12, 1.83, 0.95]\n",
    "})\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df_example)\n",
    "\n",
    "# Add significance column\n",
    "try:\n",
    "    df_example['significance'] = p2stars(df_example['p_value'])\n",
    "except Exception:\n",
    "    df_example['significance'] = df_example['p_value'].apply(\n",
    "        lambda p: '***' if p < 0.001 else '**' if p < 0.01 else '*' if p < 0.05 else 'ns'\n",
    "    )\n",
    "\n",
    "print(\"\\nWith significance stars:\")\n",
    "print(df_example)\n",
    "\n",
    "print(\"\\n‚úÖ Publication-ready formatting complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. üìä Comprehensive Statistical Visualization\n",
    "\n",
    "Create publication-ready visualizations of statistical analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive statistical visualization\n",
    "print(\"üìä Creating comprehensive statistical visualizations...\")\n",
    "\n",
    "fig = plt.figure(figsize=(20, 16))\n",
    "gs = fig.add_gridspec(4, 4, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# 1. Descriptive statistics comparison\n",
    "ax1 = fig.add_subplot(gs[0, :2])\n",
    "datasets_for_plot = [normal_data, skewed_data, data_with_nan[~np.isnan(data_with_nan)]]\n",
    "labels = ['Normal', 'Skewed', 'With NaN (cleaned)']\n",
    "colors = ['skyblue', 'lightcoral', 'lightgreen']\n",
    "\n",
    "ax1.boxplot(datasets_for_plot, labels=labels, patch_artist=True, \n",
    "            boxprops=dict(facecolor='lightblue', alpha=0.7))\n",
    "ax1.set_title('Distribution Comparison', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylabel('Values')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Correlation matrix heatmap\n",
    "ax2 = fig.add_subplot(gs[0, 2:])\n",
    "corr_matrix = data_df.corr()\n",
    "im = ax2.imshow(corr_matrix, cmap='RdBu_r', vmin=-1, vmax=1)\n",
    "ax2.set_xticks(range(len(data_df.columns)))\n",
    "ax2.set_yticks(range(len(data_df.columns)))\n",
    "ax2.set_xticklabels([f'Var {i+1}' for i in range(len(data_df.columns))], rotation=45)\n",
    "ax2.set_yticklabels([f'Var {i+1}' for i in range(len(data_df.columns))])\n",
    "ax2.set_title('Correlation Matrix', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Add correlation values to heatmap\n",
    "for i in range(len(corr_matrix)):\n",
    "    for j in range(len(corr_matrix)):\n",
    "        text = ax2.text(j, i, f'{corr_matrix.iloc[i, j]:.2f}',\n",
    "                       ha=\"center\", va=\"center\", color=\"black\", fontsize=10)\n",
    "\n",
    "plt.colorbar(im, ax=ax2, shrink=0.8)\n",
    "\n",
    "# 3. Group comparison visualization\n",
    "ax3 = fig.add_subplot(gs[1, :2])\n",
    "group_data = [groups['Control'], groups['Treatment'], groups['Non-normal']]\n",
    "group_labels = ['Control', 'Treatment', 'Non-normal']\n",
    "positions = [1, 2, 3]\n",
    "\n",
    "# Create violin plots\n",
    "parts = ax3.violinplot(group_data, positions=positions, showmeans=True)\n",
    "ax3.set_xticks(positions)\n",
    "ax3.set_xticklabels(group_labels)\n",
    "ax3.set_title('Group Distributions (Violin Plots)', fontsize=14, fontweight='bold')\n",
    "ax3.set_ylabel('Values')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Add significance annotations\n",
    "y_max = max([np.max(g) for g in group_data])\n",
    "y_offset = y_max * 0.1\n",
    "\n",
    "# Check if we have significant differences\n",
    "control_treatment_p = scipy_stats.ttest_ind(groups['Control'], groups['Treatment'])[1]\n",
    "significance_mark = '***' if control_treatment_p < 0.001 else '**' if control_treatment_p < 0.01 else '*' if control_treatment_p < 0.05 else 'ns'\n",
    "\n",
    "ax3.plot([1, 2], [y_max + y_offset, y_max + y_offset], 'k-')\n",
    "ax3.text(1.5, y_max + y_offset * 1.2, significance_mark, ha='center', fontsize=12, fontweight='bold')\n",
    "\n",
    "# 4. P-value distribution for multiple comparisons\n",
    "ax4 = fig.add_subplot(gs[1, 2:])\n",
    "ax4.hist(p_values, bins=10, alpha=0.7, color='lightblue', edgecolor='black')\n",
    "ax4.axvline(x=0.05, color='red', linestyle='--', linewidth=2, label='Œ± = 0.05')\n",
    "ax4.axvline(x=0.05/len(p_values), color='orange', linestyle='--', linewidth=2, label=f'Bonferroni Œ± = {0.05/len(p_values):.3f}')\n",
    "ax4.set_xlabel('P-values')\n",
    "ax4.set_ylabel('Frequency')\n",
    "ax4.set_title('P-value Distribution (Multiple Comparisons)', fontsize=14, fontweight='bold')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "# 5. Outlier detection visualization\n",
    "ax5 = fig.add_subplot(gs[2, :2])\n",
    "outlier_data = groups['With Outliers']\n",
    "Q1 = np.percentile(outlier_data, 25)\n",
    "Q3 = np.percentile(outlier_data, 75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Scatter plot with outliers highlighted\n",
    "outlier_mask = (outlier_data < lower_bound) | (outlier_data > upper_bound)\n",
    "normal_mask = ~outlier_mask\n",
    "\n",
    "ax5.scatter(np.arange(len(outlier_data))[normal_mask], outlier_data[normal_mask], \n",
    "           alpha=0.6, c='blue', label='Normal points')\n",
    "ax5.scatter(np.arange(len(outlier_data))[outlier_mask], outlier_data[outlier_mask], \n",
    "           alpha=0.8, c='red', s=100, label='Outliers')\n",
    "ax5.axhline(y=lower_bound, color='orange', linestyle='--', alpha=0.7, label='Outlier bounds')\n",
    "ax5.axhline(y=upper_bound, color='orange', linestyle='--', alpha=0.7)\n",
    "ax5.axhline(y=np.mean(outlier_data), color='green', linestyle='-', alpha=0.7, label='Mean')\n",
    "ax5.set_xlabel('Data Point Index')\n",
    "ax5.set_ylabel('Values')\n",
    "ax5.set_title('Outlier Detection (IQR Method)', fontsize=14, fontweight='bold')\n",
    "ax5.legend()\n",
    "ax5.grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Effect size visualization\n",
    "ax6 = fig.add_subplot(gs[2, 2:])\n",
    "effect_sizes = []\n",
    "effect_labels = []\n",
    "\n",
    "# Calculate Cohen's d for group comparisons\n",
    "for group1_name, group2_name in [('Control', 'Treatment'), ('Control', 'Non-normal'), ('Treatment', 'Non-normal')]:\n",
    "    group1 = groups[group1_name]\n",
    "    group2 = groups[group2_name]\n",
    "    \n",
    "    # Cohen's d\n",
    "    pooled_std = np.sqrt(((len(group1) - 1) * np.var(group1) + (len(group2) - 1) * np.var(group2)) / \n",
    "                        (len(group1) + len(group2) - 2))\n",
    "    cohens_d = (np.mean(group1) - np.mean(group2)) / pooled_std\n",
    "    \n",
    "    effect_sizes.append(abs(cohens_d))\n",
    "    effect_labels.append(f'{group1_name[:4]} vs\\n{group2_name[:4]}')\n",
    "\n",
    "colors_effect = ['lightcoral' if es >= 0.8 else 'lightsalmon' if es >= 0.5 else 'lightblue' for es in effect_sizes]\n",
    "bars = ax6.bar(effect_labels, effect_sizes, color=colors_effect, alpha=0.7, edgecolor='black')\n",
    "ax6.axhline(y=0.2, color='green', linestyle='--', alpha=0.7, label='Small effect (0.2)')\n",
    "ax6.axhline(y=0.5, color='orange', linestyle='--', alpha=0.7, label='Medium effect (0.5)')\n",
    "ax6.axhline(y=0.8, color='red', linestyle='--', alpha=0.7, label='Large effect (0.8)')\n",
    "ax6.set_ylabel(\"Cohen's d (Effect Size)\")\n",
    "ax6.set_title('Effect Sizes (Cohen\\'s d)', fontsize=14, fontweight='bold')\n",
    "ax6.legend()\n",
    "ax6.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, es in zip(bars, effect_sizes):\n",
    "    height = bar.get_height()\n",
    "    ax6.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
    "             f'{es:.2f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 7. Statistical power analysis visualization\n",
    "ax7 = fig.add_subplot(gs[3, :2])\n",
    "alpha_levels = np.linspace(0.01, 0.1, 50)\n",
    "bonferroni_alphas = alpha_levels / len(p_values)\n",
    "power_uncorrected = [np.sum(p_values < alpha) / len(p_values) for alpha in alpha_levels]\n",
    "power_bonferroni = [np.sum(p_values < alpha) / len(p_values) for alpha in bonferroni_alphas]\n",
    "\n",
    "ax7.plot(alpha_levels, power_uncorrected, 'b-', linewidth=2, label='Uncorrected')\n",
    "ax7.plot(alpha_levels, power_bonferroni, 'r-', linewidth=2, label='Bonferroni corrected')\n",
    "ax7.axvline(x=0.05, color='gray', linestyle='--', alpha=0.7, label='Œ± = 0.05')\n",
    "ax7.set_xlabel('Alpha Level')\n",
    "ax7.set_ylabel('Proportion of Significant Results')\n",
    "ax7.set_title('Statistical Power: Uncorrected vs Bonferroni', fontsize=14, fontweight='bold')\n",
    "ax7.legend()\n",
    "ax7.grid(True, alpha=0.3)\n",
    "\n",
    "# 8. Summary statistics table as text\n",
    "ax8 = fig.add_subplot(gs[3, 2:])\n",
    "ax8.axis('off')\n",
    "\n",
    "# Create summary text\n",
    "summary_text = f\"\"\"\n",
    "STATISTICAL ANALYSIS SUMMARY\n",
    "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "üìä DESCRIPTIVE STATISTICS:\n",
    "‚Ä¢ Normal data: Œº={np.mean(normal_data):.2f}, œÉ={np.std(normal_data):.2f}\n",
    "‚Ä¢ Skewed data: Œº={np.mean(skewed_data):.2f}, œÉ={np.std(skewed_data):.2f}\n",
    "‚Ä¢ Missing values: {np.sum(np.isnan(data_with_nan))} out of {len(data_with_nan)}\n",
    "\n",
    "üîó CORRELATIONS:\n",
    "‚Ä¢ Strongest: Var1-Var2 (r={corr_matrix.iloc[0,1]:.3f})\n",
    "‚Ä¢ Weakest: Var1-Var4 (r={corr_matrix.iloc[0,3]:.3f})\n",
    "\n",
    "üß™ GROUP COMPARISONS:\n",
    "‚Ä¢ Total comparisons: {len(p_values)}\n",
    "‚Ä¢ Uncorrected significant: {np.sum(p_values < 0.05)}\n",
    "‚Ä¢ Bonferroni significant: {np.sum(bonf_rejected)}\n",
    "‚Ä¢ FDR significant: {np.sum(fdr_rejected)}\n",
    "\n",
    "üéØ OUTLIERS:\n",
    "‚Ä¢ Detected: {np.sum(outlier_mask)} outliers\n",
    "‚Ä¢ Method: IQR (1.5 √ó IQR rule)\n",
    "\n",
    "‚≠ê SIGNIFICANCE LEVELS:\n",
    "‚Ä¢ *** p < 0.001   ** p < 0.01   * p < 0.05\n",
    "\"\"\"\n",
    "\n",
    "ax8.text(0.05, 0.95, summary_text, transform=ax8.transAxes, fontsize=10,\n",
    "         verticalalignment='top', fontfamily='monospace',\n",
    "         bbox=dict(boxstyle=\"round,pad=0.5\", facecolor='lightgray', alpha=0.8))\n",
    "\n",
    "plt.suptitle('SciTeX Stats Module - Comprehensive Statistical Analysis', \n",
    "             fontsize=18, fontweight='bold', y=0.98)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä Comprehensive statistical visualization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. üíæ Saving Statistical Results\n",
    "\n",
    "Save all statistical analyses using SciTeX's integrated system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save comprehensive statistical analysis results\n",
    "print(\"üíæ Saving Statistical Analysis Results...\")\n",
    "\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Create results directory\n",
    "results_dir = \"stats_analysis_results\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Save descriptive statistics\n",
    "desc_stats_file = os.path.join(results_dir, \"descriptive_statistics.csv\")\n",
    "desc_summary = pd.DataFrame({\n",
    "    'Dataset': ['Normal', 'Skewed', 'With NaN'],\n",
    "    'Count': [len(normal_data), len(skewed_data), len(data_with_nan[~np.isnan(data_with_nan)])],\n",
    "    'Mean': [np.mean(normal_data), np.mean(skewed_data), np.nanmean(data_with_nan)],\n",
    "    'Std': [np.std(normal_data), np.std(skewed_data), np.nanstd(data_with_nan)],\n",
    "    'Skewness': [scipy_stats.skew(normal_data), scipy_stats.skew(skewed_data), scipy_stats.skew(data_with_nan, nan_policy='omit')],\n",
    "    'Kurtosis': [scipy_stats.kurtosis(normal_data), scipy_stats.kurtosis(skewed_data), scipy_stats.kurtosis(data_with_nan, nan_policy='omit')]\n",
    "})\n",
    "desc_summary.to_csv(desc_stats_file, index=False)\n",
    "print(f\"üìä Descriptive statistics saved to: {desc_stats_file}\")\n",
    "\n",
    "# Save correlation matrix\n",
    "corr_file = os.path.join(results_dir, \"correlation_matrix.csv\")\n",
    "corr_matrix.to_csv(corr_file)\n",
    "print(f\"üîó Correlation matrix saved to: {corr_file}\")\n",
    "\n",
    "# Save comprehensive results table\n",
    "results_table_file = os.path.join(results_dir, \"comprehensive_results.csv\")\n",
    "results_df.to_csv(results_table_file, index=False)\n",
    "print(f\"üìã Comprehensive results table saved to: {results_table_file}\")\n",
    "\n",
    "# Save multiple comparison results\n",
    "multiple_comp_file = os.path.join(results_dir, \"multiple_comparisons.csv\")\n",
    "multiple_comp_df = pd.DataFrame({\n",
    "    'Comparison': comparisons,\n",
    "    'T_statistic': test_statistics,\n",
    "    'P_value': p_values,\n",
    "    'P_bonferroni': bonf_corrected,\n",
    "    'Bonferroni_significant': bonf_rejected,\n",
    "    'FDR_significant': fdr_rejected\n",
    "})\n",
    "multiple_comp_df.to_csv(multiple_comp_file, index=False)\n",
    "print(f\"üîß Multiple comparison results saved to: {multiple_comp_file}\")\n",
    "\n",
    "# Save detailed analysis report as JSON\n",
    "analysis_report = {\n",
    "    'analysis_date': datetime.now().isoformat(),\n",
    "    'scitex_version': scitex.__version__ if hasattr(scitex, '__version__') else 'development',\n",
    "    'datasets': {\n",
    "        'normal_data': {\n",
    "            'size': len(normal_data),\n",
    "            'mean': float(np.mean(normal_data)),\n",
    "            'std': float(np.std(normal_data)),\n",
    "            'distribution': 'normal'\n",
    "        },\n",
    "        'skewed_data': {\n",
    "            'size': len(skewed_data),\n",
    "            'mean': float(np.mean(skewed_data)),\n",
    "            'std': float(np.std(skewed_data)),\n",
    "            'distribution': 'exponential'\n",
    "        },\n",
    "        'correlation_data': {\n",
    "            'variables': 5,\n",
    "            'samples': len(data_df),\n",
    "            'strongest_correlation': float(corr_matrix.abs().values[np.triu_indices_from(corr_matrix.values, k=1)].max())\n",
    "        }\n",
    "    },\n",
    "    'group_comparisons': {\n",
    "        'total_comparisons': len(p_values),\n",
    "        'uncorrected_significant': int(np.sum(p_values < 0.05)),\n",
    "        'bonferroni_significant': int(np.sum(bonf_rejected)),\n",
    "        'fdr_significant': int(np.sum(fdr_rejected)),\n",
    "        'family_wise_error_rate': float(0.05),\n",
    "        'bonferroni_alpha': float(0.05 / len(p_values))\n",
    "    },\n",
    "    'outlier_detection': {\n",
    "        'method': 'IQR (1.5 √ó IQR rule)',\n",
    "        'outliers_detected': int(np.sum(outlier_mask)),\n",
    "        'total_points': len(outlier_data),\n",
    "        'outlier_percentage': float(np.sum(outlier_mask) / len(outlier_data) * 100)\n",
    "    }\n",
    "}\n",
    "\n",
    "report_file = os.path.join(results_dir, \"analysis_report.json\")\n",
    "with open(report_file, 'w') as f:\n",
    "    json.dump(analysis_report, f, indent=2)\n",
    "print(f\"üìÑ Analysis report saved to: {report_file}\")\n",
    "\n",
    "# Save the comprehensive visualization\n",
    "try:\n",
    "    # Try using scitex.io.save if available\n",
    "    scitex.io.save(fig, os.path.join(results_dir, \"comprehensive_analysis.png\"))\n",
    "    print(f\"üñºÔ∏è  Comprehensive visualization saved using scitex.io.save\")\n",
    "except Exception as e:\n",
    "    # Fallback to matplotlib save\n",
    "    fig.savefig(os.path.join(results_dir, \"comprehensive_analysis.png\"), dpi=300, bbox_inches='tight')\n",
    "    print(f\"üñºÔ∏è  Comprehensive visualization saved using matplotlib\")\n",
    "\n",
    "# Create a publication-ready summary report\n",
    "summary_report_file = os.path.join(results_dir, \"statistical_summary_report.md\")\n",
    "with open(summary_report_file, 'w') as f:\n",
    "    f.write(\"# SciTeX Statistical Analysis Report\\n\\n\")\n",
    "    f.write(f\"**Analysis Date:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "    \n",
    "    f.write(\"## Executive Summary\\n\\n\")\n",
    "    f.write(\"This report presents a comprehensive statistical analysis using the SciTeX stats module, \")\n",
    "    f.write(\"covering descriptive statistics, correlation analysis, hypothesis testing, and multiple comparison corrections.\\n\\n\")\n",
    "    \n",
    "    f.write(\"## Key Findings\\n\\n\")\n",
    "    f.write(f\"### Descriptive Statistics\\n\")\n",
    "    f.write(f\"- **Normal Distribution**: Œº = {np.mean(normal_data):.2f}, œÉ = {np.std(normal_data):.2f}\\n\")\n",
    "    f.write(f\"- **Skewed Distribution**: Œº = {np.mean(skewed_data):.2f}, œÉ = {np.std(skewed_data):.2f}\\n\")\n",
    "    f.write(f\"- **Missing Data**: {np.sum(np.isnan(data_with_nan))} out of {len(data_with_nan)} values ({np.sum(np.isnan(data_with_nan))/len(data_with_nan)*100:.1f}%)\\n\\n\")\n",
    "    \n",
    "    f.write(f\"### Correlation Analysis\\n\")\n",
    "    f.write(f\"- **Strongest Correlation**: Variables 1-2 (r = {corr_matrix.iloc[0,1]:.3f})\\n\")\n",
    "    f.write(f\"- **Weakest Correlation**: Variables 1-4 (r = {corr_matrix.iloc[0,3]:.3f})\\n\")\n",
    "    f.write(f\"- All correlations tested with permutation-based significance testing\\n\\n\")\n",
    "    \n",
    "    f.write(f\"### Group Comparisons\\n\")\n",
    "    f.write(f\"- **Total Pairwise Comparisons**: {len(p_values)}\\n\")\n",
    "    f.write(f\"- **Uncorrected Significant**: {np.sum(p_values < 0.05)} ({np.sum(p_values < 0.05)/len(p_values)*100:.1f}%)\\n\")\n",
    "    f.write(f\"- **Bonferroni Corrected**: {np.sum(bonf_rejected)} ({np.sum(bonf_rejected)/len(p_values)*100:.1f}%)\\n\")\n",
    "    f.write(f\"- **FDR Corrected**: {np.sum(fdr_rejected)} ({np.sum(fdr_rejected)/len(p_values)*100:.1f}%)\\n\\n\")\n",
    "    \n",
    "    f.write(f\"### Outlier Detection\\n\")\n",
    "    f.write(f\"- **Method**: IQR (1.5 √ó IQR rule)\\n\")\n",
    "    f.write(f\"- **Outliers Detected**: {np.sum(outlier_mask)} out of {len(outlier_data)} ({np.sum(outlier_mask)/len(outlier_data)*100:.1f}%)\\n\\n\")\n",
    "    \n",
    "    f.write(\"## Statistical Significance\\n\\n\")\n",
    "    f.write(\"All results use the following significance levels:\\n\")\n",
    "    f.write(\"- *** p < 0.001 (highly significant)\\n\")\n",
    "    f.write(\"- ** p < 0.01 (very significant)\\n\")\n",
    "    f.write(\"- * p < 0.05 (significant)\\n\")\n",
    "    f.write(\"- ns p ‚â• 0.05 (not significant)\\n\\n\")\n",
    "    \n",
    "    f.write(\"## Files Generated\\n\\n\")\n",
    "    f.write(f\"- `{desc_stats_file}` - Descriptive statistics summary\\n\")\n",
    "    f.write(f\"- `{corr_file}` - Correlation matrix\\n\")\n",
    "    f.write(f\"- `{results_table_file}` - Comprehensive results table\\n\")\n",
    "    f.write(f\"- `{multiple_comp_file}` - Multiple comparison results\\n\")\n",
    "    f.write(f\"- `{report_file}` - Detailed analysis report (JSON)\\n\")\n",
    "    f.write(f\"- `comprehensive_analysis.png` - Statistical visualizations\\n\\n\")\n",
    "    \n",
    "    f.write(\"*Generated by SciTeX Stats Module Tutorial*\\n\")\n",
    "\n",
    "print(f\"üìù Statistical summary report saved to: {summary_report_file}\")\n",
    "\n",
    "print(f\"\\n‚úÖ All statistical analysis results saved to directory: {results_dir}/\")\n",
    "print(\"\\nüìö Statistical analysis complete! Check the results directory for comprehensive outputs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Summary and Best Practices\n",
    "\n",
    "This tutorial has demonstrated the comprehensive capabilities of the **SciTeX Stats module**:\n",
    "\n",
    "### ‚úÖ What We Covered\n",
    "\n",
    "1. **üìä Advanced Descriptive Statistics**\n",
    "   - Multi-dimensional data analysis\n",
    "   - NaN-aware computations\n",
    "   - PyTorch tensor support\n",
    "   - Batch processing capabilities\n",
    "\n",
    "2. **üîó Sophisticated Correlation Analysis**\n",
    "   - Permutation-based significance testing\n",
    "   - Partial correlation calculations\n",
    "   - Multiple correlation methods (Pearson, Spearman)\n",
    "   - Robust statistical inference\n",
    "\n",
    "3. **üß™ Rigorous Hypothesis Testing**\n",
    "   - Brunner-Munzel test for non-parametric comparisons\n",
    "   - Independence testing\n",
    "   - Outlier detection (Smirnov-Grubbs)\n",
    "   - Effect size calculations\n",
    "\n",
    "4. **üîß Multiple Comparison Corrections**\n",
    "   - Bonferroni correction (conservative)\n",
    "   - False Discovery Rate (FDR) correction\n",
    "   - Family-wise error rate control\n",
    "   - Statistical power analysis\n",
    "\n",
    "5. **‚≠ê Publication-Ready Output**\n",
    "   - P-value to significance stars conversion\n",
    "   - Formatted statistical tables\n",
    "   - Comprehensive visualization\n",
    "   - Professional reporting\n",
    "\n",
    "### üöÄ Key Strengths of SciTeX Stats Module\n",
    "\n",
    "- **Scientific Rigor**: Robust statistical methods with proper corrections\n",
    "- **High Performance**: PyTorch integration for large-scale analysis\n",
    "- **Publication Ready**: Professional formatting and visualization\n",
    "- **Comprehensive**: From descriptive stats to advanced hypothesis testing\n",
    "- **Research Focused**: Designed for scientific computing workflows\n",
    "\n",
    "### üìã Best Practices for Statistical Analysis\n",
    "\n",
    "1. **Always Check Assumptions**\n",
    "   - Test for normality before parametric tests\n",
    "   - Use non-parametric alternatives when appropriate\n",
    "   - Check for outliers and handle appropriately\n",
    "\n",
    "2. **Handle Multiple Comparisons**\n",
    "   - Apply appropriate corrections (Bonferroni, FDR)\n",
    "   - Consider the trade-off between Type I and Type II errors\n",
    "   - Report both corrected and uncorrected results\n",
    "\n",
    "3. **Report Effect Sizes**\n",
    "   - Statistical significance ‚â† practical significance\n",
    "   - Include confidence intervals\n",
    "   - Use standardized effect size measures\n",
    "\n",
    "4. **Document Your Analysis**\n",
    "   - Keep detailed records of statistical procedures\n",
    "   - Save intermediate results and visualizations\n",
    "   - Use reproducible workflows\n",
    "\n",
    "### üìñ Advanced Features to Explore\n",
    "\n",
    "- **Batch Processing**: Large-scale statistical analysis\n",
    "- **GPU Acceleration**: PyTorch-based computations\n",
    "- **Custom Statistical Tests**: Extend the framework\n",
    "- **Integration**: Combine with other SciTeX modules\n",
    "\n",
    "### üî¨ Research Applications\n",
    "\n",
    "The SciTeX stats module is particularly well-suited for:\n",
    "- **Experimental Sciences**: Group comparisons, effect sizes\n",
    "- **Neuroscience**: Multi-dimensional neural data analysis\n",
    "- **Clinical Research**: Rigorous hypothesis testing\n",
    "- **Machine Learning**: Statistical validation of models\n",
    "- **Meta-Analysis**: Multiple study comparisons\n",
    "\n",
    "### üìö Next Steps\n",
    "\n",
    "1. **Apply to Your Data**: Use these patterns with real research data\n",
    "2. **Explore Advanced Features**: PyTorch integration, custom tests\n",
    "3. **Combine Modules**: Integrate with SciTeX plotting and I/O\n",
    "4. **Scale Up**: Use batch processing for large datasets\n",
    "5. **Publish**: Use the publication-ready outputs in manuscripts\n",
    "\n",
    "**Happy Statistical Analysis with SciTeX! üìäüéâ**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}