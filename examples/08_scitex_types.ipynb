{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SciTeX Type Handling Utilities Tutorial\n",
    "\n",
    "This comprehensive notebook demonstrates the SciTeX types module, covering type definitions, type checking utilities, and validation functions for scientific computing workflows.\n",
    "\n",
    "## Features Covered\n",
    "\n",
    "### Type Definitions\n",
    "* ArrayLike - Union type for array-like objects\n",
    "* ColorLike - Union type for color representations\n",
    "\n",
    "### Type Checking Functions\n",
    "* is_array_like - Check if object is array-like\n",
    "* is_listed_X - Check if list contains specific types\n",
    "* is_list_of_type - Conventional alias for type checking\n",
    "\n",
    "### Applications\n",
    "* Input validation for scientific functions\n",
    "* Type safety in data processing pipelines\n",
    "* Flexible parameter handling\n",
    "* Cross-library compatibility checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5e0f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect notebook name for output directory\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Get notebook name (for papermill compatibility)\n",
    "notebook_name = \"08_scitex_types\"\n",
    "if 'PAPERMILL_NOTEBOOK_NAME' in os.environ:\n",
    "    notebook_name = Path(os.environ['PAPERMILL_NOTEBOOK_NAME']).stem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "import scitex\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import time\n",
    "from typing import List, Tuple, Union, Any\n",
    "\n",
    "# Try to import optional dependencies\n",
    "try:\n",
    "    import torch\n",
    "    TORCH_AVAILABLE = True\n",
    "except ImportError:\n",
    "    TORCH_AVAILABLE = False\n",
    "    print(\"PyTorch not available - some examples will be skipped\")\n",
    "\n",
    "try:\n",
    "    import xarray as xr\n",
    "    XARRAY_AVAILABLE = True\n",
    "except ImportError:\n",
    "    XARRAY_AVAILABLE = False\n",
    "    print(\"XArray not available - some examples will be skipped\")\n",
    "\n",
    "print(\"SciTeX Type Handling Utilities Tutorial - Ready to begin!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: ArrayLike Type and Validation\n",
    "\n",
    "### 1.1 Understanding ArrayLike\n",
    "\n",
    "The ArrayLike type union allows functions to accept various array-like objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create different types of array-like objects\n",
    "test_objects = {\n",
    "    'python_list': [1, 2, 3, 4, 5],\n",
    "    'python_tuple': (1, 2, 3, 4, 5),\n",
    "    'numpy_array': np.array([1, 2, 3, 4, 5]),\n",
    "    'pandas_series': pd.Series([1, 2, 3, 4, 5]),\n",
    "    'pandas_dataframe': pd.DataFrame({'col1': [1, 2, 3], 'col2': [4, 5, 6]}),\n",
    "    'nested_list': [[1, 2], [3, 4], [5, 6]],\n",
    "    'string': \"not an array\",\n",
    "    'integer': 42,\n",
    "    'float': 3.14,\n",
    "    'dictionary': {'a': 1, 'b': 2}\n",
    "}\n",
    "\n",
    "# Add optional objects if available\n",
    "if TORCH_AVAILABLE:\n",
    "    test_objects['torch_tensor'] = torch.tensor([1, 2, 3, 4, 5])\n",
    "\n",
    "if XARRAY_AVAILABLE:\n",
    "    test_objects['xarray_dataarray'] = xr.DataArray([1, 2, 3, 4, 5], dims=['x'])\n",
    "\n",
    "# Test is_array_like function\n",
    "print(\"Testing is_array_like function:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "array_like_results = {}\n",
    "for name, obj in test_objects.items():\n",
    "    is_array_like = scitex.types.is_array_like(obj)\n",
    "    array_like_results[name] = is_array_like\n",
    "    status = \"✓ Array-like\" if is_array_like else \"✗ Not array-like\"\n",
    "    obj_type = type(obj).__name__\n",
    "    print(f\"{name:20} ({obj_type:15}): {status}\")\n",
    "\n",
    "# Summary\n",
    "array_like_count = sum(array_like_results.values())\n",
    "total_count = len(array_like_results)\n",
    "print(f\"\\nSummary: {array_like_count}/{total_count} objects are array-like\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Array-like Operations and Compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate operations with different array-like types\n",
    "def process_array_like(data, operation=\"sum\"):\n",
    "    \"\"\"\n",
    "    Process array-like data with type checking.\n",
    "    \n",
    "    Args:\n",
    "        data: ArrayLike object\n",
    "        operation: Operation to perform ('sum', 'mean', 'max', 'min')\n",
    "    \n",
    "    Returns:\n",
    "        Result of operation or None if data is not array-like\n",
    "    \"\"\"\n",
    "    if not scitex.types.is_array_like(data):\n",
    "        print(f\"Error: Input is not array-like (type: {type(data).__name__})\")\n",
    "        return None\n",
    "    \n",
    "    # Convert to numpy array for consistent operations\n",
    "    try:\n",
    "        if isinstance(data, pd.DataFrame):\n",
    "            # For DataFrames, operate on all numeric columns\n",
    "            numeric_data = data.select_dtypes(include=[np.number])\n",
    "            if numeric_data.empty:\n",
    "                print(\"Error: DataFrame contains no numeric data\")\n",
    "                return None\n",
    "            data_array = numeric_data.values\n",
    "        elif isinstance(data, pd.Series):\n",
    "            data_array = data.values\n",
    "        elif TORCH_AVAILABLE and torch.is_tensor(data):\n",
    "            data_array = data.numpy()\n",
    "        elif XARRAY_AVAILABLE and isinstance(data, xr.DataArray):\n",
    "            data_array = data.values\n",
    "        else:\n",
    "            data_array = np.array(data)\n",
    "        \n",
    "        # Perform operation\n",
    "        if operation == \"sum\":\n",
    "            result = np.sum(data_array)\n",
    "        elif operation == \"mean\":\n",
    "            result = np.mean(data_array)\n",
    "        elif operation == \"max\":\n",
    "            result = np.max(data_array)\n",
    "        elif operation == \"min\":\n",
    "            result = np.min(data_array)\n",
    "        else:\n",
    "            result = f\"Unknown operation: {operation}\"\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing data: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test the function with different array-like objects\n",
    "print(\"Testing array-like processing function:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "operations = ['sum', 'mean', 'max', 'min']\n",
    "processing_results = {}\n",
    "\n",
    "# Select only array-like objects for processing\n",
    "array_like_objects = {name: obj for name, obj in test_objects.items() \n",
    "                     if array_like_results[name]}\n",
    "\n",
    "for op in operations:\n",
    "    print(f\"\\nOperation: {op.upper()}\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    operation_results = {}\n",
    "    for name, obj in array_like_objects.items():\n",
    "        result = process_array_like(obj, op)\n",
    "        operation_results[name] = result\n",
    "        \n",
    "        if result is not None:\n",
    "            print(f\"{name:20}: {result:.3f}\" if isinstance(result, (int, float)) else f\"{name:20}: {result}\")\n",
    "        else:\n",
    "            print(f\"{name:20}: Failed\")\n",
    "    \n",
    "    processing_results[op] = operation_results\n",
    "\n",
    "# Test with non-array-like objects\n",
    "print(\"\\nTesting with non-array-like objects:\")\n",
    "non_array_objects = {name: obj for name, obj in test_objects.items() \n",
    "                    if not array_like_results[name]}\n",
    "\n",
    "for name, obj in non_array_objects.items():\n",
    "    result = process_array_like(obj, 'sum')\n",
    "    print(f\"{name:20}: {'Correctly rejected' if result is None else 'Unexpected acceptance'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Cross-library Compatibility Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate seamless conversion between different array-like types\n",
    "def convert_array_like(data, target_type):\n",
    "    \"\"\"\n",
    "    Convert array-like data to specified target type.\n",
    "    \n",
    "    Args:\n",
    "        data: ArrayLike object\n",
    "        target_type: Target type ('numpy', 'pandas_series', 'pandas_dataframe', 'list', 'torch', 'xarray')\n",
    "    \n",
    "    Returns:\n",
    "        Converted data or None if conversion fails\n",
    "    \"\"\"\n",
    "    if not scitex.types.is_array_like(data):\n",
    "        print(f\"Input is not array-like: {type(data).__name__}\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # First convert to numpy array as intermediate format\n",
    "        if isinstance(data, pd.DataFrame):\n",
    "            # For DataFrames, use the first numeric column or all numeric data\n",
    "            numeric_data = data.select_dtypes(include=[np.number])\n",
    "            if not numeric_data.empty:\n",
    "                if numeric_data.shape[1] == 1:\n",
    "                    np_array = numeric_data.iloc[:, 0].values\n",
    "                else:\n",
    "                    np_array = numeric_data.values\n",
    "            else:\n",
    "                np_array = np.array(data.values)\n",
    "        elif isinstance(data, pd.Series):\n",
    "            np_array = data.values\n",
    "        elif TORCH_AVAILABLE and torch.is_tensor(data):\n",
    "            np_array = data.detach().numpy() if data.requires_grad else data.numpy()\n",
    "        elif XARRAY_AVAILABLE and isinstance(data, xr.DataArray):\n",
    "            np_array = data.values\n",
    "        else:\n",
    "            np_array = np.array(data)\n",
    "        \n",
    "        # Convert to target type\n",
    "        if target_type == 'numpy':\n",
    "            return np_array\n",
    "        elif target_type == 'list':\n",
    "            return np_array.tolist()\n",
    "        elif target_type == 'pandas_series':\n",
    "            return pd.Series(np_array.flatten() if np_array.ndim > 1 else np_array)\n",
    "        elif target_type == 'pandas_dataframe':\n",
    "            if np_array.ndim == 1:\n",
    "                return pd.DataFrame({'data': np_array})\n",
    "            else:\n",
    "                return pd.DataFrame(np_array)\n",
    "        elif target_type == 'torch' and TORCH_AVAILABLE:\n",
    "            return torch.from_numpy(np_array.astype(np.float32))\n",
    "        elif target_type == 'xarray' and XARRAY_AVAILABLE:\n",
    "            if np_array.ndim == 1:\n",
    "                return xr.DataArray(np_array, dims=['x'])\n",
    "            else:\n",
    "                return xr.DataArray(np_array, dims=['x', 'y'])\n",
    "        else:\n",
    "            return f\"Unsupported target type: {target_type}\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Conversion error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test conversions with sample data\n",
    "sample_data = np.random.randn(5, 3)\n",
    "target_types = ['numpy', 'list', 'pandas_series', 'pandas_dataframe']\n",
    "\n",
    "if TORCH_AVAILABLE:\n",
    "    target_types.append('torch')\n",
    "if XARRAY_AVAILABLE:\n",
    "    target_types.append('xarray')\n",
    "\n",
    "print(\"Array-like type conversion demonstration:\")\n",
    "print(\"=\" * 45)\n",
    "print(f\"Original data shape: {sample_data.shape}\")\n",
    "print(f\"Original data type: {type(sample_data).__name__}\")\n",
    "\n",
    "conversion_results = {}\n",
    "for target in target_types:\n",
    "    converted = convert_array_like(sample_data, target)\n",
    "    conversion_results[target] = converted\n",
    "    \n",
    "    if converted is not None and not isinstance(converted, str):\n",
    "        converted_type = type(converted).__name__\n",
    "        if hasattr(converted, 'shape'):\n",
    "            shape_info = f\"shape: {converted.shape}\"\n",
    "        elif hasattr(converted, '__len__'):\n",
    "            shape_info = f\"length: {len(converted)}\"\n",
    "        else:\n",
    "            shape_info = \"scalar\"\n",
    "        \n",
    "        # Check if converted object is array-like\n",
    "        is_still_array_like = scitex.types.is_array_like(converted)\n",
    "        array_like_status = \"✓\" if is_still_array_like else \"✗\"\n",
    "        \n",
    "        print(f\"{target:15} -> {converted_type:15} ({shape_info:12}) Array-like: {array_like_status}\")\n",
    "    else:\n",
    "        print(f\"{target:15} -> Conversion failed\")\n",
    "\n",
    "# Demonstrate round-trip conversions\n",
    "print(\"\\nRound-trip conversion test:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "original_list = [1, 2, 3, 4, 5]\n",
    "print(f\"Original: {original_list} (type: {type(original_list).__name__})\")\n",
    "\n",
    "# Convert through different types and back to list\n",
    "conversion_chain = ['numpy', 'pandas_series', 'pandas_dataframe', 'list']\n",
    "current_data = original_list\n",
    "\n",
    "for i, target in enumerate(conversion_chain):\n",
    "    current_data = convert_array_like(current_data, target)\n",
    "    if current_data is not None:\n",
    "        data_preview = str(current_data)[:50] + \"...\" if len(str(current_data)) > 50 else str(current_data)\n",
    "        print(f\"Step {i+1}: {target:15} -> {data_preview}\")\n",
    "    else:\n",
    "        print(f\"Step {i+1}: {target:15} -> Conversion failed\")\n",
    "        break\n",
    "\n",
    "# Check if we got back to the original\n",
    "if current_data is not None and isinstance(current_data, list):\n",
    "    success = current_data == original_list\n",
    "    print(f\"\\nRound-trip successful: {success}\")\n",
    "    if success:\n",
    "        print(f\"Final result: {current_data}\")\n",
    "else:\n",
    "    print(\"\\nRound-trip failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: ColorLike Type and Color Handling\n",
    "\n",
    "### 2.1 Understanding ColorLike\n",
    "\n",
    "The ColorLike type allows flexible color specification in scientific plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create different types of color specifications\n",
    "color_examples = {\n",
    "    'named_color': 'red',\n",
    "    'hex_color': '#FF5733',\n",
    "    'rgb_tuple': (0.2, 0.6, 0.8),\n",
    "    'rgba_tuple': (0.2, 0.6, 0.8, 0.7),\n",
    "    'rgb_list': [0.9, 0.3, 0.1],\n",
    "    'rgba_list': [0.9, 0.3, 0.1, 0.5],\n",
    "    'matplotlib_color': 'C0',  # Matplotlib color cycle\n",
    "    'grayscale': '0.5',  # Grayscale value\n",
    "    'invalid_string': 'not_a_color',\n",
    "    'invalid_tuple': (1, 2),  # Wrong number of elements\n",
    "    'invalid_list': [1, 2, 3, 4, 5],  # Too many elements\n",
    "    'invalid_type': 42\n",
    "}\n",
    "\n",
    "def is_valid_color(color):\n",
    "    \"\"\"\n",
    "    Check if a color specification is valid according to ColorLike type.\n",
    "    \n",
    "    Args:\n",
    "        color: Color specification to validate\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if color is valid ColorLike, False otherwise\n",
    "    \"\"\"\n",
    "    # Check string colors\n",
    "    if isinstance(color, str):\n",
    "        return True  # We'll assume string validation is done by matplotlib\n",
    "    \n",
    "    # Check tuple colors\n",
    "    if isinstance(color, tuple):\n",
    "        if len(color) == 3:  # RGB\n",
    "            return all(isinstance(c, (int, float)) and 0 <= c <= 1 for c in color)\n",
    "        elif len(color) == 4:  # RGBA\n",
    "            return all(isinstance(c, (int, float)) and 0 <= c <= 1 for c in color)\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    # Check list colors\n",
    "    if isinstance(color, list):\n",
    "        if len(color) == 3:  # RGB\n",
    "            return all(isinstance(c, (int, float)) and 0 <= c <= 1 for c in color)\n",
    "        elif len(color) == 4:  # RGBA\n",
    "            return all(isinstance(c, (int, float)) and 0 <= c <= 1 for c in color)\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    return False\n",
    "\n",
    "def normalize_color(color):\n",
    "    \"\"\"\n",
    "    Normalize a ColorLike object to RGBA tuple.\n",
    "    \n",
    "    Args:\n",
    "        color: ColorLike object\n",
    "    \n",
    "    Returns:\n",
    "        tuple: RGBA tuple (r, g, b, a) or None if invalid\n",
    "    \"\"\"\n",
    "    if not is_valid_color(color):\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Use matplotlib to convert color to RGBA\n",
    "        import matplotlib.colors as mcolors\n",
    "        \n",
    "        if isinstance(color, str):\n",
    "            try:\n",
    "                rgba = mcolors.to_rgba(color)\n",
    "                return rgba\n",
    "            except ValueError:\n",
    "                return None\n",
    "        elif isinstance(color, (tuple, list)):\n",
    "            if len(color) == 3:\n",
    "                return (*color, 1.0)  # Add alpha=1.0\n",
    "            elif len(color) == 4:\n",
    "                return tuple(color)\n",
    "        \n",
    "        return None\n",
    "    except ImportError:\n",
    "        # Fallback without matplotlib\n",
    "        if isinstance(color, (tuple, list)):\n",
    "            if len(color) == 3:\n",
    "                return (*color, 1.0)\n",
    "            elif len(color) == 4:\n",
    "                return tuple(color)\n",
    "        return None\n",
    "\n",
    "# Test color validation\n",
    "print(\"Testing ColorLike validation:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "color_validation_results = {}\n",
    "for name, color in color_examples.items():\n",
    "    is_valid = is_valid_color(color)\n",
    "    normalized = normalize_color(color)\n",
    "    color_validation_results[name] = {'valid': is_valid, 'normalized': normalized}\n",
    "    \n",
    "    status = \"✓ Valid\" if is_valid else \"✗ Invalid\"\n",
    "    color_repr = str(color)[:30] + \"...\" if len(str(color)) > 30 else str(color)\n",
    "    print(f\"{name:18} {color_repr:25} -> {status}\")\n",
    "    \n",
    "    if normalized:\n",
    "        print(f\"{'':44} RGBA: ({normalized[0]:.3f}, {normalized[1]:.3f}, {normalized[2]:.3f}, {normalized[3]:.3f})\")\n",
    "\n",
    "# Summary\n",
    "valid_colors = sum(1 for result in color_validation_results.values() if result['valid'])\n",
    "total_colors = len(color_validation_results)\n",
    "print(f\"\\nSummary: {valid_colors}/{total_colors} color specifications are valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Color Processing and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate color processing and visualization\n",
    "def create_color_palette(base_colors, n_variations=5):\n",
    "    \"\"\"\n",
    "    Create color variations from base ColorLike objects.\n",
    "    \n",
    "    Args:\n",
    "        base_colors: List of ColorLike objects\n",
    "        n_variations: Number of variations per base color\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary of color variations\n",
    "    \"\"\"\n",
    "    palette = {}\n",
    "    \n",
    "    for i, color in enumerate(base_colors):\n",
    "        normalized = normalize_color(color)\n",
    "        if normalized is None:\n",
    "            continue\n",
    "        \n",
    "        r, g, b, a = normalized\n",
    "        variations = []\n",
    "        \n",
    "        # Create variations by adjusting brightness\n",
    "        for j in range(n_variations):\n",
    "            factor = 0.3 + (0.7 * j / (n_variations - 1))  # Range from 0.3 to 1.0\n",
    "            var_r = min(1.0, r * factor + 0.1 * (1 - factor))\n",
    "            var_g = min(1.0, g * factor + 0.1 * (1 - factor))\n",
    "            var_b = min(1.0, b * factor + 0.1 * (1 - factor))\n",
    "            variations.append((var_r, var_g, var_b, a))\n",
    "        \n",
    "        palette[f'color_{i+1}'] = {\n",
    "            'original': normalized,\n",
    "            'variations': variations,\n",
    "            'input': color\n",
    "        }\n",
    "    \n",
    "    return palette\n",
    "\n",
    "# Create a color palette from valid colors\n",
    "valid_color_examples = [\n",
    "    'red', \n",
    "    (0.2, 0.6, 0.8), \n",
    "    [0.9, 0.3, 0.1], \n",
    "    '#FF5733'\n",
    "]\n",
    "\n",
    "color_palette = create_color_palette(valid_color_examples, n_variations=5)\n",
    "\n",
    "print(\"Generated Color Palette:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "for color_name, color_data in color_palette.items():\n",
    "    print(f\"\\n{color_name}:\")\n",
    "    print(f\"  Input: {color_data['input']}\")\n",
    "    print(f\"  Original RGBA: ({color_data['original'][0]:.3f}, {color_data['original'][1]:.3f}, {color_data['original'][2]:.3f}, {color_data['original'][3]:.3f})\")\n",
    "    print(f\"  Variations: {len(color_data['variations'])} shades\")\n",
    "\n",
    "# Visualize the color palette\n",
    "fig, axes = plt.subplots(len(color_palette), 1, figsize=(10, 2 * len(color_palette)))\n",
    "if len(color_palette) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for i, (color_name, color_data) in enumerate(color_palette.items()):\n",
    "    # Create a color bar showing variations\n",
    "    variations = color_data['variations']\n",
    "    colors_array = np.array(variations)[:, :3]  # Remove alpha for visualization\n",
    "    \n",
    "    # Create a horizontal color bar\n",
    "    axes[i].imshow(colors_array.reshape(1, -1, 3), aspect='auto', extent=[0, len(variations), 0, 1])\n",
    "    axes[i].set_title(f\"{color_name} - Input: {color_data['input']}\")\n",
    "    axes[i].set_xticks(np.arange(len(variations)) + 0.5)\n",
    "    axes[i].set_xticklabels([f'V{j+1}' for j in range(len(variations))])\n",
    "    axes[i].set_yticks([])\n",
    "    axes[i].set_xlabel('Variations')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Demonstrate color distance calculation\n",
    "def color_distance(color1, color2):\n",
    "    \"\"\"\n",
    "    Calculate Euclidean distance between two colors in RGB space.\n",
    "    \n",
    "    Args:\n",
    "        color1, color2: ColorLike objects\n",
    "    \n",
    "    Returns:\n",
    "        float: Distance between colors (0-√3)\n",
    "    \"\"\"\n",
    "    rgba1 = normalize_color(color1)\n",
    "    rgba2 = normalize_color(color2)\n",
    "    \n",
    "    if rgba1 is None or rgba2 is None:\n",
    "        return None\n",
    "    \n",
    "    # Calculate Euclidean distance in RGB space\n",
    "    r_diff = rgba1[0] - rgba2[0]\n",
    "    g_diff = rgba1[1] - rgba2[1]\n",
    "    b_diff = rgba1[2] - rgba2[2]\n",
    "    \n",
    "    distance = np.sqrt(r_diff**2 + g_diff**2 + b_diff**2)\n",
    "    return distance\n",
    "\n",
    "# Test color distances\n",
    "print(\"\\nColor Distance Analysis:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "test_color_pairs = [\n",
    "    ('red', 'blue'),\n",
    "    ('red', '#FF0000'),  # Same color, different representation\n",
    "    ((1, 0, 0), (0.9, 0.1, 0.1)),  # Similar reds\n",
    "    ('black', 'white'),\n",
    "    ((0.5, 0.5, 0.5), '0.5')  # Same gray, different representation\n",
    "]\n",
    "\n",
    "for color1, color2 in test_color_pairs:\n",
    "    distance = color_distance(color1, color2)\n",
    "    if distance is not None:\n",
    "        print(f\"{str(color1):20} <-> {str(color2):20}: {distance:.3f}\")\n",
    "    else:\n",
    "        print(f\"{str(color1):20} <-> {str(color2):20}: Invalid color(s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: List Type Checking with is_listed_X\n",
    "\n",
    "### 3.1 Basic Type Checking for Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test lists with different types\n",
    "test_lists = {\n",
    "    'integers': [1, 2, 3, 4, 5],\n",
    "    'floats': [1.1, 2.2, 3.3, 4.4, 5.5],\n",
    "    'strings': ['a', 'b', 'c', 'd', 'e'],\n",
    "    'mixed_numbers': [1, 2.5, 3, 4.0, 5],\n",
    "    'mixed_types': [1, 'two', 3.0, [4], {'five': 5}],\n",
    "    'booleans': [True, False, True, True, False],\n",
    "    'nested_lists': [[1, 2], [3, 4], [5, 6]],\n",
    "    'empty_list': [],\n",
    "    'single_element': [42],\n",
    "    'none_values': [None, None, None],\n",
    "    'numpy_arrays': [np.array([1, 2]), np.array([3, 4])],\n",
    "    'pandas_objects': [pd.Series([1, 2]), pd.DataFrame({'a': [1]})]\n",
    "}\n",
    "\n",
    "# Also test non-list objects\n",
    "non_list_objects = {\n",
    "    'tuple': (1, 2, 3),\n",
    "    'string': \"hello\",\n",
    "    'integer': 42,\n",
    "    'numpy_array': np.array([1, 2, 3]),\n",
    "    'dict': {'a': 1, 'b': 2}\n",
    "}\n",
    "\n",
    "# Test different type specifications\n",
    "type_tests = [\n",
    "    (int, \"integers only\"),\n",
    "    (float, \"floats only\"),\n",
    "    (str, \"strings only\"),\n",
    "    ((int, float), \"numbers (int or float)\"),\n",
    "    ([int, float], \"numbers (list of types)\"),\n",
    "    (bool, \"booleans only\"),\n",
    "    (list, \"lists only\"),\n",
    "    (type(None), \"None values only\"),\n",
    "    (np.ndarray, \"numpy arrays only\")\n",
    "]\n",
    "\n",
    "print(\"Testing is_listed_X function:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test all combinations\n",
    "for type_spec, type_desc in type_tests:\n",
    "    print(f\"\\nTesting for {type_desc}:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Test with list objects\n",
    "    for name, test_list in test_lists.items():\n",
    "        result = scitex.types.is_listed_X(test_list, type_spec)\n",
    "        alternative_result = scitex.types.is_list_of_type(test_list, type_spec)\n",
    "        \n",
    "        # Verify both functions give same result\n",
    "        assert result == alternative_result, f\"Functions disagree for {name}\"\n",
    "        \n",
    "        status = \"✓\" if result else \"✗\"\n",
    "        preview = str(test_list)[:30] + \"...\" if len(str(test_list)) > 30 else str(test_list)\n",
    "        print(f\"  {name:15} {preview:25} -> {status}\")\n",
    "    \n",
    "    # Test with non-list objects (should all be False)\n",
    "    print(\"  Non-list objects:\")\n",
    "    for name, obj in non_list_objects.items():\n",
    "        result = scitex.types.is_listed_X(obj, type_spec)\n",
    "        status = \"✓\" if result else \"✗\"\n",
    "        print(f\"    {name:13} -> {status} (should be ✗)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Advanced List Validation for Scientific Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scientific data validation functions\n",
    "def validate_numeric_list(data, allow_nan=False, min_length=1, max_length=None):\n",
    "    \"\"\"\n",
    "    Validate a list contains only numeric data with optional constraints.\n",
    "    \n",
    "    Args:\n",
    "        data: List to validate\n",
    "        allow_nan: Whether to allow NaN values\n",
    "        min_length: Minimum required length\n",
    "        max_length: Maximum allowed length (None for no limit)\n",
    "    \n",
    "    Returns:\n",
    "        dict: Validation results\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        'is_list': isinstance(data, list),\n",
    "        'length': len(data) if isinstance(data, list) else 0,\n",
    "        'is_numeric': False,\n",
    "        'has_nan': False,\n",
    "        'length_valid': False,\n",
    "        'overall_valid': False,\n",
    "        'errors': []\n",
    "    }\n",
    "    \n",
    "    if not results['is_list']:\n",
    "        results['errors'].append(\"Input is not a list\")\n",
    "        return results\n",
    "    \n",
    "    # Check if all elements are numeric\n",
    "    results['is_numeric'] = scitex.types.is_list_of_type(data, (int, float))\n",
    "    \n",
    "    if not results['is_numeric']:\n",
    "        results['errors'].append(\"List contains non-numeric elements\")\n",
    "    \n",
    "    # Check for NaN values\n",
    "    if results['is_numeric']:\n",
    "        results['has_nan'] = any(np.isnan(x) for x in data if isinstance(x, float))\n",
    "        if results['has_nan'] and not allow_nan:\n",
    "            results['errors'].append(\"List contains NaN values\")\n",
    "    \n",
    "    # Check length constraints\n",
    "    if results['length'] < min_length:\n",
    "        results['errors'].append(f\"List too short (minimum: {min_length})\")\n",
    "    elif max_length is not None and results['length'] > max_length:\n",
    "        results['errors'].append(f\"List too long (maximum: {max_length})\")\n",
    "    else:\n",
    "        results['length_valid'] = True\n",
    "    \n",
    "    # Overall validation\n",
    "    results['overall_valid'] = (\n",
    "        results['is_list'] and \n",
    "        results['is_numeric'] and \n",
    "        results['length_valid'] and\n",
    "        (allow_nan or not results['has_nan'])\n",
    "    )\n",
    "    \n",
    "    return results\n",
    "\n",
    "def validate_coordinate_list(data):\n",
    "    \"\"\"\n",
    "    Validate a list of coordinate tuples/lists.\n",
    "    \n",
    "    Args:\n",
    "        data: List of coordinates [(x1, y1), (x2, y2), ...]\n",
    "    \n",
    "    Returns:\n",
    "        dict: Validation results\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        'is_list': isinstance(data, list),\n",
    "        'all_coordinates': False,\n",
    "        'consistent_dimensions': False,\n",
    "        'dimensions': None,\n",
    "        'count': len(data) if isinstance(data, list) else 0,\n",
    "        'overall_valid': False,\n",
    "        'errors': []\n",
    "    }\n",
    "    \n",
    "    if not results['is_list']:\n",
    "        results['errors'].append(\"Input is not a list\")\n",
    "        return results\n",
    "    \n",
    "    if len(data) == 0:\n",
    "        results['errors'].append(\"List is empty\")\n",
    "        return results\n",
    "    \n",
    "    # Check if all elements are coordinate-like (tuples or lists)\n",
    "    results['all_coordinates'] = scitex.types.is_list_of_type(data, (tuple, list))\n",
    "    \n",
    "    if not results['all_coordinates']:\n",
    "        results['errors'].append(\"Not all elements are coordinate-like (tuple/list)\")\n",
    "        return results\n",
    "    \n",
    "    # Check dimension consistency\n",
    "    first_dim = len(data[0]) if len(data) > 0 else 0\n",
    "    results['dimensions'] = first_dim\n",
    "    \n",
    "    for i, coord in enumerate(data):\n",
    "        if len(coord) != first_dim:\n",
    "            results['errors'].append(f\"Inconsistent dimensions at index {i}\")\n",
    "            return results\n",
    "        \n",
    "        # Check if all coordinate components are numeric\n",
    "        if not all(isinstance(c, (int, float)) for c in coord):\n",
    "            results['errors'].append(f\"Non-numeric coordinate at index {i}\")\n",
    "            return results\n",
    "    \n",
    "    results['consistent_dimensions'] = True\n",
    "    results['overall_valid'] = True\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test scientific data validation\n",
    "scientific_test_data = {\n",
    "    'valid_measurements': [1.2, 3.4, 5.6, 7.8, 9.0],\n",
    "    'with_nan': [1.2, 3.4, float('nan'), 7.8, 9.0],\n",
    "    'mixed_numbers': [1, 2.5, 3, 4.0, 5],\n",
    "    'with_strings': [1.2, '3.4', 5.6, 7.8, 9.0],\n",
    "    'too_short': [1.2],\n",
    "    'empty': [],\n",
    "    'coordinates_2d': [(0, 1), (2, 3), (4, 5)],\n",
    "    'coordinates_3d': [(0, 1, 2), (3, 4, 5), (6, 7, 8)],\n",
    "    'mixed_dimensions': [(0, 1), (2, 3, 4), (5, 6)],\n",
    "    'invalid_coordinates': [(0, 1), 'not_coord', (4, 5)],\n",
    "    'non_numeric_coords': [('a', 'b'), ('c', 'd')]\n",
    "}\n",
    "\n",
    "print(\"Scientific Data Validation Tests:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Test numeric validation\n",
    "print(\"\\nNumeric List Validation:\")\n",
    "print(\"-\" * 25)\n",
    "\n",
    "numeric_tests = [\n",
    "    'valid_measurements', 'with_nan', 'mixed_numbers', \n",
    "    'with_strings', 'too_short', 'empty'\n",
    "]\n",
    "\n",
    "for test_name in numeric_tests:\n",
    "    data = scientific_test_data[test_name]\n",
    "    \n",
    "    # Test with different constraints\n",
    "    result_strict = validate_numeric_list(data, allow_nan=False, min_length=3)\n",
    "    result_lenient = validate_numeric_list(data, allow_nan=True, min_length=1)\n",
    "    \n",
    "    print(f\"\\n{test_name}:\")\n",
    "    print(f\"  Data: {data}\")\n",
    "    print(f\"  Strict validation: {'✓' if result_strict['overall_valid'] else '✗'}\")\n",
    "    if result_strict['errors']:\n",
    "        print(f\"    Errors: {', '.join(result_strict['errors'])}\")\n",
    "    print(f\"  Lenient validation: {'✓' if result_lenient['overall_valid'] else '✗'}\")\n",
    "    if result_lenient['errors']:\n",
    "        print(f\"    Errors: {', '.join(result_lenient['errors'])}\")\n",
    "\n",
    "# Test coordinate validation\n",
    "print(\"\\n\\nCoordinate List Validation:\")\n",
    "print(\"-\" * 27)\n",
    "\n",
    "coordinate_tests = [\n",
    "    'coordinates_2d', 'coordinates_3d', 'mixed_dimensions',\n",
    "    'invalid_coordinates', 'non_numeric_coords'\n",
    "]\n",
    "\n",
    "for test_name in coordinate_tests:\n",
    "    data = scientific_test_data[test_name]\n",
    "    result = validate_coordinate_list(data)\n",
    "    \n",
    "    print(f\"\\n{test_name}:\")\n",
    "    print(f\"  Data: {data}\")\n",
    "    print(f\"  Valid: {'✓' if result['overall_valid'] else '✗'}\")\n",
    "    if result['overall_valid']:\n",
    "        print(f\"  Dimensions: {result['dimensions']}D, Count: {result['count']}\")\n",
    "    if result['errors']:\n",
    "        print(f\"  Errors: {', '.join(result['errors'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Practical Applications and Integration\n",
    "\n",
    "### 4.1 Type-Safe Scientific Function Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design type-safe scientific functions using SciTeX types\n",
    "def safe_statistical_analysis(data, method='mean', confidence_level=0.95):\n",
    "    \"\"\"\n",
    "    Perform statistical analysis with comprehensive type checking.\n",
    "    \n",
    "    Args:\n",
    "        data: ArrayLike - Numeric data for analysis\n",
    "        method: str - Statistical method ('mean', 'median', 'std', 'var')\n",
    "        confidence_level: float - Confidence level for intervals\n",
    "    \n",
    "    Returns:\n",
    "        dict: Analysis results or error information\n",
    "    \"\"\"\n",
    "    result = {\n",
    "        'success': False,\n",
    "        'method': method,\n",
    "        'data_info': {},\n",
    "        'statistics': {},\n",
    "        'errors': []\n",
    "    }\n",
    "    \n",
    "    # Type checking\n",
    "    if not scitex.types.is_array_like(data):\n",
    "        result['errors'].append(f\"Data is not array-like (type: {type(data).__name__})\")\n",
    "        return result\n",
    "    \n",
    "    # Convert to numpy for analysis\n",
    "    try:\n",
    "        if isinstance(data, pd.DataFrame):\n",
    "            numeric_data = data.select_dtypes(include=[np.number])\n",
    "            if numeric_data.empty:\n",
    "                result['errors'].append(\"DataFrame contains no numeric columns\")\n",
    "                return result\n",
    "            np_data = numeric_data.values.flatten()\n",
    "        elif isinstance(data, pd.Series):\n",
    "            if not pd.api.types.is_numeric_dtype(data):\n",
    "                result['errors'].append(\"Series is not numeric\")\n",
    "                return result\n",
    "            np_data = data.values\n",
    "        else:\n",
    "            np_data = np.array(data, dtype=float)\n",
    "    except (ValueError, TypeError) as e:\n",
    "        result['errors'].append(f\"Cannot convert data to numeric array: {e}\")\n",
    "        return result\n",
    "    \n",
    "    # Remove NaN values and validate\n",
    "    clean_data = np_data[~np.isnan(np_data)]\n",
    "    \n",
    "    if len(clean_data) == 0:\n",
    "        result['errors'].append(\"No valid numeric data after removing NaN values\")\n",
    "        return result\n",
    "    \n",
    "    # Store data info\n",
    "    result['data_info'] = {\n",
    "        'original_size': len(np_data),\n",
    "        'valid_size': len(clean_data),\n",
    "        'nan_count': len(np_data) - len(clean_data),\n",
    "        'data_type': type(data).__name__\n",
    "    }\n",
    "    \n",
    "    # Perform statistical analysis\n",
    "    try:\n",
    "        if method == 'mean':\n",
    "            stat_value = np.mean(clean_data)\n",
    "            # Calculate confidence interval for mean\n",
    "            sem = np.std(clean_data, ddof=1) / np.sqrt(len(clean_data))\n",
    "            from scipy.stats import t\n",
    "            t_val = t.ppf((1 + confidence_level) / 2, len(clean_data) - 1)\n",
    "            margin = t_val * sem\n",
    "            ci_lower = stat_value - margin\n",
    "            ci_upper = stat_value + margin\n",
    "            \n",
    "        elif method == 'median':\n",
    "            stat_value = np.median(clean_data)\n",
    "            # Simple confidence interval for median (bootstrap approximation)\n",
    "            n = len(clean_data)\n",
    "            sorted_data = np.sort(clean_data)\n",
    "            z_val = 1.96  # For 95% confidence\n",
    "            margin = z_val * np.sqrt(n) / 2\n",
    "            lower_idx = max(0, int(n/2 - margin))\n",
    "            upper_idx = min(n-1, int(n/2 + margin))\n",
    "            ci_lower = sorted_data[lower_idx]\n",
    "            ci_upper = sorted_data[upper_idx]\n",
    "            \n",
    "        elif method == 'std':\n",
    "            stat_value = np.std(clean_data, ddof=1)\n",
    "            # Chi-square confidence interval for standard deviation\n",
    "            from scipy.stats import chi2\n",
    "            n = len(clean_data)\n",
    "            chi2_lower = chi2.ppf((1 - confidence_level) / 2, n - 1)\n",
    "            chi2_upper = chi2.ppf((1 + confidence_level) / 2, n - 1)\n",
    "            ci_lower = np.sqrt((n - 1) * stat_value**2 / chi2_upper)\n",
    "            ci_upper = np.sqrt((n - 1) * stat_value**2 / chi2_lower)\n",
    "            \n",
    "        elif method == 'var':\n",
    "            stat_value = np.var(clean_data, ddof=1)\n",
    "            # Chi-square confidence interval for variance\n",
    "            from scipy.stats import chi2\n",
    "            n = len(clean_data)\n",
    "            chi2_lower = chi2.ppf((1 - confidence_level) / 2, n - 1)\n",
    "            chi2_upper = chi2.ppf((1 + confidence_level) / 2, n - 1)\n",
    "            ci_lower = (n - 1) * stat_value / chi2_upper\n",
    "            ci_upper = (n - 1) * stat_value / chi2_lower\n",
    "            \n",
    "        else:\n",
    "            result['errors'].append(f\"Unknown method: {method}\")\n",
    "            return result\n",
    "        \n",
    "        result['statistics'] = {\n",
    "            'value': stat_value,\n",
    "            'confidence_interval': (ci_lower, ci_upper),\n",
    "            'confidence_level': confidence_level\n",
    "        }\n",
    "        result['success'] = True\n",
    "        \n",
    "    except Exception as e:\n",
    "        result['errors'].append(f\"Statistical calculation failed: {e}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "def safe_plotting_function(x_data, y_data, colors=None, markers=None, title=\"Plot\"):\n",
    "    \"\"\"\n",
    "    Create a plot with comprehensive type checking.\n",
    "    \n",
    "    Args:\n",
    "        x_data: ArrayLike - X coordinates\n",
    "        y_data: ArrayLike - Y coordinates  \n",
    "        colors: List of ColorLike objects or single ColorLike\n",
    "        markers: List of strings or single string\n",
    "        title: str - Plot title\n",
    "    \n",
    "    Returns:\n",
    "        dict: Plot creation results\n",
    "    \"\"\"\n",
    "    result = {\n",
    "        'success': False,\n",
    "        'errors': [],\n",
    "        'warnings': [],\n",
    "        'plot_info': {}\n",
    "    }\n",
    "    \n",
    "    # Type checking for coordinates\n",
    "    if not scitex.types.is_array_like(x_data):\n",
    "        result['errors'].append(\"x_data is not array-like\")\n",
    "        return result\n",
    "    \n",
    "    if not scitex.types.is_array_like(y_data):\n",
    "        result['errors'].append(\"y_data is not array-like\")\n",
    "        return result\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    try:\n",
    "        x_array = np.array(x_data, dtype=float)\n",
    "        y_array = np.array(y_data, dtype=float)\n",
    "    except (ValueError, TypeError) as e:\n",
    "        result['errors'].append(f\"Cannot convert coordinates to numeric arrays: {e}\")\n",
    "        return result\n",
    "    \n",
    "    # Check dimensions match\n",
    "    if len(x_array) != len(y_array):\n",
    "        result['errors'].append(f\"Coordinate arrays have different lengths: {len(x_array)} vs {len(y_array)}\")\n",
    "        return result\n",
    "    \n",
    "    # Validate colors if provided\n",
    "    processed_colors = None\n",
    "    if colors is not None:\n",
    "        if isinstance(colors, (list, tuple)):\n",
    "            # Check if it's a list of colors\n",
    "            if scitex.types.is_list_of_type(colors, str):\n",
    "                processed_colors = colors\n",
    "            else:\n",
    "                # Check if each element is a valid color\n",
    "                valid_colors = []\n",
    "                for i, color in enumerate(colors):\n",
    "                    normalized = normalize_color(color)\n",
    "                    if normalized:\n",
    "                        valid_colors.append(normalized)\n",
    "                    else:\n",
    "                        result['warnings'].append(f\"Invalid color at index {i}: {color}\")\n",
    "                processed_colors = valid_colors if valid_colors else None\n",
    "        else:\n",
    "            # Single color\n",
    "            normalized = normalize_color(colors)\n",
    "            if normalized:\n",
    "                processed_colors = [normalized]\n",
    "            else:\n",
    "                result['warnings'].append(f\"Invalid color: {colors}\")\n",
    "    \n",
    "    # Validate markers if provided\n",
    "    processed_markers = None\n",
    "    if markers is not None:\n",
    "        if isinstance(markers, str):\n",
    "            processed_markers = [markers]\n",
    "        elif scitex.types.is_list_of_type(markers, str):\n",
    "            processed_markers = markers\n",
    "        else:\n",
    "            result['warnings'].append(\"Invalid markers - must be string or list of strings\")\n",
    "    \n",
    "    # Create the plot\n",
    "    try:\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "        \n",
    "        # Plot data\n",
    "        n_points = len(x_array)\n",
    "        \n",
    "        if processed_colors and processed_markers:\n",
    "            # Use both colors and markers\n",
    "            for i in range(n_points):\n",
    "                color_idx = i % len(processed_colors)\n",
    "                marker_idx = i % len(processed_markers)\n",
    "                ax.scatter(x_array[i], y_array[i], \n",
    "                          c=[processed_colors[color_idx]], \n",
    "                          marker=processed_markers[marker_idx],\n",
    "                          s=50)\n",
    "        elif processed_colors:\n",
    "            # Use colors only\n",
    "            for i in range(n_points):\n",
    "                color_idx = i % len(processed_colors)\n",
    "                ax.scatter(x_array[i], y_array[i], \n",
    "                          c=[processed_colors[color_idx]], s=50)\n",
    "        elif processed_markers:\n",
    "            # Use markers only\n",
    "            for i in range(n_points):\n",
    "                marker_idx = i % len(processed_markers)\n",
    "                ax.scatter(x_array[i], y_array[i], \n",
    "                          marker=processed_markers[marker_idx], s=50)\n",
    "        else:\n",
    "            # Default plotting\n",
    "            ax.scatter(x_array, y_array, s=50)\n",
    "        \n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel('X')\n",
    "        ax.set_ylabel('Y')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        result['success'] = True\n",
    "        result['plot_info'] = {\n",
    "            'n_points': n_points,\n",
    "            'x_range': (np.min(x_array), np.max(x_array)),\n",
    "            'y_range': (np.min(y_array), np.max(y_array)),\n",
    "            'colors_used': len(processed_colors) if processed_colors else 0,\n",
    "            'markers_used': len(processed_markers) if processed_markers else 0\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        result['errors'].append(f\"Plot creation failed: {e}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Test the type-safe functions\n",
    "print(\"Testing Type-Safe Scientific Functions:\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# Test statistical analysis\n",
    "test_datasets = {\n",
    "    'valid_list': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'numpy_array': np.random.normal(10, 2, 50),\n",
    "    'pandas_series': pd.Series(np.random.exponential(2, 30)),\n",
    "    'with_nan': [1, 2, float('nan'), 4, 5, 6, 7, 8, 9, 10],\n",
    "    'invalid_data': 'not_array_like'\n",
    "}\n",
    "\n",
    "print(\"\\nStatistical Analysis Tests:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "for name, data in test_datasets.items():\n",
    "    result = safe_statistical_analysis(data, method='mean')\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Success: {'✓' if result['success'] else '✗'}\")\n",
    "    \n",
    "    if result['success']:\n",
    "        stats = result['statistics']\n",
    "        data_info = result['data_info']\n",
    "        print(f\"  Mean: {stats['value']:.3f}\")\n",
    "        print(f\"  95% CI: ({stats['confidence_interval'][0]:.3f}, {stats['confidence_interval'][1]:.3f})\")\n",
    "        print(f\"  Data: {data_info['valid_size']}/{data_info['original_size']} valid points\")\n",
    "    \n",
    "    if result['errors']:\n",
    "        print(f\"  Errors: {', '.join(result['errors'])}\")\n",
    "\n",
    "# Test plotting function\n",
    "print(\"\\n\\nPlotting Function Tests:\")\n",
    "print(\"-\" * 25)\n",
    "\n",
    "# Generate test data\n",
    "x_test = np.linspace(0, 10, 20)\n",
    "y_test = np.sin(x_test) + np.random.normal(0, 0.1, 20)\n",
    "\n",
    "test_colors = ['red', (0.2, 0.6, 0.8), '#FF5733']\n",
    "test_markers = ['o', 's', '^']\n",
    "\n",
    "plot_result = safe_plotting_function(\n",
    "    x_test, y_test, \n",
    "    colors=test_colors, \n",
    "    markers=test_markers,\n",
    "    title=\"Type-Safe Plotting Demo\"\n",
    ")\n",
    "\n",
    "print(f\"Plot creation: {'✓' if plot_result['success'] else '✗'}\")\n",
    "if plot_result['success']:\n",
    "    info = plot_result['plot_info']\n",
    "    print(f\"Points plotted: {info['n_points']}\")\n",
    "    print(f\"X range: ({info['x_range'][0]:.2f}, {info['x_range'][1]:.2f})\")\n",
    "    print(f\"Y range: ({info['y_range'][0]:.2f}, {info['y_range'][1]:.2f})\")\n",
    "    print(f\"Colors used: {info['colors_used']}\")\n",
    "    print(f\"Markers used: {info['markers_used']}\")\n",
    "\n",
    "if plot_result['errors']:\n",
    "    print(f\"Errors: {', '.join(plot_result['errors'])}\")\n",
    "if plot_result['warnings']:\n",
    "    print(f\"Warnings: {', '.join(plot_result['warnings'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Performance Comparison and Best Practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance comparison of type checking approaches\n",
    "import time\n",
    "from typing import get_type_hints\n",
    "\n",
    "def benchmark_type_checking():\n",
    "    \"\"\"\n",
    "    Compare performance of different type checking approaches.\n",
    "    \"\"\"\n",
    "    # Create test data\n",
    "    test_data = {\n",
    "        'small_list': list(range(100)),\n",
    "        'large_list': list(range(10000)),\n",
    "        'numpy_array': np.random.randn(10000),\n",
    "        'pandas_series': pd.Series(range(10000)),\n",
    "        'nested_list': [[i, i+1] for i in range(1000)]\n",
    "    }\n",
    "    \n",
    "    # Type checking functions to compare\n",
    "    def scitex_is_array_like(obj):\n",
    "        return scitex.types.is_array_like(obj)\n",
    "    \n",
    "    def scitex_is_list_of_type(obj):\n",
    "        return scitex.types.is_list_of_type(obj, int) if isinstance(obj, list) else False\n",
    "    \n",
    "    def manual_type_check(obj):\n",
    "        return isinstance(obj, (list, tuple, np.ndarray, pd.Series, pd.DataFrame))\n",
    "    \n",
    "    def hasattr_check(obj):\n",
    "        return hasattr(obj, '__iter__') and hasattr(obj, '__len__')\n",
    "    \n",
    "    # Benchmark functions\n",
    "    functions_to_test = [\n",
    "        ('SciTeX is_array_like', scitex_is_array_like),\n",
    "        ('Manual isinstance', manual_type_check),\n",
    "        ('hasattr check', hasattr_check)\n",
    "    ]\n",
    "    \n",
    "    results = {}\n",
    "    n_iterations = 1000\n",
    "    \n",
    "    print(\"Type Checking Performance Benchmark:\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"Iterations per test: {n_iterations}\")\n",
    "    \n",
    "    for data_name, data in test_data.items():\n",
    "        print(f\"\\nTesting with {data_name} (size: {len(data)}):\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        data_results = {}\n",
    "        \n",
    "        for func_name, func in functions_to_test:\n",
    "            # Warm up\n",
    "            for _ in range(10):\n",
    "                func(data)\n",
    "            \n",
    "            # Benchmark\n",
    "            start_time = time.time()\n",
    "            for _ in range(n_iterations):\n",
    "                result = func(data)\n",
    "            end_time = time.time()\n",
    "            \n",
    "            total_time = end_time - start_time\n",
    "            avg_time = total_time / n_iterations * 1000000  # microseconds\n",
    "            \n",
    "            data_results[func_name] = {\n",
    "                'total_time': total_time,\n",
    "                'avg_time_us': avg_time,\n",
    "                'result': result\n",
    "            }\n",
    "            \n",
    "            print(f\"  {func_name:20}: {avg_time:.2f} μs/call -> {result}\")\n",
    "        \n",
    "        results[data_name] = data_results\n",
    "    \n",
    "    # Test list type checking performance\n",
    "    print(f\"\\n\\nList Type Checking Performance:\")\n",
    "    print(\"-\" * 35)\n",
    "    \n",
    "    list_test_data = {\n",
    "        'small_int_list': list(range(10)),\n",
    "        'large_int_list': list(range(1000)),\n",
    "        'mixed_list': [1, 'two', 3.0, [4]],\n",
    "        'string_list': ['a', 'b', 'c', 'd', 'e'] * 100\n",
    "    }\n",
    "    \n",
    "    for data_name, data in list_test_data.items():\n",
    "        print(f\"\\n{data_name} (size: {len(data)}):\")\n",
    "        \n",
    "        # SciTeX approach\n",
    "        start_time = time.time()\n",
    "        for _ in range(n_iterations):\n",
    "            result_scitex = scitex.types.is_list_of_type(data, int)\n",
    "        scitex_time = (time.time() - start_time) / n_iterations * 1000000\n",
    "        \n",
    "        # Manual approach\n",
    "        start_time = time.time()\n",
    "        for _ in range(n_iterations):\n",
    "            result_manual = isinstance(data, list) and all(isinstance(x, int) for x in data)\n",
    "        manual_time = (time.time() - start_time) / n_iterations * 1000000\n",
    "        \n",
    "        print(f\"  SciTeX is_list_of_type: {scitex_time:.2f} μs/call -> {result_scitex}\")\n",
    "        print(f\"  Manual check:           {manual_time:.2f} μs/call -> {result_manual}\")\n",
    "        print(f\"  Speedup factor:         {scitex_time/manual_time:.2f}x\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def demonstrate_best_practices():\n",
    "    \"\"\"\n",
    "    Demonstrate best practices for using SciTeX type utilities.\n",
    "    \"\"\"\n",
    "    print(\"\\n\\nSciTeX Types Best Practices:\")\n",
    "    print(\"=\" * 35)\n",
    "    \n",
    "    print(\"\\n1. Input Validation Pattern:\")\n",
    "    print(\"-\" * 25)\n",
    "    \n",
    "    def robust_function(data, colors=None):\n",
    "        \"\"\"Example of robust input validation.\"\"\"\n",
    "        errors = []\n",
    "        \n",
    "        # Check main data\n",
    "        if not scitex.types.is_array_like(data):\n",
    "            errors.append(\"Data must be array-like\")\n",
    "            return {'success': False, 'errors': errors}\n",
    "        \n",
    "        # Check optional parameters\n",
    "        if colors is not None:\n",
    "            if isinstance(colors, list):\n",
    "                if not all(normalize_color(c) for c in colors):\n",
    "                    errors.append(\"Some colors are invalid\")\n",
    "            else:\n",
    "                if not normalize_color(colors):\n",
    "                    errors.append(\"Color is invalid\")\n",
    "        \n",
    "        if errors:\n",
    "            return {'success': False, 'errors': errors}\n",
    "        \n",
    "        return {'success': True, 'message': 'All inputs valid'}\n",
    "    \n",
    "    # Test the pattern\n",
    "    test_cases = [\n",
    "        ([1, 2, 3], 'red'),\n",
    "        ('not_array', 'blue'),\n",
    "        ([1, 2, 3], 'invalid_color'),\n",
    "        (np.array([1, 2, 3]), ['red', 'blue', 'green'])\n",
    "    ]\n",
    "    \n",
    "    for data, colors in test_cases:\n",
    "        result = robust_function(data, colors)\n",
    "        status = \"✓\" if result['success'] else \"✗\"\n",
    "        print(f\"  Data: {str(data)[:20]}, Colors: {colors} -> {status}\")\n",
    "        if not result['success']:\n",
    "            print(f\"    Errors: {', '.join(result['errors'])}\")\n",
    "    \n",
    "    print(\"\\n2. Type Conversion Pattern:\")\n",
    "    print(\"-\" * 27)\n",
    "    \n",
    "    def flexible_array_function(data):\n",
    "        \"\"\"Example of flexible array handling.\"\"\"\n",
    "        if not scitex.types.is_array_like(data):\n",
    "            return None\n",
    "        \n",
    "        # Convert to numpy for processing\n",
    "        try:\n",
    "            if isinstance(data, pd.DataFrame):\n",
    "                # Handle DataFrames specially\n",
    "                numeric_cols = data.select_dtypes(include=[np.number])\n",
    "                if not numeric_cols.empty:\n",
    "                    array_data = numeric_cols.values\n",
    "                else:\n",
    "                    return None\n",
    "            else:\n",
    "                array_data = np.asarray(data)\n",
    "            \n",
    "            # Process the array\n",
    "            result = np.sum(array_data)\n",
    "            return result\n",
    "            \n",
    "        except Exception:\n",
    "            return None\n",
    "    \n",
    "    # Test flexible handling\n",
    "    flexible_test_data = [\n",
    "        [1, 2, 3, 4, 5],\n",
    "        np.array([1, 2, 3, 4, 5]),\n",
    "        pd.Series([1, 2, 3, 4, 5]),\n",
    "        pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6]}),\n",
    "        \"not_array\"\n",
    "    ]\n",
    "    \n",
    "    for data in flexible_test_data:\n",
    "        result = flexible_array_function(data)\n",
    "        data_str = str(data)[:30] + \"...\" if len(str(data)) > 30 else str(data)\n",
    "        if result is not None:\n",
    "            print(f\"  {data_str:35} -> Sum: {result}\")\n",
    "        else:\n",
    "            print(f\"  {data_str:35} -> Cannot process\")\n",
    "    \n",
    "    print(\"\\n3. Performance Tips:\")\n",
    "    print(\"-\" * 17)\n",
    "    print(\"  • Cache type checking results for repeated use\")\n",
    "    print(\"  • Use isinstance() for simple, known types\")\n",
    "    print(\"  • Use SciTeX types for flexible, cross-library compatibility\")\n",
    "    print(\"  • Validate inputs early in function execution\")\n",
    "    print(\"  • Provide clear error messages for type mismatches\")\n",
    "\n",
    "# Run benchmarks and demonstrations\n",
    "benchmark_results = benchmark_type_checking()\n",
    "demonstrate_best_practices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Best Practices\n",
    "\n",
    "This tutorial demonstrated the comprehensive type handling capabilities of the SciTeX types module:\n",
    "\n",
    "### Key Components Covered:\n",
    "\n",
    "1. **ArrayLike Type Union**:\n",
    "   - Supports lists, tuples, NumPy arrays, Pandas Series/DataFrames, PyTorch tensors, XArray DataArrays\n",
    "   - Enables cross-library compatibility\n",
    "   - Provides flexible input handling for scientific functions\n",
    "\n",
    "2. **ColorLike Type Union**:\n",
    "   - Supports string colors, RGB/RGBA tuples, RGB/RGBA lists\n",
    "   - Enables flexible color specification for plotting\n",
    "   - Integrates with matplotlib color systems\n",
    "\n",
    "3. **List Type Checking Functions**:\n",
    "   - `is_listed_X` and `is_list_of_type` for validating list contents\n",
    "   - Support for multiple type specifications\n",
    "   - Robust error handling for edge cases\n",
    "\n",
    "4. **Type Validation Functions**:\n",
    "   - `is_array_like` for checking array-like objects\n",
    "   - Consistent behavior across different data types\n",
    "   - Integration with scientific computing workflows\n",
    "\n",
    "### Best Practices:\n",
    "\n",
    "#### Input Validation:\n",
    "- **Always validate inputs early** in function execution\n",
    "- **Provide clear error messages** that help users understand type requirements\n",
    "- **Use SciTeX type checking** for cross-library compatibility\n",
    "- **Handle edge cases** like empty arrays, NaN values, and mixed types\n",
    "\n",
    "#### Performance Considerations:\n",
    "- **Cache type checking results** when performing repeated operations\n",
    "- **Use isinstance()** for simple, known types when performance is critical\n",
    "- **Leverage SciTeX types** for flexible, user-friendly APIs\n",
    "- **Convert to NumPy arrays** early for consistent numerical operations\n",
    "\n",
    "#### Design Patterns:\n",
    "- **Graceful degradation**: Handle type mismatches without crashing\n",
    "- **Flexible input handling**: Accept multiple array-like types\n",
    "- **Consistent output formats**: Return standardized result structures\n",
    "- **Comprehensive validation**: Check all aspects of input data\n",
    "\n",
    "#### Scientific Applications:\n",
    "- **Data pipeline validation**: Ensure data integrity through processing steps\n",
    "- **Plotting functions**: Accept flexible color and marker specifications\n",
    "- **Statistical analysis**: Validate numeric data before computation\n",
    "- **Machine learning**: Type-check features, labels, and model parameters\n",
    "\n",
    "### When to Use SciTeX Types:\n",
    "\n",
    "- **Multi-library environments** where users may provide different array types\n",
    "- **User-facing APIs** that need to be flexible and forgiving\n",
    "- **Scientific computing** where data comes in various formats\n",
    "- **Plotting and visualization** where color/marker specifications vary\n",
    "- **Data validation** in research pipelines\n",
    "\n",
    "The SciTeX types module provides essential tools for building robust, flexible scientific computing applications that work seamlessly across the Python data science ecosystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SciTeX Type Handling Utilities Tutorial Complete!\")\n",
    "print(\"\\nKey takeaways:\")\n",
    "print(\"1. ArrayLike enables seamless cross-library array handling\")\n",
    "print(\"2. ColorLike provides flexible color specification for plotting\")\n",
    "print(\"3. is_listed_X validates list contents with type safety\")\n",
    "print(\"4. Type checking improves function robustness and user experience\")\n",
    "print(\"5. SciTeX types balance flexibility with performance\")\n",
    "print(\"6. Proper input validation prevents runtime errors in scientific workflows\")\n",
    "print(\"7. Type-safe design patterns enhance code maintainability\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
