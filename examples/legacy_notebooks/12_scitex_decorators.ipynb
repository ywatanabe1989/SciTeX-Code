{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SciTeX Decorators Module Tutorial\n",
    "\n",
    "This notebook demonstrates the powerful decorator utilities in SciTeX for type conversion, batch processing, caching, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scitex as stx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Optional imports\n",
    "try:\n",
    "    import torch\n",
    "    TORCH_AVAILABLE = True\n",
    "except ImportError:\n",
    "    TORCH_AVAILABLE = False\n",
    "    print(\"PyTorch not available. Some examples will be skipped.\")\n",
    "\n",
    "try:\n",
    "    import xarray as xr\n",
    "    XARRAY_AVAILABLE = True\n",
    "except ImportError:\n",
    "    XARRAY_AVAILABLE = False\n",
    "    print(\"Xarray not available. Some examples will be skipped.\")\n",
    "\n",
    "# Enable auto-ordering for decorators (recommended)\n",
    "stx.decorators.enable_auto_order()\n",
    "print(\"Auto-ordering enabled for decorators\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Type Conversion Decorators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 NumPy Function Decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic numpy_fn usage\n",
    "@stx.decorators.numpy_fn\n",
    "def compute_statistics(x):\n",
    "    \"\"\"Compute mean and std of data.\"\"\"\n",
    "    return {\n",
    "        'mean': x.mean(),\n",
    "        'std': x.std(),\n",
    "        'shape': x.shape\n",
    "    }\n",
    "\n",
    "# Test with different input types\n",
    "print(\"=== numpy_fn Decorator ===\")\n",
    "\n",
    "# Python list\n",
    "list_data = [1, 2, 3, 4, 5]\n",
    "result = compute_statistics(list_data)\n",
    "print(f\"\\nList input: {list_data}\")\n",
    "print(f\"Result: {result}\")\n",
    "\n",
    "# Pandas Series\n",
    "series_data = pd.Series([10, 20, 30, 40, 50])\n",
    "result = compute_statistics(series_data)\n",
    "print(f\"\\nPandas Series input:\")\n",
    "print(series_data)\n",
    "print(f\"Result: {result}\")\n",
    "\n",
    "# Already numpy array\n",
    "array_data = np.random.randn(3, 4)\n",
    "result = compute_statistics(array_data)\n",
    "print(f\"\\nNumPy array input shape: {array_data.shape}\")\n",
    "print(f\"Result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 PyTorch Function Decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TORCH_AVAILABLE:\n",
    "    print(\"=== torch_fn Decorator ===\")\n",
    "    \n",
    "    @stx.decorators.torch_fn\n",
    "    def neural_computation(x, dim=-1):\n",
    "        \"\"\"Perform softmax computation.\"\"\"\n",
    "        return torch.softmax(x, dim=dim)\n",
    "    \n",
    "    # Test with different inputs\n",
    "    # NumPy array\n",
    "    np_data = np.random.randn(5, 3)\n",
    "    result = neural_computation(np_data)\n",
    "    print(f\"NumPy input shape: {np_data.shape}\")\n",
    "    print(f\"Result type: {type(result)}\")\n",
    "    print(f\"Result shape: {result.shape}\")\n",
    "    print(f\"Result device: {result.device}\")\n",
    "    \n",
    "    # List of lists\n",
    "    list_data = [[1, 2, 3], [4, 5, 6]]\n",
    "    result = neural_computation(list_data)\n",
    "    print(f\"\\nList input: {list_data}\")\n",
    "    print(f\"Result:\\n{result}\")\n",
    "    \n",
    "    # With axis parameter (converts to dim)\n",
    "    @stx.decorators.torch_fn\n",
    "    def sum_along_axis(x, axis=None):\n",
    "        \"\"\"Sum along specified axis.\"\"\"\n",
    "        if axis is None:\n",
    "            return x.sum()\n",
    "        return x.sum(dim=axis)\n",
    "    \n",
    "    data = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "    print(f\"\\nOriginal data:\\n{data}\")\n",
    "    print(f\"Sum along axis 0: {sum_along_axis(data, axis=0)}\")\n",
    "    print(f\"Sum along axis 1: {sum_along_axis(data, axis=1)}\")\n",
    "else:\n",
    "    print(\"PyTorch not available, skipping torch_fn examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Pandas Function Decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== pandas_fn Decorator ===\")\n",
    "\n",
    "@stx.decorators.pandas_fn\n",
    "def analyze_dataframe(df):\n",
    "    \"\"\"Analyze DataFrame and return summary.\"\"\"\n",
    "    return {\n",
    "        'shape': df.shape,\n",
    "        'columns': df.columns.tolist(),\n",
    "        'dtypes': df.dtypes.to_dict(),\n",
    "        'missing': df.isnull().sum().to_dict(),\n",
    "        'summary': df.describe()\n",
    "    }\n",
    "\n",
    "# Test with different inputs\n",
    "# Dictionary input\n",
    "dict_data = {\n",
    "    'A': [1, 2, 3, 4],\n",
    "    'B': [5.5, 6.5, 7.5, 8.5],\n",
    "    'C': ['x', 'y', 'z', None]\n",
    "}\n",
    "result = analyze_dataframe(dict_data)\n",
    "print(\"Dictionary input analysis:\")\n",
    "print(f\"  Shape: {result['shape']}\")\n",
    "print(f\"  Columns: {result['columns']}\")\n",
    "print(f\"  Missing values: {result['missing']}\")\n",
    "\n",
    "# NumPy array input\n",
    "array_data = np.random.randn(10, 3)\n",
    "result = analyze_dataframe(array_data)\n",
    "print(\"\\nNumPy array input analysis:\")\n",
    "print(f\"  Shape: {result['shape']}\")\n",
    "print(f\"  Summary:\\n{result['summary']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Batch Processing Decorator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Basic Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== batch_fn Decorator ===\")\n",
    "\n",
    "# Simple batch processing\n",
    "@stx.decorators.batch_fn\n",
    "def process_sample(x):\n",
    "    \"\"\"Process individual sample.\"\"\"\n",
    "    return x ** 2 + 2 * x + 1\n",
    "\n",
    "# Process multiple samples\n",
    "samples = np.array([1, 2, 3, 4, 5])\n",
    "results = process_sample(samples)\n",
    "print(f\"Input samples: {samples}\")\n",
    "print(f\"Processed results: {results}\")\n",
    "\n",
    "# 2D batch processing\n",
    "@stx.decorators.batch_fn\n",
    "def normalize_vector(v):\n",
    "    \"\"\"Normalize a single vector.\"\"\"\n",
    "    norm = np.linalg.norm(v)\n",
    "    return v / norm if norm > 0 else v\n",
    "\n",
    "# Process batch of vectors\n",
    "vectors = np.random.randn(5, 3)  # 5 vectors of dimension 3\n",
    "normalized = normalize_vector(vectors)\n",
    "print(f\"\\nOriginal vectors shape: {vectors.shape}\")\n",
    "print(f\"Normalized vectors shape: {normalized.shape}\")\n",
    "print(f\"Norms after normalization: {np.linalg.norm(normalized, axis=1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Batch Processing with Multiple Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch processing over multiple dimensions\n",
    "@stx.decorators.batch_fn(n_batch_dims=2)\n",
    "def process_matrix(M):\n",
    "    \"\"\"Process individual 2x2 matrix.\"\"\"\n",
    "    return np.linalg.det(M)\n",
    "\n",
    "# Create batch of 2x2 matrices\n",
    "batch_size = 4\n",
    "matrices = np.random.randn(batch_size, 2, 2)\n",
    "determinants = process_matrix(matrices)\n",
    "\n",
    "print(\"Batch processing of matrices:\")\n",
    "for i in range(batch_size):\n",
    "    print(f\"  Matrix {i} determinant: {determinants[i]:.4f}\")\n",
    "\n",
    "# Complex example: batch processing with scalar results\n",
    "@stx.decorators.batch_fn\n",
    "def classify_point(point):\n",
    "    \"\"\"Classify a 2D point into quadrants.\"\"\"\n",
    "    x, y = point\n",
    "    if x >= 0 and y >= 0:\n",
    "        return 1  # Quadrant I\n",
    "    elif x < 0 and y >= 0:\n",
    "        return 2  # Quadrant II\n",
    "    elif x < 0 and y < 0:\n",
    "        return 3  # Quadrant III\n",
    "    else:\n",
    "        return 4  # Quadrant IV\n",
    "\n",
    "# Generate random points\n",
    "points = np.random.randn(10, 2)\n",
    "quadrants = classify_point(points)\n",
    "\n",
    "print(\"\\nPoint classification:\")\n",
    "for i, (point, quad) in enumerate(zip(points, quadrants)):\n",
    "    print(f\"  Point {i}: {point} -> Quadrant {quad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Combined Decorators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Auto-Ordering in Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Combined Decorators with Auto-Ordering ===\")\n",
    "\n",
    "# Order doesn't matter with auto-ordering enabled!\n",
    "@stx.decorators.batch_fn  # Will be reordered to apply second\n",
    "@stx.decorators.numpy_fn  # Will be reordered to apply first\n",
    "def compute_features(x):\n",
    "    \"\"\"Extract features from individual sample.\"\"\"\n",
    "    return np.array([\n",
    "        x.mean(),\n",
    "        x.std(),\n",
    "        x.min(),\n",
    "        x.max(),\n",
    "        np.median(x)\n",
    "    ])\n",
    "\n",
    "# Test with batch of samples\n",
    "batch_data = [  # List of lists\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [10, 20, 30, 40, 50],\n",
    "    [5, 5, 5, 5, 5]\n",
    "]\n",
    "\n",
    "features = compute_features(batch_data)\n",
    "print(\"Extracted features:\")\n",
    "print(f\"Shape: {features.shape}\")\n",
    "print(\"\\nFeature matrix:\")\n",
    "print(\"Sample | Mean  | Std   | Min   | Max   | Median\")\n",
    "print(\"-\" * 50)\n",
    "for i, feat in enumerate(features):\n",
    "    print(f\"{i:6d} | {feat[0]:5.1f} | {feat[1]:5.1f} | {feat[2]:5.1f} | {feat[3]:5.1f} | {feat[4]:5.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 PyTorch Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TORCH_AVAILABLE:\n",
    "    print(\"=== PyTorch Batch Processing ===\")\n",
    "    \n",
    "    # Use pre-combined decorator\n",
    "    @stx.decorators.batch_torch_fn\n",
    "    def apply_activation(x, temperature=1.0):\n",
    "        \"\"\"Apply temperature-scaled softmax.\"\"\"\n",
    "        return torch.softmax(x / temperature, dim=-1)\n",
    "    \n",
    "    # Test with batch\n",
    "    logits = np.random.randn(5, 10)  # 5 samples, 10 classes\n",
    "    \n",
    "    # Different temperatures\n",
    "    for temp in [0.5, 1.0, 2.0]:\n",
    "        probs = apply_activation(logits, temperature=temp)\n",
    "        entropy = -(probs * torch.log(probs + 1e-8)).sum(dim=-1).mean()\n",
    "        print(f\"\\nTemperature {temp}:\")\n",
    "        print(f\"  Output shape: {probs.shape}\")\n",
    "        print(f\"  Average entropy: {entropy:.3f}\")\n",
    "        print(f\"  Max probability: {probs.max(dim=-1)[0].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Caching Decorators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Memory Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== cache_mem Decorator ===\")\n",
    "\n",
    "# Expensive computation with memory caching\n",
    "@stx.decorators.cache_mem\n",
    "def expensive_computation(n):\n",
    "    \"\"\"Simulate expensive computation.\"\"\"\n",
    "    print(f\"Computing for n={n}...\")\n",
    "    time.sleep(1)  # Simulate work\n",
    "    return sum(i**2 for i in range(n))\n",
    "\n",
    "# First calls (slow)\n",
    "print(\"First calls (computed):\")\n",
    "start = time.time()\n",
    "result1 = expensive_computation(1000)\n",
    "time1 = time.time() - start\n",
    "print(f\"  n=1000: {result1} (took {time1:.3f}s)\")\n",
    "\n",
    "start = time.time()\n",
    "result2 = expensive_computation(2000)\n",
    "time2 = time.time() - start\n",
    "print(f\"  n=2000: {result2} (took {time2:.3f}s)\")\n",
    "\n",
    "# Repeated calls (cached, fast)\n",
    "print(\"\\nRepeated calls (cached):\")\n",
    "start = time.time()\n",
    "result1_cached = expensive_computation(1000)\n",
    "time1_cached = time.time() - start\n",
    "print(f\"  n=1000: {result1_cached} (took {time1_cached:.6f}s)\")\n",
    "\n",
    "start = time.time()\n",
    "result2_cached = expensive_computation(2000)\n",
    "time2_cached = time.time() - start\n",
    "print(f\"  n=2000: {result2_cached} (took {time2_cached:.6f}s)\")\n",
    "\n",
    "print(f\"\\nSpeedup: {time1/time1_cached:.0f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Disk Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== cache_disk Decorator ===\")\n",
    "\n",
    "# Large computation with disk caching\n",
    "@stx.decorators.cache_disk\n",
    "def generate_large_dataset(size, seed=42):\n",
    "    \"\"\"Generate large random dataset.\"\"\"\n",
    "    print(f\"Generating dataset of size {size} with seed {seed}...\")\n",
    "    np.random.seed(seed)\n",
    "    data = np.random.randn(size, 100)\n",
    "    return {\n",
    "        'data': data,\n",
    "        'mean': data.mean(),\n",
    "        'std': data.std(),\n",
    "        'size': size\n",
    "    }\n",
    "\n",
    "# First call (generates and caches)\n",
    "print(\"First call (generating):\")\n",
    "start = time.time()\n",
    "dataset1 = generate_large_dataset(10000)\n",
    "time1 = time.time() - start\n",
    "print(f\"  Generated in {time1:.3f}s\")\n",
    "print(f\"  Mean: {dataset1['mean']:.6f}\")\n",
    "\n",
    "# Second call (loads from cache)\n",
    "print(\"\\nSecond call (from cache):\")\n",
    "start = time.time()\n",
    "dataset2 = generate_large_dataset(10000)\n",
    "time2 = time.time() - start\n",
    "print(f\"  Loaded in {time2:.3f}s\")\n",
    "print(f\"  Mean: {dataset2['mean']:.6f}\")\n",
    "print(f\"  Data identical: {np.array_equal(dataset1['data'], dataset2['data'])}\")\n",
    "\n",
    "# Different parameters (new computation)\n",
    "print(\"\\nDifferent parameters:\")\n",
    "dataset3 = generate_large_dataset(5000)  # Different size\n",
    "print(f\"  Size: {dataset3['size']}\")\n",
    "\n",
    "# Show cache location\n",
    "cache_dir = Path.home() / \".cache\" / \"scitex\" / \"cache\"\n",
    "print(f\"\\nCache directory: {cache_dir}\")\n",
    "if cache_dir.exists():\n",
    "    cache_files = list(cache_dir.rglob(\"*\"))\n",
    "    print(f\"Cache files: {len(cache_files)} files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Utility Decorators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Timeout Decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== timeout Decorator ===\")\n",
    "\n",
    "# Function with timeout\n",
    "@stx.decorators.timeout(seconds=2, error_message=\"Function took too long!\")\n",
    "def potentially_slow_function(sleep_time):\n",
    "    \"\"\"Function that might take too long.\"\"\"\n",
    "    print(f\"Processing for {sleep_time} seconds...\")\n",
    "    time.sleep(sleep_time)\n",
    "    return f\"Completed after {sleep_time}s\"\n",
    "\n",
    "# Fast execution (within timeout)\n",
    "try:\n",
    "    result = potentially_slow_function(1)\n",
    "    print(f\"Fast execution: {result}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "# Slow execution (exceeds timeout)\n",
    "print(\"\\nTrying slow execution...\")\n",
    "try:\n",
    "    result = potentially_slow_function(3)\n",
    "    print(f\"Slow execution: {result}\")\n",
    "except Exception as e:\n",
    "    print(f\"Timeout error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Deprecation Decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== deprecated Decorator ===\")\n",
    "\n",
    "# Mark function as deprecated\n",
    "@stx.decorators.deprecated(\"Use new_function() instead\")\n",
    "def old_function(x):\n",
    "    \"\"\"Old function that should not be used.\"\"\"\n",
    "    return x * 2\n",
    "\n",
    "# Using deprecated function shows warning\n",
    "import warnings\n",
    "with warnings.catch_warnings(record=True) as w:\n",
    "    warnings.simplefilter(\"always\")\n",
    "    result = old_function(5)\n",
    "    print(f\"Result: {result}\")\n",
    "    if w:\n",
    "        print(f\"Warning: {w[0].message}\")\n",
    "\n",
    "# New function (no warning)\n",
    "def new_function(x):\n",
    "    \"\"\"New improved function.\"\"\"\n",
    "    return x * 2 + 1\n",
    "\n",
    "result = new_function(5)\n",
    "print(f\"\\nNew function result: {result} (no warning)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Real-World Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Data Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete data processing pipeline\n",
    "class DataProcessor:\n",
    "    \"\"\"Data processing with decorators.\"\"\"\n",
    "    \n",
    "    @stx.decorators.cache_mem\n",
    "    @stx.decorators.numpy_fn\n",
    "    def load_and_preprocess(self, data, normalize=True):\n",
    "        \"\"\"Load and preprocess data.\"\"\"\n",
    "        # Center the data\n",
    "        centered = data - data.mean(axis=0)\n",
    "        \n",
    "        if normalize:\n",
    "            # Normalize to unit variance\n",
    "            std = centered.std(axis=0)\n",
    "            std[std == 0] = 1  # Avoid division by zero\n",
    "            normalized = centered / std\n",
    "            return normalized\n",
    "        \n",
    "        return centered\n",
    "    \n",
    "    @stx.decorators.batch_fn\n",
    "    @stx.decorators.numpy_fn\n",
    "    def extract_features(self, sample):\n",
    "        \"\"\"Extract features from single sample.\"\"\"\n",
    "        features = [\n",
    "            sample.mean(),\n",
    "            sample.std(),\n",
    "            np.percentile(sample, [25, 50, 75]),\n",
    "            sample.max() - sample.min(),  # Range\n",
    "            np.abs(sample).mean(),  # Mean absolute value\n",
    "        ]\n",
    "        # Flatten nested arrays\n",
    "        flat_features = []\n",
    "        for f in features:\n",
    "            if isinstance(f, np.ndarray):\n",
    "                flat_features.extend(f)\n",
    "            else:\n",
    "                flat_features.append(f)\n",
    "        return np.array(flat_features)\n",
    "    \n",
    "    @stx.decorators.timeout(seconds=5)\n",
    "    def process_dataset(self, raw_data):\n",
    "        \"\"\"Complete processing pipeline.\"\"\"\n",
    "        # Preprocess\n",
    "        preprocessed = self.load_and_preprocess(raw_data)\n",
    "        print(f\"Preprocessed shape: {preprocessed.shape}\")\n",
    "        \n",
    "        # Extract features\n",
    "        features = self.extract_features(preprocessed)\n",
    "        print(f\"Features shape: {features.shape}\")\n",
    "        \n",
    "        return {\n",
    "            'preprocessed': preprocessed,\n",
    "            'features': features,\n",
    "            'n_samples': len(preprocessed),\n",
    "            'n_features': features.shape[1]\n",
    "        }\n",
    "\n",
    "# Use the processor\n",
    "processor = DataProcessor()\n",
    "\n",
    "# Generate sample data\n",
    "raw_data = np.random.randn(100, 20)  # 100 samples, 20 dimensions\n",
    "\n",
    "# Process data\n",
    "print(\"Processing dataset...\")\n",
    "results = processor.process_dataset(raw_data)\n",
    "\n",
    "print(f\"\\nProcessing complete:\")\n",
    "print(f\"  Original shape: {raw_data.shape}\")\n",
    "print(f\"  Preprocessed shape: {results['preprocessed'].shape}\")\n",
    "print(f\"  Features per sample: {results['n_features']}\")\n",
    "\n",
    "# Second call uses cache\n",
    "print(\"\\nSecond processing (using cache)...\")\n",
    "start = time.time()\n",
    "results2 = processor.process_dataset(raw_data)\n",
    "print(f\"Completed in {time.time() - start:.4f}s (cached)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Machine Learning Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TORCH_AVAILABLE:\n",
    "    print(\"=== ML Pipeline with Decorators ===\")\n",
    "    \n",
    "    class MLPipeline:\n",
    "        \"\"\"Machine learning pipeline with decorators.\"\"\"\n",
    "        \n",
    "        @stx.decorators.torch_fn\n",
    "        @stx.decorators.cache_mem\n",
    "        def create_embeddings(self, data, embedding_dim=64):\n",
    "            \"\"\"Create random embeddings (simulated).\"\"\"\n",
    "            n_samples = len(data)\n",
    "            # Simulate embedding generation\n",
    "            embeddings = torch.randn(n_samples, embedding_dim)\n",
    "            return embeddings / embeddings.norm(dim=1, keepdim=True)\n",
    "        \n",
    "        @stx.decorators.batch_torch_fn(n_batch_dims=1)\n",
    "        def compute_similarity(self, embedding1, embedding2):\n",
    "            \"\"\"Compute cosine similarity between embeddings.\"\"\"\n",
    "            return torch.cosine_similarity(embedding1, embedding2, dim=0)\n",
    "        \n",
    "        @stx.decorators.numpy_fn\n",
    "        def cluster_embeddings(self, embeddings, n_clusters=3):\n",
    "            \"\"\"Simple k-means clustering.\"\"\"\n",
    "            from sklearn.cluster import KMeans\n",
    "            \n",
    "            kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "            clusters = kmeans.fit_predict(embeddings)\n",
    "            \n",
    "            return {\n",
    "                'clusters': clusters,\n",
    "                'centers': kmeans.cluster_centers_,\n",
    "                'inertia': kmeans.inertia_\n",
    "            }\n",
    "    \n",
    "    # Use the pipeline\n",
    "    pipeline = MLPipeline()\n",
    "    \n",
    "    # Generate data\n",
    "    data = np.random.randn(50, 10)\n",
    "    \n",
    "    # Create embeddings\n",
    "    embeddings = pipeline.create_embeddings(data, embedding_dim=32)\n",
    "    print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "    print(f\"Embeddings normalized: {torch.allclose(embeddings.norm(dim=1), torch.ones(len(embeddings)))}\")\n",
    "    \n",
    "    # Compute pairwise similarities\n",
    "    n_samples = 5\n",
    "    similarities = torch.zeros(n_samples, n_samples)\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        for j in range(n_samples):\n",
    "            similarities[i, j] = pipeline.compute_similarity(\n",
    "                embeddings[i], embeddings[j]\n",
    "            )\n",
    "    \n",
    "    print(f\"\\nSimilarity matrix (first {n_samples} samples):\")\n",
    "    print(similarities.numpy().round(3))\n",
    "    \n",
    "    # Cluster embeddings\n",
    "    cluster_results = pipeline.cluster_embeddings(embeddings.numpy())\n",
    "    print(f\"\\nClustering results:\")\n",
    "    print(f\"  Unique clusters: {np.unique(cluster_results['clusters'])}\")\n",
    "    print(f\"  Cluster sizes: {np.bincount(cluster_results['clusters'])}\")\n",
    "    print(f\"  Inertia: {cluster_results['inertia']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Advanced Patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Custom Decorator Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom decorator combinations\n",
    "def robust_processor(timeout_seconds=10):\n",
    "    \"\"\"Combine multiple decorators for robust processing.\"\"\"\n",
    "    def decorator(func):\n",
    "        # Apply decorators in specific order\n",
    "        func = stx.decorators.cache_disk(func)\n",
    "        func = stx.decorators.timeout(seconds=timeout_seconds)(func)\n",
    "        func = stx.decorators.numpy_fn(func)\n",
    "        func = stx.decorators.batch_fn(func)\n",
    "        return func\n",
    "    return decorator\n",
    "\n",
    "# Use custom decorator\n",
    "@robust_processor(timeout_seconds=5)\n",
    "def analyze_signal(signal):\n",
    "    \"\"\"Analyze signal with FFT.\"\"\"\n",
    "    fft = np.fft.fft(signal)\n",
    "    freqs = np.fft.fftfreq(len(signal))\n",
    "    \n",
    "    # Find dominant frequency\n",
    "    power = np.abs(fft)**2\n",
    "    dominant_freq_idx = np.argmax(power[1:len(signal)//2]) + 1\n",
    "    dominant_freq = freqs[dominant_freq_idx]\n",
    "    \n",
    "    return {\n",
    "        'dominant_freq': dominant_freq,\n",
    "        'total_power': power.sum(),\n",
    "        'dc_component': np.abs(fft[0])\n",
    "    }\n",
    "\n",
    "# Generate test signals\n",
    "t = np.linspace(0, 1, 1000)\n",
    "signals = [\n",
    "    np.sin(2 * np.pi * 5 * t),    # 5 Hz\n",
    "    np.sin(2 * np.pi * 10 * t),   # 10 Hz\n",
    "    np.sin(2 * np.pi * 5 * t) + np.sin(2 * np.pi * 15 * t),  # Mixed\n",
    "]\n",
    "\n",
    "# Analyze batch of signals\n",
    "print(\"Analyzing signals...\")\n",
    "results = analyze_signal(signals)\n",
    "\n",
    "print(\"\\nSignal analysis results:\")\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"  Signal {i+1}:\")\n",
    "    print(f\"    Dominant frequency: {result['dominant_freq']:.2f} Hz\")\n",
    "    print(f\"    Total power: {result['total_power']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Decorator Introspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine decorator behavior\n",
    "def analyze_decorator_chain(func):\n",
    "    \"\"\"Analyze the decorator chain of a function.\"\"\"\n",
    "    print(f\"Function: {func.__name__}\")\n",
    "    print(f\"Module: {func.__module__}\")\n",
    "    \n",
    "    # Check for wrapped function\n",
    "    if hasattr(func, '__wrapped__'):\n",
    "        print(\"Decorators detected:\")\n",
    "        current = func\n",
    "        depth = 0\n",
    "        while hasattr(current, '__wrapped__'):\n",
    "            print(f\"  Level {depth}: {current.__class__.__name__ if hasattr(current, '__class__') else 'Unknown'}\")\n",
    "            current = current.__wrapped__\n",
    "            depth += 1\n",
    "    else:\n",
    "        print(\"No decorators detected\")\n",
    "\n",
    "# Test with decorated function\n",
    "@stx.decorators.cache_mem\n",
    "@stx.decorators.numpy_fn\n",
    "def test_function(x):\n",
    "    return x.mean()\n",
    "\n",
    "analyze_decorator_chain(test_function)\n",
    "\n",
    "# Test execution\n",
    "print(\"\\nTest execution:\")\n",
    "data = [1, 2, 3, 4, 5]\n",
    "result = test_function(data)\n",
    "print(f\"Result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Best Practices Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Takeaways\n",
    "\n",
    "1. **Auto-Ordering**: Enable with `enable_auto_order()` to avoid manual ordering\n",
    "2. **Type Safety**: Decorators handle type conversions automatically\n",
    "3. **Performance**: Use caching decorators for expensive computations\n",
    "4. **Batch Processing**: Process multiple samples efficiently\n",
    "5. **Robustness**: Combine decorators for production-ready code\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "1. **Enable Auto-Ordering**:\n",
    "   ```python\n",
    "   from scitex.decorators import enable_auto_order\n",
    "   enable_auto_order()  # At the start of your script\n",
    "   ```\n",
    "\n",
    "2. **Choose the Right Cache**:\n",
    "   ```python\n",
    "   @cache_mem  # For small, frequently accessed data\n",
    "   @cache_disk  # For large computations or persistent cache\n",
    "   ```\n",
    "\n",
    "3. **Combine Decorators Wisely**:\n",
    "   ```python\n",
    "   @batch_fn      # Process in batches\n",
    "   @torch_fn      # Convert to PyTorch\n",
    "   @cache_mem     # Cache results\n",
    "   def process(x):\n",
    "       return model(x)\n",
    "   ```\n",
    "\n",
    "4. **Handle Timeouts Gracefully**:\n",
    "   ```python\n",
    "   @timeout(seconds=30, error_message=\"Custom timeout message\")\n",
    "   def long_computation():\n",
    "       # Add checkpoints for partial results\n",
    "       pass\n",
    "   ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nDecorators module tutorial completed!\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Enable auto-ordering in your projects\")\n",
    "print(\"2. Use type conversion decorators for seamless integration\")\n",
    "print(\"3. Add caching to expensive computations\")\n",
    "print(\"4. Batch process data for better performance\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}