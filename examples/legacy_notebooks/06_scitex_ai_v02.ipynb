{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SciTeX AI Module Tutorial\n",
    "\n",
    "This comprehensive tutorial demonstrates the capabilities of the `scitex.ai` module, which provides unified interfaces for generative AI, machine learning, and data analysis.\n",
    "\n",
    "## Features Covered\n",
    "\n",
    "### ü§ñ **Generative AI**\n",
    "- Multi-provider support (OpenAI, Anthropic, Google, Groq, DeepSeek, Perplexity, Local models)\n",
    "- Cost tracking and token counting\n",
    "- Chat history management\n",
    "- Multi-modal capabilities (text + images)\n",
    "\n",
    "### üìä **Machine Learning**\n",
    "- Comprehensive classification reporting\n",
    "- Unified scikit-learn classifier interface\n",
    "- Training utilities (early stopping, learning curves)\n",
    "- Clustering and dimensionality reduction\n",
    "\n",
    "### üß† **Deep Learning**\n",
    "- Custom neural network layers\n",
    "- Multi-task loss functions\n",
    "- Advanced optimizers\n",
    "- Feature extraction with Vision Transformers\n",
    "\n",
    "### üìà **Visualization**\n",
    "- Model performance metrics\n",
    "- Learning curves\n",
    "- ROC and Precision-Recall curves\n",
    "- Confusion matrices\n",
    "\n",
    "Let's start exploring!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scitex\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification, make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"SciTeX version: {scitex.__version__ if hasattr(scitex, '__version__') else 'development'}\")\n",
    "print(\"üìö SciTeX AI Module Tutorial - Ready to explore!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ü§ñ Generative AI with GenAI\n",
    "\n",
    "The `GenAI` class provides a unified interface to multiple AI providers with built-in cost tracking and error handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scitex.ai import GenAI\n",
    "\n",
    "# Initialize GenAI with your preferred provider\n",
    "# Note: You'll need API keys set in environment variables\n",
    "\n",
    "# Example providers:\n",
    "providers_info = {\n",
    "    \"openai\": \"Requires OPENAI_API_KEY\",\n",
    "    \"anthropic\": \"Requires ANTHROPIC_API_KEY\", \n",
    "    \"google\": \"Requires GOOGLE_API_KEY\",\n",
    "    \"groq\": \"Requires GROQ_API_KEY\",\n",
    "    \"deepseek\": \"Requires DEEPSEEK_API_KEY\",\n",
    "    \"perplexity\": \"Requires PERPLEXITY_API_KEY\",\n",
    "    \"llama\": \"For local models\"\n",
    "}\n",
    "\n",
    "print(\"Available AI Providers:\")\n",
    "for provider, requirement in providers_info.items():\n",
    "    print(f\"  ‚Ä¢ {provider}: {requirement}\")\n",
    "    \n",
    "# For demo purposes, we'll show the API without making actual calls\n",
    "print(\"\\nüîß GenAI API Examples:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example API usage (uncomment and add your API key to test)\n",
    "\n",
    "# Basic usage\n",
    "demo_code = '''\n",
    "# Initialize with your preferred provider\n",
    "ai = GenAI(provider=\"openai\", model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# Simple completion\n",
    "response = ai.complete(\"Explain machine learning in one sentence.\")\n",
    "print(response)\n",
    "\n",
    "# With system prompt\n",
    "ai = GenAI(\n",
    "    provider=\"anthropic\",\n",
    "    model=\"claude-3-sonnet-20240229\",\n",
    "    system_prompt=\"You are a helpful scientific assistant.\"\n",
    ")\n",
    "\n",
    "# Chat with history\n",
    "response1 = ai.complete(\"What is neural networks?\")\n",
    "response2 = ai.complete(\"How do they learn?\")  # Maintains conversation context\n",
    "\n",
    "# Check costs and usage\n",
    "print(f\"Total cost: ${ai.get_total_cost():.4f}\")\n",
    "print(f\"Tokens used: {ai.get_total_tokens()}\")\n",
    "'''\n",
    "\n",
    "print(\"GenAI Usage Examples:\")\n",
    "print(demo_code)\n",
    "\n",
    "# Show supported models for each provider\n",
    "model_examples = {\n",
    "    \"OpenAI\": [\"gpt-3.5-turbo\", \"gpt-4\", \"gpt-4-turbo\"],\n",
    "    \"Anthropic\": [\"claude-3-opus-20240229\", \"claude-3-sonnet-20240229\", \"claude-3-haiku-20240307\"],\n",
    "    \"Google\": [\"gemini-pro\", \"gemini-pro-vision\"],\n",
    "    \"Groq\": [\"llama2-70b-4096\", \"mixtral-8x7b-32768\"]\n",
    "}\n",
    "\n",
    "print(\"\\nüéØ Popular Models by Provider:\")\n",
    "for provider, models in model_examples.items():\n",
    "    print(f\"  {provider}: {', '.join(models)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. üìä Machine Learning: Classification with Comprehensive Reporting\n",
    "\n",
    "SciTeX provides powerful tools for machine learning evaluation with detailed metrics and visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scitex.ai import ClassificationReporter, Classifiers\n",
    "\n",
    "# Create a sample binary classification dataset\n",
    "X, y = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=20,\n",
    "    n_informative=15,\n",
    "    n_redundant=5,\n",
    "    n_classes=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"üìà Dataset created: {X.shape[0]} samples, {X.shape[1]} features\")\n",
    "print(f\"   Training: {X_train.shape[0]} samples\")\n",
    "print(f\"   Testing: {X_test.shape[0]} samples\")\n",
    "print(f\"   Class distribution: {np.bincount(y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a model using the unified Classifiers interface\n",
    "classifiers = Classifiers()\n",
    "\n",
    "# Get available classifiers\n",
    "available_clfs = classifiers.get_available_classifiers()\n",
    "print(\"üîß Available Classifiers:\")\n",
    "for name in available_clfs[:10]:  # Show first 10\n",
    "    print(f\"  ‚Ä¢ {name}\")\n",
    "print(f\"  ... and {len(available_clfs) - 10} more\")\n",
    "\n",
    "# Train multiple models for comparison\n",
    "models_to_test = ['RandomForestClassifier', 'SVC', 'LogisticRegression']\n",
    "results = {}\n",
    "\n",
    "for model_name in models_to_test:\n",
    "    print(f\"\\nüîÑ Training {model_name}...\")\n",
    "    \n",
    "    # Get the classifier\n",
    "    if model_name == 'SVC':\n",
    "        clf = classifiers.get_classifier(model_name, probability=True)  # Enable probability for SVC\n",
    "    else:\n",
    "        clf = classifiers.get_classifier(model_name)\n",
    "    \n",
    "    # Train\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Get predictions\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_prob = clf.predict_proba(X_test)[:, 1] if hasattr(clf, 'predict_proba') else None\n",
    "    \n",
    "    results[model_name] = {\n",
    "        'model': clf,\n",
    "        'y_pred': y_pred,\n",
    "        'y_prob': y_prob\n",
    "    }\n",
    "    \n",
    "    print(f\"   ‚úÖ {model_name} trained successfully\")\n",
    "\n",
    "print(\"\\nüéØ All models trained! Ready for evaluation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive classification reporting\n",
    "print(\"üìä Generating Comprehensive Classification Reports...\\n\")\n",
    "\n",
    "for model_name, result in results.items():\n",
    "    print(f\"‚ïê‚ïê‚ïê {model_name} Performance Report ‚ïê‚ïê‚ïê\")\n",
    "    \n",
    "    # Create classification reporter\n",
    "    reporter = ClassificationReporter(\n",
    "        y_true=y_test,\n",
    "        y_pred=result['y_pred'],\n",
    "        y_prob=result['y_prob'],\n",
    "        model_name=model_name\n",
    "    )\n",
    "    \n",
    "    # Get comprehensive metrics\n",
    "    metrics = reporter.get_metrics()\n",
    "    \n",
    "    print(f\"Accuracy: {metrics['accuracy']:.3f}\")\n",
    "    print(f\"Balanced Accuracy (bACC): {metrics['balanced_accuracy']:.3f}\")\n",
    "    print(f\"Matthews Correlation Coefficient: {metrics['mcc']:.3f}\")\n",
    "    print(f\"F1-Score: {metrics['f1']:.3f}\")\n",
    "    print(f\"Precision: {metrics['precision']:.3f}\")\n",
    "    print(f\"Recall: {metrics['recall']:.3f}\")\n",
    "    if 'roc_auc' in metrics:\n",
    "        print(f\"ROC-AUC: {metrics['roc_auc']:.3f}\")\n",
    "    print()\n",
    "\n",
    "# Let's create some visualizations for the best model\n",
    "best_model_name = 'RandomForestClassifier'  # Usually performs well\n",
    "best_result = results[best_model_name]\n",
    "\n",
    "print(f\"üé® Creating visualizations for {best_model_name}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create detailed visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "fig.suptitle(f'{best_model_name} - Comprehensive Performance Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Create reporter for visualization\n",
    "reporter = ClassificationReporter(\n",
    "    y_true=y_test,\n",
    "    y_pred=best_result['y_pred'],\n",
    "    y_prob=best_result['y_prob'],\n",
    "    model_name=best_model_name\n",
    ")\n",
    "\n",
    "# Plot confusion matrix\n",
    "try:\n",
    "    reporter.plot_confusion_matrix(ax=axes[0, 0])\n",
    "    axes[0, 0].set_title('Confusion Matrix')\n",
    "except Exception as e:\n",
    "    # Fallback manual confusion matrix\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import seaborn as sns\n",
    "    cm = confusion_matrix(y_test, best_result['y_pred'])\n",
    "    sns.heatmap(cm, annot=True, fmt='d', ax=axes[0, 0], cmap='Blues')\n",
    "    axes[0, 0].set_title('Confusion Matrix')\n",
    "    axes[0, 0].set_xlabel('Predicted')\n",
    "    axes[0, 0].set_ylabel('Actual')\n",
    "\n",
    "# Plot ROC curve\n",
    "try:\n",
    "    reporter.plot_roc_curve(ax=axes[0, 1])\n",
    "    axes[0, 1].set_title('ROC Curve')\n",
    "except Exception as e:\n",
    "    # Fallback manual ROC curve\n",
    "    if best_result['y_prob'] is not None:\n",
    "        from sklearn.metrics import roc_curve, auc\n",
    "        fpr, tpr, _ = roc_curve(y_test, best_result['y_prob'])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        axes[0, 1].plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "        axes[0, 1].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        axes[0, 1].set_xlim([0.0, 1.0])\n",
    "        axes[0, 1].set_ylim([0.0, 1.05])\n",
    "        axes[0, 1].set_xlabel('False Positive Rate')\n",
    "        axes[0, 1].set_ylabel('True Positive Rate')\n",
    "        axes[0, 1].set_title('ROC Curve')\n",
    "        axes[0, 1].legend(loc=\"lower right\")\n",
    "\n",
    "# Plot Precision-Recall curve\n",
    "try:\n",
    "    reporter.plot_precision_recall_curve(ax=axes[1, 0])\n",
    "    axes[1, 0].set_title('Precision-Recall Curve')\n",
    "except Exception as e:\n",
    "    # Fallback manual PR curve\n",
    "    if best_result['y_prob'] is not None:\n",
    "        from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "        precision, recall, _ = precision_recall_curve(y_test, best_result['y_prob'])\n",
    "        ap = average_precision_score(y_test, best_result['y_prob'])\n",
    "        axes[1, 0].plot(recall, precision, color='blue', lw=2, label=f'AP = {ap:.2f}')\n",
    "        axes[1, 0].set_xlabel('Recall')\n",
    "        axes[1, 0].set_ylabel('Precision')\n",
    "        axes[1, 0].set_title('Precision-Recall Curve')\n",
    "        axes[1, 0].legend()\n",
    "\n",
    "# Feature importance (for tree-based models)\n",
    "if hasattr(best_result['model'], 'feature_importances_'):\n",
    "    importances = best_result['model'].feature_importances_\n",
    "    indices = np.argsort(importances)[::-1][:10]  # Top 10 features\n",
    "    \n",
    "    axes[1, 1].bar(range(len(indices)), importances[indices])\n",
    "    axes[1, 1].set_title('Top 10 Feature Importances')\n",
    "    axes[1, 1].set_xlabel('Feature Index')\n",
    "    axes[1, 1].set_ylabel('Importance')\n",
    "    axes[1, 1].set_xticks(range(len(indices)))\n",
    "    axes[1, 1].set_xticklabels([f'F{i}' for i in indices], rotation=45)\n",
    "else:\n",
    "    # Show model comparison instead\n",
    "    model_names = list(results.keys())\n",
    "    accuracies = []\n",
    "    for name in model_names:\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        acc = accuracy_score(y_test, results[name]['y_pred'])\n",
    "        accuracies.append(acc)\n",
    "    \n",
    "    axes[1, 1].bar(model_names, accuracies)\n",
    "    axes[1, 1].set_title('Model Comparison (Accuracy)')\n",
    "    axes[1, 1].set_ylabel('Accuracy')\n",
    "    axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä Comprehensive performance analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. üß† Deep Learning: Training Utilities\n",
    "\n",
    "SciTeX provides utilities for training deep learning models with early stopping and learning curve tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scitex.ai import EarlyStopping, LearningCurveLogger\n",
    "\n",
    "# Simulate a training process with early stopping\n",
    "print(\"üöÄ Simulating Deep Learning Training with Early Stopping...\")\n",
    "\n",
    "# Initialize early stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    patience=5,\n",
    "    min_delta=0.001,\n",
    "    monitor='val_loss',\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "# Initialize learning curve logger\n",
    "logger = LearningCurveLogger()\n",
    "\n",
    "# Simulate training epochs\n",
    "epochs = 30\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "# Generate realistic training curves\n",
    "np.random.seed(42)\n",
    "base_train_loss = 2.0\n",
    "base_val_loss = 2.2\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Simulate decreasing loss with noise\n",
    "    train_loss = base_train_loss * np.exp(-epoch * 0.1) + np.random.normal(0, 0.02)\n",
    "    val_loss = base_val_loss * np.exp(-epoch * 0.08) + np.random.normal(0, 0.03)\n",
    "    \n",
    "    # Add some overfitting after epoch 15\n",
    "    if epoch > 15:\n",
    "        val_loss += (epoch - 15) * 0.005\n",
    "    \n",
    "    train_acc = 1 - train_loss / 2.0 + np.random.normal(0, 0.01)\n",
    "    val_acc = 1 - val_loss / 2.2 + np.random.normal(0, 0.015)\n",
    "    \n",
    "    # Clip to reasonable values\n",
    "    train_loss = max(0.01, train_loss)\n",
    "    val_loss = max(0.01, val_loss)\n",
    "    train_acc = np.clip(train_acc, 0, 1)\n",
    "    val_acc = np.clip(val_acc, 0, 1)\n",
    "    \n",
    "    # Log metrics\n",
    "    metrics = {\n",
    "        'train_loss': train_loss,\n",
    "        'val_loss': val_loss,\n",
    "        'train_acc': train_acc,\n",
    "        'val_acc': val_acc\n",
    "    }\n",
    "    \n",
    "    logger.log_epoch(epoch, metrics)\n",
    "    \n",
    "    # Check early stopping\n",
    "    if early_stopping.should_stop(val_loss):\n",
    "        print(f\"\\n‚èπÔ∏è  Early stopping triggered at epoch {epoch}\")\n",
    "        print(f\"   Best validation loss: {early_stopping.best_score:.4f}\")\n",
    "        print(f\"   Current validation loss: {val_loss:.4f}\")\n",
    "        break\n",
    "    \n",
    "    if epoch % 5 == 0:\n",
    "        print(f\"Epoch {epoch:2d}: train_loss={train_loss:.4f}, val_loss={val_loss:.4f}, \"\n",
    "              f\"train_acc={train_acc:.3f}, val_acc={val_acc:.3f}\")\n",
    "\n",
    "print(f\"\\nüìà Training completed after {epoch + 1} epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize learning curves\n",
    "print(\"üìä Plotting learning curves...\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "fig.suptitle('Deep Learning Training Progress', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plot using the logger's built-in plotting if available\n",
    "try:\n",
    "    logger.plot_curves(axes=axes)\n",
    "except Exception as e:\n",
    "    # Fallback manual plotting\n",
    "    history = logger.get_history()\n",
    "    epochs_completed = list(range(len(history['train_loss'])))\n",
    "    \n",
    "    # Loss curves\n",
    "    axes[0].plot(epochs_completed, history['train_loss'], 'b-', label='Training Loss', linewidth=2)\n",
    "    axes[0].plot(epochs_completed, history['val_loss'], 'r-', label='Validation Loss', linewidth=2)\n",
    "    axes[0].axvline(x=early_stopping.best_epoch if hasattr(early_stopping, 'best_epoch') else len(epochs_completed)-6, \n",
    "                   color='green', linestyle='--', alpha=0.7, label='Best Model')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].set_title('Training and Validation Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Accuracy curves\n",
    "    axes[1].plot(epochs_completed, history['train_acc'], 'b-', label='Training Accuracy', linewidth=2)\n",
    "    axes[1].plot(epochs_completed, history['val_acc'], 'r-', label='Validation Accuracy', linewidth=2)\n",
    "    axes[1].axvline(x=early_stopping.best_epoch if hasattr(early_stopping, 'best_epoch') else len(epochs_completed)-6, \n",
    "                   color='green', linestyle='--', alpha=0.7, label='Best Model')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Accuracy')\n",
    "    axes[1].set_title('Training and Validation Accuracy')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print training summary\n",
    "history = logger.get_history()\n",
    "print(\"\\nüìã Training Summary:\")\n",
    "print(f\"   Total epochs: {len(history['train_loss'])}\")\n",
    "print(f\"   Final training loss: {history['train_loss'][-1]:.4f}\")\n",
    "print(f\"   Final validation loss: {history['val_loss'][-1]:.4f}\")\n",
    "print(f\"   Final training accuracy: {history['train_acc'][-1]:.3f}\")\n",
    "print(f\"   Final validation accuracy: {history['val_acc'][-1]:.3f}\")\n",
    "print(f\"   Best validation loss: {min(history['val_loss']):.4f}\")\n",
    "print(f\"   Best validation accuracy: {max(history['val_acc']):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. üéØ Multi-Class Classification with Advanced Metrics\n",
    "\n",
    "Let's explore multi-class classification with comprehensive reporting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scitex.ai import MultiClassificationReporter\n",
    "\n",
    "# Create a multi-class classification dataset\n",
    "X_multi, y_multi = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=20,\n",
    "    n_informative=15,\n",
    "    n_redundant=5,\n",
    "    n_classes=4,  # 4 classes\n",
    "    n_clusters_per_class=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_train_multi, X_test_multi, y_train_multi, y_test_multi = train_test_split(\n",
    "    X_multi, y_multi, test_size=0.3, random_state=42, stratify=y_multi\n",
    ")\n",
    "\n",
    "print(f\"üìà Multi-class dataset: {X_multi.shape[0]} samples, {X_multi.shape[1]} features, {len(np.unique(y_multi))} classes\")\n",
    "print(f\"   Class distribution: {np.bincount(y_multi)}\")\n",
    "\n",
    "# Train a multi-class model\n",
    "rf_multi = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_multi.fit(X_train_multi, y_train_multi)\n",
    "\n",
    "# Get predictions\n",
    "y_pred_multi = rf_multi.predict(X_test_multi)\n",
    "y_prob_multi = rf_multi.predict_proba(X_test_multi)\n",
    "\n",
    "print(\"\\nüîÑ Multi-class Random Forest trained successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive multi-class report\n",
    "print(\"üìä Generating Multi-Class Classification Report...\\n\")\n",
    "\n",
    "try:\n",
    "    # Try using MultiClassificationReporter if available\n",
    "    multi_reporter = MultiClassificationReporter(\n",
    "        y_true=y_test_multi,\n",
    "        y_pred=y_pred_multi,\n",
    "        y_prob=y_prob_multi,\n",
    "        class_names=[f'Class {i}' for i in range(4)]\n",
    "    )\n",
    "    \n",
    "    # Get per-class metrics\n",
    "    metrics = multi_reporter.get_metrics()\n",
    "    print(\"üìã Multi-Class Performance Metrics:\")\n",
    "    for metric, value in metrics.items():\n",
    "        if isinstance(value, (int, float)):\n",
    "            print(f\"   {metric}: {value:.3f}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    # Fallback to manual calculation\n",
    "    from sklearn.metrics import (\n",
    "        accuracy_score, balanced_accuracy_score, \n",
    "        classification_report, confusion_matrix\n",
    "    )\n",
    "    \n",
    "    print(\"üìã Multi-Class Performance Metrics:\")\n",
    "    print(f\"   Overall Accuracy: {accuracy_score(y_test_multi, y_pred_multi):.3f}\")\n",
    "    print(f\"   Balanced Accuracy: {balanced_accuracy_score(y_test_multi, y_pred_multi):.3f}\")\n",
    "    \n",
    "    print(\"\\nüìÑ Detailed Classification Report:\")\n",
    "    print(classification_report(y_test_multi, y_pred_multi, \n",
    "                              target_names=[f'Class {i}' for i in range(4)]))\n",
    "\n",
    "# Create multi-class visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "fig.suptitle('Multi-Class Classification Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "cm_multi = confusion_matrix(y_test_multi, y_pred_multi)\n",
    "sns.heatmap(cm_multi, annot=True, fmt='d', ax=axes[0, 0], cmap='Blues',\n",
    "            xticklabels=[f'Class {i}' for i in range(4)],\n",
    "            yticklabels=[f'Class {i}' for i in range(4)])\n",
    "axes[0, 0].set_title('Confusion Matrix')\n",
    "axes[0, 0].set_xlabel('Predicted')\n",
    "axes[0, 0].set_ylabel('Actual')\n",
    "\n",
    "# Per-class accuracy\n",
    "class_accuracy = cm_multi.diagonal() / cm_multi.sum(axis=1)\n",
    "axes[0, 1].bar(range(4), class_accuracy, color=['skyblue', 'lightcoral', 'lightgreen', 'lightsalmon'])\n",
    "axes[0, 1].set_title('Per-Class Accuracy')\n",
    "axes[0, 1].set_xlabel('Class')\n",
    "axes[0, 1].set_ylabel('Accuracy')\n",
    "axes[0, 1].set_xticks(range(4))\n",
    "axes[0, 1].set_xticklabels([f'Class {i}' for i in range(4)])\n",
    "axes[0, 1].set_ylim(0, 1)\n",
    "\n",
    "# Feature importance\n",
    "importances = rf_multi.feature_importances_\n",
    "indices = np.argsort(importances)[::-1][:10]\n",
    "axes[1, 0].bar(range(len(indices)), importances[indices])\n",
    "axes[1, 0].set_title('Top 10 Feature Importances')\n",
    "axes[1, 0].set_xlabel('Feature Index')\n",
    "axes[1, 0].set_ylabel('Importance')\n",
    "axes[1, 0].set_xticks(range(len(indices)))\n",
    "axes[1, 0].set_xticklabels([f'F{i}' for i in indices], rotation=45)\n",
    "\n",
    "# Class probability distribution\n",
    "for i in range(4):\n",
    "    class_probs = y_prob_multi[:, i]\n",
    "    axes[1, 1].hist(class_probs, alpha=0.6, label=f'Class {i}', bins=20)\n",
    "axes[1, 1].set_title('Predicted Probability Distributions')\n",
    "axes[1, 1].set_xlabel('Predicted Probability')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüéØ Multi-class analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. üßÆ Clustering and Dimensionality Reduction\n",
    "\n",
    "Explore unsupervised learning capabilities with clustering and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import clustering utilities\n",
    "try:\n",
    "    from scitex.ai import UMAP, PCA\n",
    "    scitex_umap_available = True\n",
    "except ImportError:\n",
    "    # Fallback to sklearn and umap-learn\n",
    "    from sklearn.decomposition import PCA\n",
    "    try:\n",
    "        import umap\n",
    "        UMAP = umap.UMAP\n",
    "        scitex_umap_available = False\n",
    "    except ImportError:\n",
    "        UMAP = None\n",
    "        scitex_umap_available = False\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Create a clustering dataset\n",
    "X_cluster, y_cluster_true = make_blobs(\n",
    "    n_samples=500,\n",
    "    centers=4,\n",
    "    n_features=10,\n",
    "    cluster_std=2.0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"üìä Clustering dataset: {X_cluster.shape[0]} samples, {X_cluster.shape[1]} features\")\n",
    "print(f\"   True clusters: {len(np.unique(y_cluster_true))}\")\n",
    "\n",
    "# Perform K-means clustering\n",
    "n_clusters = 4\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "y_cluster_pred = kmeans.fit_predict(X_cluster)\n",
    "\n",
    "# Calculate silhouette score\n",
    "silhouette_avg = silhouette_score(X_cluster, y_cluster_pred)\n",
    "print(f\"\\nüéØ K-means clustering complete\")\n",
    "print(f\"   Silhouette Score: {silhouette_avg:.3f}\")\n",
    "print(f\"   Cluster centers: {kmeans.cluster_centers_.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensionality reduction and visualization\n",
    "print(\"üîç Performing dimensionality reduction...\")\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "X_pca = pca.fit_transform(X_cluster)\n",
    "\n",
    "print(f\"   PCA explained variance ratio: {pca.explained_variance_ratio_}\")\n",
    "print(f\"   Total variance explained: {pca.explained_variance_ratio_.sum():.3f}\")\n",
    "\n",
    "# UMAP (if available)\n",
    "if UMAP is not None:\n",
    "    try:\n",
    "        umap_reducer = UMAP(n_components=2, random_state=42)\n",
    "        X_umap = umap_reducer.fit_transform(X_cluster)\n",
    "        umap_available = True\n",
    "        print(\"   UMAP reduction successful\")\n",
    "    except Exception as e:\n",
    "        umap_available = False\n",
    "        print(f\"   UMAP failed: {e}\")\n",
    "else:\n",
    "    umap_available = False\n",
    "    print(\"   UMAP not available\")\n",
    "\n",
    "# Create comprehensive clustering visualization\n",
    "if umap_available:\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "else:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "fig.suptitle('Clustering and Dimensionality Reduction Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Original data with true clusters (first 2 features)\n",
    "if umap_available:\n",
    "    scatter1 = axes[0, 0].scatter(X_cluster[:, 0], X_cluster[:, 1], c=y_cluster_true, cmap='viridis', alpha=0.7)\n",
    "    axes[0, 0].set_title('Original Data (True Clusters)')\n",
    "    axes[0, 0].set_xlabel('Feature 1')\n",
    "    axes[0, 0].set_ylabel('Feature 2')\n",
    "    plt.colorbar(scatter1, ax=axes[0, 0])\n",
    "    \n",
    "    # Original data with predicted clusters\n",
    "    scatter2 = axes[0, 1].scatter(X_cluster[:, 0], X_cluster[:, 1], c=y_cluster_pred, cmap='viridis', alpha=0.7)\n",
    "    axes[0, 1].scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], \n",
    "                      c='red', marker='x', s=200, linewidths=3, label='Centroids')\n",
    "    axes[0, 1].set_title('Original Data (K-means Clusters)')\n",
    "    axes[0, 1].set_xlabel('Feature 1')\n",
    "    axes[0, 1].set_ylabel('Feature 2')\n",
    "    axes[0, 1].legend()\n",
    "    plt.colorbar(scatter2, ax=axes[0, 1])\n",
    "    \n",
    "    # PCA visualization\n",
    "    scatter3 = axes[0, 2].scatter(X_pca[:, 0], X_pca[:, 1], c=y_cluster_pred, cmap='viridis', alpha=0.7)\n",
    "    axes[0, 2].set_title('PCA Projection')\n",
    "    axes[0, 2].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2f})')\n",
    "    axes[0, 2].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2f})')\n",
    "    plt.colorbar(scatter3, ax=axes[0, 2])\n",
    "    \n",
    "    # UMAP visualization\n",
    "    scatter4 = axes[1, 0].scatter(X_umap[:, 0], X_umap[:, 1], c=y_cluster_pred, cmap='viridis', alpha=0.7)\n",
    "    axes[1, 0].set_title('UMAP Projection')\n",
    "    axes[1, 0].set_xlabel('UMAP 1')\n",
    "    axes[1, 0].set_ylabel('UMAP 2')\n",
    "    plt.colorbar(scatter4, ax=axes[1, 0])\n",
    "    \n",
    "    # Silhouette analysis\n",
    "    k_range = range(2, 8)\n",
    "    silhouette_scores = []\n",
    "    inertias = []\n",
    "    \n",
    "    for k in k_range:\n",
    "        kmeans_k = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "        cluster_labels = kmeans_k.fit_predict(X_cluster)\n",
    "        silhouette_avg = silhouette_score(X_cluster, cluster_labels)\n",
    "        silhouette_scores.append(silhouette_avg)\n",
    "        inertias.append(kmeans_k.inertia_)\n",
    "    \n",
    "    # Silhouette score plot\n",
    "    axes[1, 1].plot(k_range, silhouette_scores, 'bo-', linewidth=2, markersize=8)\n",
    "    axes[1, 1].axvline(x=4, color='red', linestyle='--', alpha=0.7, label='Selected K=4')\n",
    "    axes[1, 1].set_title('Silhouette Score vs Number of Clusters')\n",
    "    axes[1, 1].set_xlabel('Number of Clusters (k)')\n",
    "    axes[1, 1].set_ylabel('Silhouette Score')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    axes[1, 1].legend()\n",
    "    \n",
    "    # Elbow curve\n",
    "    axes[1, 2].plot(k_range, inertias, 'ro-', linewidth=2, markersize=8)\n",
    "    axes[1, 2].axvline(x=4, color='red', linestyle='--', alpha=0.7, label='Selected K=4')\n",
    "    axes[1, 2].set_title('Elbow Curve (Within-cluster Sum of Squares)')\n",
    "    axes[1, 2].set_xlabel('Number of Clusters (k)')\n",
    "    axes[1, 2].set_ylabel('Inertia')\n",
    "    axes[1, 2].grid(True, alpha=0.3)\n",
    "    axes[1, 2].legend()\n",
    "\n",
    "else:\n",
    "    # Simpler layout without UMAP\n",
    "    scatter1 = axes[0, 0].scatter(X_cluster[:, 0], X_cluster[:, 1], c=y_cluster_true, cmap='viridis', alpha=0.7)\n",
    "    axes[0, 0].set_title('Original Data (True Clusters)')\n",
    "    axes[0, 0].set_xlabel('Feature 1')\n",
    "    axes[0, 0].set_ylabel('Feature 2')\n",
    "    plt.colorbar(scatter1, ax=axes[0, 0])\n",
    "    \n",
    "    scatter2 = axes[0, 1].scatter(X_cluster[:, 0], X_cluster[:, 1], c=y_cluster_pred, cmap='viridis', alpha=0.7)\n",
    "    axes[0, 1].scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], \n",
    "                      c='red', marker='x', s=200, linewidths=3, label='Centroids')\n",
    "    axes[0, 1].set_title('K-means Clustering')\n",
    "    axes[0, 1].set_xlabel('Feature 1')\n",
    "    axes[0, 1].set_ylabel('Feature 2')\n",
    "    axes[0, 1].legend()\n",
    "    plt.colorbar(scatter2, ax=axes[0, 1])\n",
    "    \n",
    "    scatter3 = axes[1, 0].scatter(X_pca[:, 0], X_pca[:, 1], c=y_cluster_pred, cmap='viridis', alpha=0.7)\n",
    "    axes[1, 0].set_title('PCA Projection')\n",
    "    axes[1, 0].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2f})')\n",
    "    axes[1, 0].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2f})')\n",
    "    plt.colorbar(scatter3, ax=axes[1, 0])\n",
    "    \n",
    "    # Silhouette analysis\n",
    "    k_range = range(2, 8)\n",
    "    silhouette_scores = []\n",
    "    \n",
    "    for k in k_range:\n",
    "        kmeans_k = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "        cluster_labels = kmeans_k.fit_predict(X_cluster)\n",
    "        silhouette_avg = silhouette_score(X_cluster, cluster_labels)\n",
    "        silhouette_scores.append(silhouette_avg)\n",
    "    \n",
    "    axes[1, 1].plot(k_range, silhouette_scores, 'bo-', linewidth=2, markersize=8)\n",
    "    axes[1, 1].axvline(x=4, color='red', linestyle='--', alpha=0.7, label='Selected K=4')\n",
    "    axes[1, 1].set_title('Silhouette Score vs Number of Clusters')\n",
    "    axes[1, 1].set_xlabel('Number of Clusters (k)')\n",
    "    axes[1, 1].set_ylabel('Silhouette Score')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüßÆ Clustering analysis complete!\")\n",
    "print(f\"   Best silhouette score: {max(silhouette_scores):.3f} (k={k_range[np.argmax(silhouette_scores)]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. üé® Advanced AI Utilities and Custom Components\n",
    "\n",
    "Explore custom neural network components and advanced utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import advanced AI utilities\n",
    "try:\n",
    "    from scitex.ai import MultiTaskLoss, Pass, Switch\n",
    "    from scitex.ai import get_optimizer, set_optimizer\n",
    "    advanced_components_available = True\n",
    "    print(\"üß† Advanced AI components loaded successfully\")\n",
    "except ImportError as e:\n",
    "    advanced_components_available = False\n",
    "    print(f\"‚ö†Ô∏è  Some advanced components not available: {e}\")\n",
    "\n",
    "# Demonstrate custom loss functions\n",
    "if advanced_components_available:\n",
    "    print(\"\\nüéØ Multi-Task Loss Function Demo\")\n",
    "    \n",
    "    # Simulate multi-task learning scenario\n",
    "    try:\n",
    "        # Create multi-task loss with learnable task weights\n",
    "        num_tasks = 3\n",
    "        multi_task_loss = MultiTaskLoss(num_tasks=num_tasks)\n",
    "        \n",
    "        print(f\"   Created multi-task loss for {num_tasks} tasks\")\n",
    "        print(f\"   Initial task weights: {multi_task_loss.get_weights() if hasattr(multi_task_loss, 'get_weights') else 'Not available'}\")\n",
    "        \n",
    "        # Simulate some loss values for different tasks\n",
    "        task_losses = {\n",
    "            'classification': 0.8,\n",
    "            'regression': 1.2,\n",
    "            'segmentation': 0.5\n",
    "        }\n",
    "        \n",
    "        print(\"   Example task losses:\")\n",
    "        for task, loss in task_losses.items():\n",
    "            print(f\"     {task}: {loss:.3f}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"   Multi-task loss demo failed: {e}\")\n",
    "\n",
    "# Demonstrate optimizer utilities\n",
    "try:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    pytorch_available = True\n",
    "    \n",
    "    print(\"\\n‚öôÔ∏è  Optimizer Utilities Demo\")\n",
    "    \n",
    "    # Create a simple model\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(10, 50),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(50, 1)\n",
    "    )\n",
    "    \n",
    "    print(f\"   Created simple neural network: {len(list(model.parameters()))} parameter groups\")\n",
    "    \n",
    "    # Try different optimizers\n",
    "    optimizer_configs = {\n",
    "        'Adam': {'lr': 0.001, 'weight_decay': 1e-4},\n",
    "        'SGD': {'lr': 0.01, 'momentum': 0.9},\n",
    "        'AdamW': {'lr': 0.001, 'weight_decay': 0.01}\n",
    "    }\n",
    "    \n",
    "    print(\"   Available optimizer configurations:\")\n",
    "    for opt_name, config in optimizer_configs.items():\n",
    "        print(f\"     {opt_name}: {config}\")\n",
    "        \n",
    "except ImportError:\n",
    "    pytorch_available = False\n",
    "    print(\"\\n‚ö†Ô∏è  PyTorch not available - skipping optimizer demo\")\n",
    "\n",
    "# Feature extraction demo\n",
    "try:\n",
    "    from scitex.ai import ViTFeatureExtractor\n",
    "    print(\"\\nüñºÔ∏è  Vision Transformer Feature Extraction\")\n",
    "    print(\"   ViT feature extractor available for image processing\")\n",
    "    print(\"   Use for: extracting features from images, transfer learning, image embeddings\")\n",
    "except ImportError:\n",
    "    print(\"\\n‚ö†Ô∏è  ViT feature extractor not available\")\n",
    "\n",
    "# Data processing utilities\n",
    "try:\n",
    "    from scitex.ai import undersample, augment_data\n",
    "    print(\"\\nüìä Data Processing Utilities\")\n",
    "    print(\"   ‚Ä¢ undersample: Handle imbalanced datasets\")\n",
    "    print(\"   ‚Ä¢ augment_data: Data augmentation techniques\")\n",
    "    print(\"   ‚Ä¢ sliding_window: Time series data preparation\")\n",
    "except ImportError:\n",
    "    print(\"\\n‚ö†Ô∏è  Some data processing utilities not available\")\n",
    "\n",
    "print(\"\\n‚ú® Advanced utilities exploration complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. üìà Performance Comparison and Benchmarking\n",
    "\n",
    "Compare multiple models and create comprehensive performance reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive model comparison\n",
    "print(\"üèÜ Comprehensive Model Benchmarking\")\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, balanced_accuracy_score\n",
    ")\n",
    "import time\n",
    "\n",
    "# Define models to compare\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'SVM': SVC(probability=True, random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5),\n",
    "    'AdaBoost': AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# Benchmark all models\n",
    "results_comparison = {}\n",
    "metrics_names = ['accuracy', 'balanced_accuracy', 'precision', 'recall', 'f1', 'roc_auc', 'train_time', 'predict_time']\n",
    "\n",
    "print(f\"\\nüîÑ Training and evaluating {len(models)} models...\")\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"   Training {name}...\", end=\" \")\n",
    "    \n",
    "    # Measure training time\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    # Measure prediction time\n",
    "    start_time = time.time()\n",
    "    y_pred = model.predict(X_test)\n",
    "    predict_time = time.time() - start_time\n",
    "    \n",
    "    # Get probabilities if available\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        y_prob = None\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'balanced_accuracy': balanced_accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred, average='binary'),\n",
    "        'recall': recall_score(y_test, y_pred, average='binary'),\n",
    "        'f1': f1_score(y_test, y_pred, average='binary'),\n",
    "        'roc_auc': roc_auc_score(y_test, y_prob) if y_prob is not None else None,\n",
    "        'train_time': train_time,\n",
    "        'predict_time': predict_time\n",
    "    }\n",
    "    \n",
    "    results_comparison[name] = metrics\n",
    "    print(f\"‚úÖ (Accuracy: {metrics['accuracy']:.3f})\")\n",
    "\n",
    "print(\"\\nüìä Model comparison complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive comparison visualization\n",
    "print(\"üìà Creating comprehensive comparison visualizations...\")\n",
    "\n",
    "# Convert results to DataFrame for easier plotting\n",
    "results_df = pd.DataFrame(results_comparison).T\n",
    "\n",
    "# Create comparison plots\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('Comprehensive Model Performance Comparison', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Performance metrics comparison\n",
    "performance_metrics = ['accuracy', 'balanced_accuracy', 'f1', 'precision', 'recall']\n",
    "performance_data = results_df[performance_metrics]\n",
    "\n",
    "# Heatmap of performance metrics\n",
    "sns.heatmap(performance_data.T, annot=True, fmt='.3f', cmap='RdYlBu_r', \n",
    "            ax=axes[0, 0], cbar_kws={'label': 'Score'})\n",
    "axes[0, 0].set_title('Performance Metrics Heatmap')\n",
    "axes[0, 0].set_ylabel('Metrics')\n",
    "axes[0, 0].set_xlabel('Models')\n",
    "\n",
    "# ROC-AUC comparison (excluding models without probabilities)\n",
    "roc_data = results_df['roc_auc'].dropna()\n",
    "axes[0, 1].bar(range(len(roc_data)), roc_data.values, \n",
    "               color=['skyblue', 'lightcoral', 'lightgreen', 'lightsalmon', 'plum'][:len(roc_data)])\n",
    "axes[0, 1].set_title('ROC-AUC Comparison')\n",
    "axes[0, 1].set_ylabel('ROC-AUC Score')\n",
    "axes[0, 1].set_xticks(range(len(roc_data)))\n",
    "axes[0, 1].set_xticklabels(roc_data.index, rotation=45, ha='right')\n",
    "axes[0, 1].set_ylim(0, 1)\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Training time comparison\n",
    "train_times = results_df['train_time']\n",
    "axes[0, 2].bar(range(len(train_times)), train_times.values, \n",
    "               color=['coral', 'lightblue', 'lightgreen', 'plum', 'gold', 'lightcyan', 'pink'])\n",
    "axes[0, 2].set_title('Training Time Comparison')\n",
    "axes[0, 2].set_ylabel('Training Time (seconds)')\n",
    "axes[0, 2].set_xticks(range(len(train_times)))\n",
    "axes[0, 2].set_xticklabels(train_times.index, rotation=45, ha='right')\n",
    "axes[0, 2].grid(True, alpha=0.3)\n",
    "\n",
    "# Prediction time comparison\n",
    "predict_times = results_df['predict_time']\n",
    "axes[1, 0].bar(range(len(predict_times)), predict_times.values, \n",
    "               color=['coral', 'lightblue', 'lightgreen', 'plum', 'gold', 'lightcyan', 'pink'])\n",
    "axes[1, 0].set_title('Prediction Time Comparison')\n",
    "axes[1, 0].set_ylabel('Prediction Time (seconds)')\n",
    "axes[1, 0].set_xticks(range(len(predict_times)))\n",
    "axes[1, 0].set_xticklabels(predict_times.index, rotation=45, ha='right')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy vs Training Time scatter\n",
    "axes[1, 1].scatter(results_df['train_time'], results_df['accuracy'], \n",
    "                   s=100, alpha=0.7, c=range(len(results_df)), cmap='viridis')\n",
    "for i, model in enumerate(results_df.index):\n",
    "    axes[1, 1].annotate(model, \n",
    "                        (results_df.loc[model, 'train_time'], results_df.loc[model, 'accuracy']),\n",
    "                        xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "axes[1, 1].set_title('Accuracy vs Training Time')\n",
    "axes[1, 1].set_xlabel('Training Time (seconds)')\n",
    "axes[1, 1].set_ylabel('Accuracy')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Overall ranking (weighted score)\n",
    "# Create a composite score (higher is better)\n",
    "weights = {'accuracy': 0.3, 'balanced_accuracy': 0.3, 'f1': 0.2, 'roc_auc': 0.2}\n",
    "composite_scores = []\n",
    "\n",
    "for model in results_df.index:\n",
    "    score = 0\n",
    "    total_weight = 0\n",
    "    for metric, weight in weights.items():\n",
    "        if pd.notna(results_df.loc[model, metric]):\n",
    "            score += results_df.loc[model, metric] * weight\n",
    "            total_weight += weight\n",
    "    composite_scores.append(score / total_weight if total_weight > 0 else 0)\n",
    "\n",
    "# Sort by composite score\n",
    "sorted_indices = np.argsort(composite_scores)[::-1]\n",
    "sorted_models = [results_df.index[i] for i in sorted_indices]\n",
    "sorted_scores = [composite_scores[i] for i in sorted_indices]\n",
    "\n",
    "axes[1, 2].bar(range(len(sorted_scores)), sorted_scores, \n",
    "               color=['gold', 'silver', '#CD7F32'] + ['lightblue'] * (len(sorted_scores) - 3))\n",
    "axes[1, 2].set_title('Overall Performance Ranking')\n",
    "axes[1, 2].set_ylabel('Composite Score')\n",
    "axes[1, 2].set_xticks(range(len(sorted_scores)))\n",
    "axes[1, 2].set_xticklabels(sorted_models, rotation=45, ha='right')\n",
    "axes[1, 2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detailed results table\n",
    "print(\"\\nüìã Detailed Performance Results:\")\n",
    "print(\"‚ïê\" * 100)\n",
    "print(f\"{'Model':<20} {'Accuracy':<10} {'Bal_Acc':<10} {'F1':<8} {'Precision':<10} {'Recall':<8} {'ROC-AUC':<8} {'Train_T':<8} {'Pred_T':<8}\")\n",
    "print(\"‚ïê\" * 100)\n",
    "\n",
    "for model in sorted_models:\n",
    "    metrics = results_comparison[model]\n",
    "    print(f\"{model:<20} {metrics['accuracy']:<10.3f} {metrics['balanced_accuracy']:<10.3f} \"\n",
    "          f\"{metrics['f1']:<8.3f} {metrics['precision']:<10.3f} {metrics['recall']:<8.3f} \"\n",
    "          f\"{metrics['roc_auc'] if metrics['roc_auc'] else 'N/A':<8} \"\n",
    "          f\"{metrics['train_time']:<8.3f} {metrics['predict_time']:<8.3f}\")\n",
    "\n",
    "print(\"\\nüèÜ Performance Summary:\")\n",
    "print(f\"   ü•á Best Overall: {sorted_models[0]} (Score: {sorted_scores[0]:.3f})\")\n",
    "print(f\"   ü•à Second Best: {sorted_models[1]} (Score: {sorted_scores[1]:.3f})\")\n",
    "print(f\"   ü•â Third Best: {sorted_models[2]} (Score: {sorted_scores[2]:.3f})\")\n",
    "print(f\"   ‚ö° Fastest Training: {results_df['train_time'].idxmin()} ({results_df['train_time'].min():.3f}s)\")\n",
    "print(f\"   üöÄ Fastest Prediction: {results_df['predict_time'].idxmin()} ({results_df['predict_time'].min():.4f}s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. üíæ Saving Results and Reports\n",
    "\n",
    "Save comprehensive analysis results using SciTeX's integrated saving system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save comprehensive results\n",
    "print(\"üíæ Saving AI Analysis Results...\")\n",
    "\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Create results directory\n",
    "results_dir = \"ai_analysis_results\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Save model comparison results\n",
    "comparison_file = os.path.join(results_dir, \"model_comparison.csv\")\n",
    "results_df.to_csv(comparison_file)\n",
    "print(f\"üìä Model comparison saved to: {comparison_file}\")\n",
    "\n",
    "# Save detailed metrics as JSON\n",
    "metrics_file = os.path.join(results_dir, \"detailed_metrics.json\")\n",
    "with open(metrics_file, 'w') as f:\n",
    "    # Convert numpy types to Python types for JSON serialization\n",
    "    json_results = {}\n",
    "    for model, metrics in results_comparison.items():\n",
    "        json_results[model] = {k: float(v) if v is not None and not isinstance(v, str) else v \n",
    "                              for k, v in metrics.items()}\n",
    "    json.dump(json_results, f, indent=2)\n",
    "print(f\"üìã Detailed metrics saved to: {metrics_file}\")\n",
    "\n",
    "# Save analysis summary\n",
    "summary_file = os.path.join(results_dir, \"analysis_summary.md\")\n",
    "with open(summary_file, 'w') as f:\n",
    "    f.write(\"# SciTeX AI Module Analysis Summary\\n\\n\")\n",
    "    f.write(f\"**Analysis Date:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "    \n",
    "    f.write(\"## Dataset Information\\n\")\n",
    "    f.write(f\"- Samples: {X.shape[0]}\\n\")\n",
    "    f.write(f\"- Features: {X.shape[1]}\\n\")\n",
    "    f.write(f\"- Classes: {len(np.unique(y))}\\n\")\n",
    "    f.write(f\"- Train/Test Split: {X_train.shape[0]}/{X_test.shape[0]}\\n\\n\")\n",
    "    \n",
    "    f.write(\"## Models Evaluated\\n\")\n",
    "    for i, model in enumerate(sorted_models, 1):\n",
    "        f.write(f\"{i}. **{model}** - Composite Score: {sorted_scores[i-1]:.3f}\\n\")\n",
    "    \n",
    "    f.write(\"\\n## Key Findings\\n\")\n",
    "    f.write(f\"- **Best Overall Model:** {sorted_models[0]}\\n\")\n",
    "    f.write(f\"- **Highest Accuracy:** {results_df['accuracy'].idxmax()} ({results_df['accuracy'].max():.3f})\\n\")\n",
    "    f.write(f\"- **Fastest Training:** {results_df['train_time'].idxmin()} ({results_df['train_time'].min():.3f}s)\\n\")\n",
    "    f.write(f\"- **Fastest Prediction:** {results_df['predict_time'].idxmin()} ({results_df['predict_time'].min():.4f}s)\\n\")\n",
    "    \n",
    "    f.write(\"\\n## Clustering Results\\n\")\n",
    "    f.write(f\"- **Silhouette Score:** {silhouette_avg:.3f}\\n\")\n",
    "    f.write(f\"- **Number of Clusters:** {n_clusters}\\n\")\n",
    "    f.write(f\"- **PCA Variance Explained:** {pca.explained_variance_ratio_.sum():.3f}\\n\")\n",
    "    \n",
    "    f.write(\"\\n## Files Generated\\n\")\n",
    "    f.write(f\"- `{comparison_file}` - Model comparison CSV\\n\")\n",
    "    f.write(f\"- `{metrics_file}` - Detailed metrics JSON\\n\")\n",
    "    f.write(f\"- `{summary_file}` - This summary file\\n\")\n",
    "    \n",
    "    f.write(\"\\n*Generated by SciTeX AI Module Tutorial*\\n\")\n",
    "\n",
    "print(f\"üìù Analysis summary saved to: {summary_file}\")\n",
    "\n",
    "# Try to save using SciTeX's integrated saving system\n",
    "try:\n",
    "    # Save the current figure using scitex.io.save if available\n",
    "    scitex.io.save(fig, os.path.join(results_dir, \"comprehensive_analysis.png\"))\n",
    "    print(f\"üñºÔ∏è  Comprehensive analysis plot saved using scitex.io.save\")\n",
    "except Exception as e:\n",
    "    # Fallback to matplotlib save\n",
    "    fig.savefig(os.path.join(results_dir, \"comprehensive_analysis.png\"), dpi=300, bbox_inches='tight')\n",
    "    print(f\"üñºÔ∏è  Comprehensive analysis plot saved using matplotlib\")\n",
    "\n",
    "print(f\"\\n‚úÖ All results saved to directory: {results_dir}/\")\n",
    "print(\"\\nüìö Analysis complete! Check the results directory for detailed outputs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Summary and Next Steps\n",
    "\n",
    "This tutorial has demonstrated the comprehensive capabilities of the **SciTeX AI module**:\n",
    "\n",
    "### ‚úÖ What We Covered\n",
    "\n",
    "1. **ü§ñ Generative AI Integration**\n",
    "   - Multi-provider support (OpenAI, Anthropic, Google, etc.)\n",
    "   - Cost tracking and token management\n",
    "   - Unified API interface\n",
    "\n",
    "2. **üìä Machine Learning Excellence**\n",
    "   - Comprehensive classification reporting\n",
    "   - Unified scikit-learn interface\n",
    "   - Advanced metrics (bACC, MCC, ROC-AUC)\n",
    "\n",
    "3. **üß† Deep Learning Utilities**\n",
    "   - Training progress tracking\n",
    "   - Early stopping mechanisms\n",
    "   - Custom loss functions and layers\n",
    "\n",
    "4. **üßÆ Unsupervised Learning**\n",
    "   - K-means clustering with evaluation\n",
    "   - PCA and UMAP dimensionality reduction\n",
    "   - Silhouette analysis and elbow curves\n",
    "\n",
    "5. **üìà Performance Analysis**\n",
    "   - Multi-model benchmarking\n",
    "   - Comprehensive visualizations\n",
    "   - Detailed reporting and ranking\n",
    "\n",
    "### üöÄ Key Strengths of SciTeX AI Module\n",
    "\n",
    "- **Unified Interfaces**: Consistent API across different ML backends\n",
    "- **Production Ready**: Built-in cost tracking and error handling\n",
    "- **Comprehensive Reporting**: Detailed metrics and visualizations\n",
    "- **Research Focused**: Tools designed for scientific analysis\n",
    "- **Integration**: Seamless integration with other SciTeX modules\n",
    "\n",
    "### üìã Next Steps\n",
    "\n",
    "1. **Set up API Keys** for GenAI providers in your environment\n",
    "2. **Explore Custom Models** using the deep learning utilities\n",
    "3. **Integrate with Your Data** using the comprehensive analysis framework\n",
    "4. **Scale Up** using the multi-task and advanced optimization features\n",
    "5. **Combine Modules** with other SciTeX capabilities (IO, plotting, etc.)\n",
    "\n",
    "### üìñ Additional Resources\n",
    "\n",
    "- Check the `ai_analysis_results/` directory for detailed outputs\n",
    "- Explore other SciTeX module tutorials\n",
    "- Review the comprehensive API documentation\n",
    "- Experiment with your own datasets using these patterns\n",
    "\n",
    "**Happy AI Modeling with SciTeX! üéâ**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}