{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SciTeX Web Tutorial\n",
    "\n",
    "This notebook demonstrates how to use the `scitex.web` module for web-based scientific research and data collection.\n",
    "\n",
    "## Features Covered\n",
    "\n",
    "* PubMed database searching and article retrieval\n",
    "* Automated BibTeX generation from scientific articles\n",
    "* Web content extraction and summarization\n",
    "* URL crawling with content analysis\n",
    "* Scientific literature management\n",
    "* CrossRef metrics integration\n",
    "* Asynchronous batch processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scitex import web as stx_web\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "import asyncio\n",
    "\n",
    "print(\"SciTeX Web Tutorial\")\n",
    "print(\"Available functions:\")\n",
    "available_functions = [func for func in dir(stx_web) if not func.startswith('_')]\n",
    "for i, func in enumerate(available_functions):\n",
    "    if i % 3 == 0:\n",
    "        print()\n",
    "    print(f\"{func:<25}\", end=\"\")\n",
    "print()\n",
    "\n",
    "# Note: Some functions require internet access and API keys\n",
    "print(\"\\n⚠️ Note: This tutorial demonstrates web functionality.\")\n",
    "print(\"   Some examples may require internet access and API keys.\")\n",
    "print(\"   Examples are designed to work with mock data when needed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. PubMed Literature Search\n",
    "\n",
    "### Basic PubMed Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate PubMed search functionality\n",
    "print(\"PubMed Literature Search Examples:\")\n",
    "print(\"=\" * 34)\n",
    "\n",
    "# Example search queries for different research areas\n",
    "research_queries = {\n",
    "    \"Neuroscience\": \"epilepsy prediction machine learning\",\n",
    "    \"AI/ML\": \"deep learning medical imaging\", \n",
    "    \"Statistics\": \"bayesian analysis clinical trials\",\n",
    "    \"Bioinformatics\": \"genomic data analysis python\",\n",
    "    \"Physics\": \"quantum computing algorithms\"\n",
    "}\n",
    "\n",
    "print(\"Research Query Examples:\")\n",
    "for field, query in research_queries.items():\n",
    "    print(f\"{field:<15}: '{query}'\")\n",
    "\n",
    "# Demonstrate search functionality (mock example)\n",
    "def mock_pubmed_search(query, n_entries=5):\n",
    "    \"\"\"Mock PubMed search for demonstration purposes.\"\"\"\n",
    "    print(f\"\\nSearching PubMed for: '{query}'\")\n",
    "    print(f\"Requested entries: {n_entries}\")\n",
    "    \n",
    "    # Simulate search results\n",
    "    mock_results = {\n",
    "        \"query\": query,\n",
    "        \"total_found\": np.random.randint(50, 500),\n",
    "        \"retrieved\": n_entries,\n",
    "        \"status\": \"success\",\n",
    "        \"bibtex_file\": f\"pubmed_{query.replace(' ', '_')}.bib\"\n",
    "    }\n",
    "    \n",
    "    print(f\"✓ Found {mock_results['total_found']} articles\")\n",
    "    print(f\"✓ Retrieved {mock_results['retrieved']} detailed entries\")\n",
    "    print(f\"✓ Saved to: {mock_results['bibtex_file']}\")\n",
    "    \n",
    "    return mock_results\n",
    "\n",
    "# Example searches\n",
    "search_examples = [\n",
    "    (\"machine learning healthcare\", 10),\n",
    "    (\"CRISPR gene editing\", 5),\n",
    "    (\"neural networks signal processing\", 8)\n",
    "]\n",
    "\n",
    "search_results = []\n",
    "for query, n_entries in search_examples:\n",
    "    result = mock_pubmed_search(query, n_entries)\n",
    "    search_results.append(result)\n",
    "\n",
    "# Summary statistics\n",
    "total_articles = sum(r['total_found'] for r in search_results)\n",
    "total_retrieved = sum(r['retrieved'] for r in search_results)\n",
    "\n",
    "print(f\"\\nSearch Summary:\")\n",
    "print(f\"Total queries: {len(search_results)}\")\n",
    "print(f\"Total articles found: {total_articles:,}\")\n",
    "print(f\"Total articles retrieved: {total_retrieved}\")\n",
    "print(f\"Average articles per query: {total_articles/len(search_results):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BibTeX Generation and Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate BibTeX generation functionality\n",
    "print(\"BibTeX Generation and Management:\")\n",
    "print(\"=\" * 33)\n",
    "\n",
    "# Mock paper data structure\n",
    "def create_mock_paper(title, authors, journal, year, pmid, doi=\"\"):\n",
    "    \"\"\"Create mock paper data structure.\"\"\"\n",
    "    return {\n",
    "        \"title\": title,\n",
    "        \"authors\": [{\"name\": author} for author in authors],\n",
    "        \"source\": journal,\n",
    "        \"pubdate\": f\"{year} Jan\",\n",
    "        \"pmid\": pmid,\n",
    "        \"doi\": doi\n",
    "    }\n",
    "\n",
    "# Sample scientific papers\n",
    "sample_papers = {\n",
    "    \"12345678\": create_mock_paper(\n",
    "        \"Deep Learning Approaches for Medical Image Analysis\",\n",
    "        [\"Smith J\", \"Johnson A\", \"Williams B\"],\n",
    "        \"Nature Medicine\",\n",
    "        \"2023\",\n",
    "        \"12345678\",\n",
    "        \"10.1038/s41591-023-12345\"\n",
    "    ),\n",
    "    \"23456789\": create_mock_paper(\n",
    "        \"Machine Learning in Genomics: A Comprehensive Review\",\n",
    "        [\"Brown C\", \"Davis D\"],\n",
    "        \"Nature Genetics\", \n",
    "        \"2023\",\n",
    "        \"23456789\",\n",
    "        \"10.1038/s41588-023-23456\"\n",
    "    ),\n",
    "    \"34567890\": create_mock_paper(\n",
    "        \"Statistical Methods for Clinical Trial Analysis\",\n",
    "        [\"Wilson E\", \"Miller F\", \"Moore G\", \"Taylor H\"],\n",
    "        \"The Lancet\",\n",
    "        \"2024\",\n",
    "        \"34567890\",\n",
    "        \"10.1016/S0140-6736(24)34567\"\n",
    "    )\n",
    "}\n",
    "\n",
    "# Mock abstract data\n",
    "sample_abstracts = {\n",
    "    \"12345678\": (\n",
    "        \"Deep learning has revolutionized medical image analysis by providing automated and accurate diagnostic tools. This review examines recent advances in convolutional neural networks for radiology applications.\",\n",
    "        [\"Deep Learning\", \"Medical Imaging\", \"Radiology\", \"Artificial Intelligence\"],\n",
    "        \"10.1038/s41591-023-12345\"\n",
    "    ),\n",
    "    \"23456789\": (\n",
    "        \"Genomic data analysis has been transformed by machine learning algorithms. This comprehensive review covers applications in variant calling, gene expression analysis, and personalized medicine.\",\n",
    "        [\"Machine Learning\", \"Genomics\", \"Bioinformatics\", \"Personalized Medicine\"],\n",
    "        \"10.1038/s41588-023-23456\"\n",
    "    ),\n",
    "    \"34567890\": (\n",
    "        \"Statistical methods form the backbone of clinical trial design and analysis. This paper reviews modern approaches including Bayesian methods and adaptive trial designs.\",\n",
    "        [\"Statistics\", \"Clinical Trials\", \"Bayesian Analysis\", \"Study Design\"],\n",
    "        \"10.1016/S0140-6736(24)34567\"\n",
    "    )\n",
    "}\n",
    "\n",
    "# Demonstrate BibTeX formatting\n",
    "print(\"Sample BibTeX Entries:\")\n",
    "print(\"-\" * 25)\n",
    "\n",
    "for pmid, paper in sample_papers.items():\n",
    "    abstract_data = sample_abstracts.get(pmid, (\"\", [], \"\"))\n",
    "    \n",
    "    print(f\"\\nPaper: {paper['title'][:50]}...\")\n",
    "    print(f\"Authors: {', '.join([a['name'] for a in paper['authors']])}\")\n",
    "    print(f\"Journal: {paper['source']}\")\n",
    "    print(f\"Year: {paper['pubdate'].split()[0]}\")\n",
    "    print(f\"PMID: {pmid}\")\n",
    "    print(f\"DOI: {paper.get('doi', 'N/A')}\")\n",
    "    print(f\"Keywords: {', '.join(abstract_data[1])}\")\n",
    "    print(f\"Abstract: {abstract_data[0][:100]}...\")\n",
    "\n",
    "# Mock CrossRef metrics\n",
    "def mock_crossref_metrics(doi):\n",
    "    \"\"\"Mock CrossRef metrics for demonstration.\"\"\"\n",
    "    if not doi:\n",
    "        return {}\n",
    "    \n",
    "    return {\n",
    "        \"citations\": np.random.randint(0, 150),\n",
    "        \"type\": \"journal-article\",\n",
    "        \"publisher\": \"Nature Publishing Group\" if \"nature\" in doi.lower() else \"Elsevier\",\n",
    "        \"references\": np.random.randint(20, 80),\n",
    "        \"doi\": doi\n",
    "    }\n",
    "\n",
    "print(\"\\n\\nCrossRef Metrics:\")\n",
    "print(\"-\" * 18)\n",
    "\n",
    "for pmid, paper in sample_papers.items():\n",
    "    doi = paper.get('doi', '')\n",
    "    metrics = mock_crossref_metrics(doi)\n",
    "    if metrics:\n",
    "        print(f\"\\n{paper['title'][:40]}...\")\n",
    "        print(f\"  Citations: {metrics['citations']}\")\n",
    "        print(f\"  References: {metrics['references']}\")\n",
    "        print(f\"  Publisher: {metrics['publisher']}\")\n",
    "        print(f\"  Type: {metrics['type']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Web Content Extraction and Analysis\n",
    "\n",
    "### URL Content Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate web content extraction\n",
    "print(\"Web Content Extraction and Analysis:\")\n",
    "print(\"=\" * 36)\n",
    "\n",
    "# Mock HTML content for demonstration\n",
    "sample_html_content = \"\"\"\n",
    "<html>\n",
    "<head>\n",
    "    <title>Scientific Computing with Python</title>\n",
    "</head>\n",
    "<body>\n",
    "    <header>\n",
    "        <nav>Navigation menu</nav>\n",
    "    </header>\n",
    "    <main>\n",
    "        <h1>Introduction to Scientific Computing</h1>\n",
    "        <p>Scientific computing combines mathematical models, quantitative analysis \n",
    "        techniques, and computer programming to solve complex scientific problems.</p>\n",
    "        \n",
    "        <h2>Key Libraries</h2>\n",
    "        <ul>\n",
    "            <li>NumPy: Numerical computing with arrays</li>\n",
    "            <li>SciPy: Scientific computing algorithms</li>\n",
    "            <li>Pandas: Data manipulation and analysis</li>\n",
    "            <li>Matplotlib: Plotting and visualization</li>\n",
    "        </ul>\n",
    "        \n",
    "        <h2>Applications</h2>\n",
    "        <p>Scientific computing is used in physics simulations, bioinformatics,\n",
    "        climate modeling, financial analysis, and machine learning research.</p>\n",
    "    </main>\n",
    "    <footer>\n",
    "        <p>Copyright 2024 Scientific Computing Guide</p>\n",
    "    </footer>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "# Mock function to demonstrate content extraction\n",
    "def mock_extract_main_content(html):\n",
    "    \"\"\"Mock content extraction for demonstration.\"\"\"\n",
    "    import re\n",
    "    from bs4 import BeautifulSoup\n",
    "    \n",
    "    # Parse HTML\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    # Extract main content (remove nav, footer, scripts)\n",
    "    for element in soup(['nav', 'footer', 'script', 'style']):\n",
    "        element.decompose()\n",
    "    \n",
    "    # Get text content\n",
    "    text = soup.get_text()\n",
    "    \n",
    "    # Clean up whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Extract content from sample HTML\n",
    "extracted_content = mock_extract_main_content(sample_html_content)\n",
    "\n",
    "print(\"Original HTML length:\", len(sample_html_content))\n",
    "print(\"Extracted content length:\", len(extracted_content))\n",
    "print(\"\\nExtracted content:\")\n",
    "print(\"-\" * 20)\n",
    "print(extracted_content)\n",
    "\n",
    "# Content analysis\n",
    "print(\"\\nContent Analysis:\")\n",
    "print(\"-\" * 17)\n",
    "\n",
    "words = extracted_content.split()\n",
    "sentences = extracted_content.split('.')\n",
    "scientific_terms = ['scientific', 'computing', 'numpy', 'scipy', 'pandas', 'matplotlib', \n",
    "                   'algorithms', 'analysis', 'research', 'bioinformatics']\n",
    "\n",
    "term_count = sum(1 for word in words if word.lower().strip('.,!?') in scientific_terms)\n",
    "\n",
    "print(f\"Word count: {len(words)}\")\n",
    "print(f\"Sentence count: {len([s for s in sentences if s.strip()])}\")\n",
    "print(f\"Scientific terms found: {term_count}\")\n",
    "print(f\"Scientific term density: {term_count/len(words)*100:.1f}%\")\n",
    "\n",
    "# Key phrases extraction (simple)\n",
    "key_phrases = []\n",
    "content_lower = extracted_content.lower()\n",
    "phrase_patterns = [\n",
    "    'scientific computing',\n",
    "    'machine learning',\n",
    "    'data analysis',\n",
    "    'numerical computing',\n",
    "    'climate modeling'\n",
    "]\n",
    "\n",
    "for phrase in phrase_patterns:\n",
    "    if phrase in content_lower:\n",
    "        key_phrases.append(phrase)\n",
    "\n",
    "print(f\"\\nKey phrases found: {', '.join(key_phrases) if key_phrases else 'None'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Crawling and Site Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate web crawling concepts\n",
    "print(\"Web Crawling and Site Analysis:\")\n",
    "print(\"=\" * 32)\n",
    "\n",
    "# Mock website structure for demonstration\n",
    "mock_website = {\n",
    "    \"https://scientific-computing.org/\": {\n",
    "        \"title\": \"Scientific Computing Hub\",\n",
    "        \"content\": \"Welcome to the scientific computing community. Explore tutorials, research papers, and tools for computational science.\",\n",
    "        \"links\": [\n",
    "            \"https://scientific-computing.org/tutorials/\",\n",
    "            \"https://scientific-computing.org/papers/\",\n",
    "            \"https://scientific-computing.org/tools/\"\n",
    "        ],\n",
    "        \"content_type\": \"homepage\"\n",
    "    },\n",
    "    \"https://scientific-computing.org/tutorials/\": {\n",
    "        \"title\": \"Tutorials - Scientific Computing\",\n",
    "        \"content\": \"Learn scientific computing with Python. Topics include NumPy, SciPy, machine learning, and data visualization.\",\n",
    "        \"links\": [\n",
    "            \"https://scientific-computing.org/tutorials/numpy/\",\n",
    "            \"https://scientific-computing.org/tutorials/scipy/\",\n",
    "            \"https://scientific-computing.org/tutorials/ml/\"\n",
    "        ],\n",
    "        \"content_type\": \"tutorial_index\"\n",
    "    },\n",
    "    \"https://scientific-computing.org/papers/\": {\n",
    "        \"title\": \"Research Papers - Scientific Computing\",\n",
    "        \"content\": \"Collection of research papers on computational methods, algorithms, and applications in scientific domains.\",\n",
    "        \"links\": [],\n",
    "        \"content_type\": \"research\"\n",
    "    },\n",
    "    \"https://scientific-computing.org/tools/\": {\n",
    "        \"title\": \"Tools - Scientific Computing\",\n",
    "        \"content\": \"Software tools and libraries for scientific computing. Download guides, documentation, and examples.\",\n",
    "        \"links\": [],\n",
    "        \"content_type\": \"tools\"\n",
    "    }\n",
    "}\n",
    "\n",
    "def mock_crawl_website(start_url, max_depth=1):\n",
    "    \"\"\"Mock website crawling for demonstration.\"\"\"\n",
    "    visited = set()\n",
    "    to_visit = [(start_url, 0)]\n",
    "    crawl_results = {}\n",
    "    \n",
    "    while to_visit:\n",
    "        current_url, depth = to_visit.pop(0)\n",
    "        \n",
    "        if current_url in visited or depth > max_depth:\n",
    "            continue\n",
    "            \n",
    "        if current_url in mock_website:\n",
    "            visited.add(current_url)\n",
    "            page_data = mock_website[current_url]\n",
    "            crawl_results[current_url] = page_data\n",
    "            \n",
    "            # Add linked pages to visit queue\n",
    "            for link in page_data['links']:\n",
    "                if link not in visited:\n",
    "                    to_visit.append((link, depth + 1))\n",
    "    \n",
    "    return visited, crawl_results\n",
    "\n",
    "# Perform mock crawl\n",
    "start_url = \"https://scientific-computing.org/\"\n",
    "crawled_urls, crawled_content = mock_crawl_website(start_url, max_depth=2)\n",
    "\n",
    "print(f\"Crawl Results for: {start_url}\")\n",
    "print(f\"Pages crawled: {len(crawled_urls)}\")\n",
    "print(f\"Max depth: 2\")\n",
    "\n",
    "print(\"\\nCrawled Pages:\")\n",
    "print(\"-\" * 15)\n",
    "\n",
    "for url, data in crawled_content.items():\n",
    "    print(f\"\\nURL: {url}\")\n",
    "    print(f\"Title: {data['title']}\")\n",
    "    print(f\"Type: {data['content_type']}\")\n",
    "    print(f\"Content: {data['content'][:80]}...\")\n",
    "    print(f\"Links found: {len(data['links'])}\")\n",
    "\n",
    "# Content analysis across crawled pages\n",
    "print(\"\\nSite Analysis:\")\n",
    "print(\"-\" * 14)\n",
    "\n",
    "total_content = ' '.join([data['content'] for data in crawled_content.values()])\n",
    "total_words = len(total_content.split())\n",
    "total_links = sum(len(data['links']) for data in crawled_content.values())\n",
    "\n",
    "content_types = {}\n",
    "for data in crawled_content.values():\n",
    "    content_type = data['content_type']\n",
    "    content_types[content_type] = content_types.get(content_type, 0) + 1\n",
    "\n",
    "print(f\"Total words across all pages: {total_words}\")\n",
    "print(f\"Total internal links: {total_links}\")\n",
    "print(f\"Average words per page: {total_words/len(crawled_content):.1f}\")\n",
    "print(f\"Page types: {dict(content_types)}\")\n",
    "\n",
    "# Scientific content analysis\n",
    "scientific_keywords = ['scientific', 'computing', 'research', 'algorithm', 'data', \n",
    "                      'analysis', 'python', 'numpy', 'scipy', 'machine', 'learning']\n",
    "\n",
    "keyword_counts = {}\n",
    "for keyword in scientific_keywords:\n",
    "    count = total_content.lower().count(keyword)\n",
    "    if count > 0:\n",
    "        keyword_counts[keyword] = count\n",
    "\n",
    "print(f\"\\nScientific keyword frequency:\")\n",
    "for keyword, count in sorted(keyword_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"  {keyword}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Advanced Research Workflows\n",
    "\n",
    "### Literature Review Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced research workflow demonstration\n",
    "print(\"Literature Review Pipeline:\")\n",
    "print(\"=\" * 27)\n",
    "\n",
    "class LiteratureReviewPipeline:\n",
    "    def __init__(self, research_topic):\n",
    "        self.research_topic = research_topic\n",
    "        self.papers = []\n",
    "        self.keywords = set()\n",
    "        self.authors = set()\n",
    "        self.journals = set()\n",
    "        self.year_range = [float('inf'), 0]\n",
    "    \n",
    "    def search_literature(self, queries, max_papers_per_query=10):\n",
    "        \"\"\"Search literature across multiple queries.\"\"\"\n",
    "        print(f\"\\nSearching literature for: {self.research_topic}\")\n",
    "        print(f\"Queries: {len(queries)}\")\n",
    "        \n",
    "        for i, query in enumerate(queries, 1):\n",
    "            print(f\"\\nQuery {i}: '{query}'\")\n",
    "            \n",
    "            # Mock search results\n",
    "            n_found = np.random.randint(20, 100)\n",
    "            n_retrieved = min(max_papers_per_query, n_found)\n",
    "            \n",
    "            print(f\"  Found: {n_found} papers\")\n",
    "            print(f\"  Retrieved: {n_retrieved} papers\")\n",
    "            \n",
    "            # Generate mock papers\n",
    "            for j in range(n_retrieved):\n",
    "                paper = self._generate_mock_paper(query, j)\n",
    "                self.papers.append(paper)\n",
    "                \n",
    "                # Update metadata\n",
    "                self.keywords.update(paper['keywords'])\n",
    "                self.authors.update(paper['authors'])\n",
    "                self.journals.add(paper['journal'])\n",
    "                \n",
    "                year = int(paper['year'])\n",
    "                self.year_range[0] = min(self.year_range[0], year)\n",
    "                self.year_range[1] = max(self.year_range[1], year)\n",
    "        \n",
    "        print(f\"\\nTotal papers collected: {len(self.papers)}\")\n",
    "        return len(self.papers)\n",
    "    \n",
    "    def _generate_mock_paper(self, query, index):\n",
    "        \"\"\"Generate mock paper data.\"\"\"\n",
    "        query_words = query.split()\n",
    "        \n",
    "        # Generate title based on query\n",
    "        title_templates = [\n",
    "            f\"Advances in {query_words[0].title()} for {query_words[-1].title()} Applications\",\n",
    "            f\"A Novel Approach to {query_words[0].title()} Using {query_words[-1].title()}\",\n",
    "            f\"{query_words[0].title()}-Based Methods for {query_words[-1].title()} Analysis\",\n",
    "            f\"Comparative Study of {query_words[0].title()} Techniques in {query_words[-1].title()}\"\n",
    "        ]\n",
    "        \n",
    "        title = np.random.choice(title_templates)\n",
    "        \n",
    "        # Generate authors\n",
    "        first_names = ['John', 'Jane', 'Michael', 'Sarah', 'David', 'Emily', 'Robert', 'Lisa']\n",
    "        last_names = ['Smith', 'Johnson', 'Williams', 'Brown', 'Jones', 'Garcia', 'Miller', 'Davis']\n",
    "        \n",
    "        n_authors = np.random.randint(2, 6)\n",
    "        authors = [f\"{np.random.choice(first_names)} {np.random.choice(last_names)}\" \n",
    "                  for _ in range(n_authors)]\n",
    "        \n",
    "        # Generate other metadata\n",
    "        journals = ['Nature', 'Science', 'Cell', 'PNAS', 'Journal of AI Research', \n",
    "                   'IEEE Transactions', 'JAMA', 'The Lancet']\n",
    "        \n",
    "        paper = {\n",
    "            'title': title,\n",
    "            'authors': authors,\n",
    "            'journal': np.random.choice(journals),\n",
    "            'year': str(np.random.randint(2020, 2025)),\n",
    "            'citations': np.random.randint(0, 200),\n",
    "            'keywords': query_words + [np.random.choice(['analysis', 'method', 'study', 'research'])],\n",
    "            'pmid': f\"{np.random.randint(30000000, 40000000)}\",\n",
    "            'doi': f\"10.1038/{np.random.randint(1000, 9999)}\"\n",
    "        }\n",
    "        \n",
    "        return paper\n",
    "    \n",
    "    def analyze_collection(self):\n",
    "        \"\"\"Analyze the collected literature.\"\"\"\n",
    "        if not self.papers:\n",
    "            print(\"No papers to analyze.\")\n",
    "            return\n",
    "        \n",
    "        print(f\"\\nLiterature Collection Analysis:\")\n",
    "        print(\"=\" * 31)\n",
    "        \n",
    "        # Basic statistics\n",
    "        print(f\"Total papers: {len(self.papers)}\")\n",
    "        print(f\"Unique authors: {len(self.authors)}\")\n",
    "        print(f\"Unique journals: {len(self.journals)}\")\n",
    "        print(f\"Year range: {self.year_range[0]}-{self.year_range[1]}\")\n",
    "        print(f\"Unique keywords: {len(self.keywords)}\")\n",
    "        \n",
    "        # Citation analysis\n",
    "        citations = [paper['citations'] for paper in self.papers]\n",
    "        print(f\"\\nCitation Statistics:\")\n",
    "        print(f\"  Mean citations: {np.mean(citations):.1f}\")\n",
    "        print(f\"  Median citations: {np.median(citations):.1f}\")\n",
    "        print(f\"  Max citations: {max(citations)}\")\n",
    "        print(f\"  Total citations: {sum(citations):,}\")\n",
    "        \n",
    "        # Year distribution\n",
    "        years = [int(paper['year']) for paper in self.papers]\n",
    "        year_counts = {year: years.count(year) for year in set(years)}\n",
    "        print(f\"\\nPublications by year:\")\n",
    "        for year in sorted(year_counts.keys()):\n",
    "            print(f\"  {year}: {year_counts[year]} papers\")\n",
    "        \n",
    "        # Journal distribution\n",
    "        journal_counts = {}\n",
    "        for paper in self.papers:\n",
    "            journal = paper['journal']\n",
    "            journal_counts[journal] = journal_counts.get(journal, 0) + 1\n",
    "        \n",
    "        print(f\"\\nTop journals:\")\n",
    "        for journal, count in sorted(journal_counts.items(), key=lambda x: x[1], reverse=True)[:5]:\n",
    "            print(f\"  {journal}: {count} papers\")\n",
    "        \n",
    "        return {\n",
    "            'total_papers': len(self.papers),\n",
    "            'citation_stats': {\n",
    "                'mean': np.mean(citations),\n",
    "                'median': np.median(citations),\n",
    "                'max': max(citations),\n",
    "                'total': sum(citations)\n",
    "            },\n",
    "            'year_distribution': year_counts,\n",
    "            'journal_distribution': journal_counts\n",
    "        }\n",
    "    \n",
    "    def generate_bibliography(self, filename=None):\n",
    "        \"\"\"Generate BibTeX bibliography.\"\"\"\n",
    "        if filename is None:\n",
    "            filename = f\"{self.research_topic.replace(' ', '_')}_bibliography.bib\"\n",
    "        \n",
    "        print(f\"\\nGenerating bibliography: {filename}\")\n",
    "        \n",
    "        # Mock BibTeX generation\n",
    "        bibtex_entries = []\n",
    "        for paper in self.papers:\n",
    "            authors_str = ' and '.join(paper['authors'])\n",
    "            \n",
    "            entry = f\"\"\"@article{{{paper['pmid']},\n",
    "    title = {{{paper['title']}}},\n",
    "    author = {{{authors_str}}},\n",
    "    journal = {{{paper['journal']}}},\n",
    "    year = {{{paper['year']}}},\n",
    "    doi = {{{paper['doi']}}},\n",
    "    pmid = {{{paper['pmid']}}}\n",
    "}}\"\"\"\n",
    "            bibtex_entries.append(entry)\n",
    "        \n",
    "        print(f\"Generated {len(bibtex_entries)} BibTeX entries\")\n",
    "        print(f\"Total bibliography size: ~{len('\\n\\n'.join(bibtex_entries))} characters\")\n",
    "        \n",
    "        return filename, bibtex_entries\n",
    "\n",
    "# Demonstrate literature review pipeline\n",
    "research_topic = \"Machine Learning in Healthcare\"\n",
    "pipeline = LiteratureReviewPipeline(research_topic)\n",
    "\n",
    "# Define search queries\n",
    "queries = [\n",
    "    \"machine learning medical diagnosis\",\n",
    "    \"deep learning healthcare applications\", \n",
    "    \"artificial intelligence clinical decision\",\n",
    "    \"neural networks medical imaging\",\n",
    "    \"ML electronic health records\"\n",
    "]\n",
    "\n",
    "# Execute pipeline\n",
    "pipeline.search_literature(queries, max_papers_per_query=8)\n",
    "analysis_results = pipeline.analyze_collection()\n",
    "bibliography_file, bibtex_entries = pipeline.generate_bibliography()\n",
    "\n",
    "print(f\"\\nLiterature review pipeline completed for: {research_topic}\")\n",
    "print(f\"Bibliography saved as: {bibliography_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research Trend Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Research trend analysis visualization\n",
    "print(\"Research Trend Analysis:\")\n",
    "print(\"=\" * 24)\n",
    "\n",
    "# Create visualization of research trends\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('Literature Review Analysis Dashboard', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plot 1: Publications by year\n",
    "ax1 = axes[0, 0]\n",
    "if 'year_distribution' in analysis_results:\n",
    "    years = sorted(analysis_results['year_distribution'].keys())\n",
    "    counts = [analysis_results['year_distribution'][year] for year in years]\n",
    "    \n",
    "    ax1.bar(years, counts, color='skyblue', alpha=0.7)\n",
    "    ax1.set_xlabel('Year')\n",
    "    ax1.set_ylabel('Number of Publications')\n",
    "    ax1.set_title('Publications by Year')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Citation distribution\n",
    "ax2 = axes[0, 1]\n",
    "citations = [paper['citations'] for paper in pipeline.papers]\n",
    "ax2.hist(citations, bins=15, color='lightgreen', alpha=0.7, edgecolor='black')\n",
    "ax2.set_xlabel('Citations')\n",
    "ax2.set_ylabel('Number of Papers')\n",
    "ax2.set_title('Citation Distribution')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Journal distribution (top 8)\n",
    "ax3 = axes[1, 0]\n",
    "if 'journal_distribution' in analysis_results:\n",
    "    journal_items = sorted(analysis_results['journal_distribution'].items(), \n",
    "                          key=lambda x: x[1], reverse=True)[:8]\n",
    "    journals = [item[0] for item in journal_items]\n",
    "    paper_counts = [item[1] for item in journal_items]\n",
    "    \n",
    "    ax3.barh(range(len(journals)), paper_counts, color='lightcoral', alpha=0.7)\n",
    "    ax3.set_yticks(range(len(journals)))\n",
    "    ax3.set_yticklabels([j[:15] + '...' if len(j) > 15 else j for j in journals])\n",
    "    ax3.set_xlabel('Number of Papers')\n",
    "    ax3.set_title('Top Journals')\n",
    "    ax3.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Plot 4: Research impact metrics\n",
    "ax4 = axes[1, 1]\n",
    "if 'citation_stats' in analysis_results:\n",
    "    stats = analysis_results['citation_stats']\n",
    "    metrics = ['Mean', 'Median', 'Max']\n",
    "    values = [stats['mean'], stats['median'], stats['max']]\n",
    "    \n",
    "    bars = ax4.bar(metrics, values, color=['gold', 'orange', 'red'], alpha=0.7)\n",
    "    ax4.set_ylabel('Citations')\n",
    "    ax4.set_title('Citation Statistics')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, value in zip(bars, values):\n",
    "        height = bar.get_height()\n",
    "        ax4.text(bar.get_x() + bar.get_width()/2., height + height*0.01,\n",
    "                f'{value:.1f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nResearch Trend Summary:\")\n",
    "print(\"=\" * 23)\n",
    "\n",
    "if analysis_results:\n",
    "    print(f\"Dataset: {analysis_results['total_papers']} papers\")\n",
    "    print(f\"Average citations per paper: {analysis_results['citation_stats']['mean']:.1f}\")\n",
    "    print(f\"Most cited paper: {analysis_results['citation_stats']['max']} citations\")\n",
    "    print(f\"Total research impact: {analysis_results['citation_stats']['total']:,} citations\")\n",
    "    \n",
    "    # Publication trend\n",
    "    years = sorted(analysis_results['year_distribution'].keys())\n",
    "    if len(years) > 1:\n",
    "        recent_years = years[-2:]\n",
    "        trend = analysis_results['year_distribution'][recent_years[-1]] - analysis_results['year_distribution'][recent_years[0]]\n",
    "        trend_direction = \"increasing\" if trend > 0 else \"decreasing\" if trend < 0 else \"stable\"\n",
    "        print(f\"Publication trend: {trend_direction} ({trend:+d} papers from {recent_years[0]} to {recent_years[1]})\")\n",
    "    \n",
    "    # Most productive journal\n",
    "    top_journal = max(analysis_results['journal_distribution'].items(), key=lambda x: x[1])\n",
    "    print(f\"Most productive journal: {top_journal[0]} ({top_journal[1]} papers)\")\n",
    "\n",
    "print(f\"\\nLiterature analysis completed for: {research_topic}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Automated Research Assistant\n",
    "\n",
    "### Research Question to Literature Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automated research assistant demonstration\n",
    "print(\"Automated Research Assistant:\")\n",
    "print(\"=\" * 28)\n",
    "\n",
    "class ResearchAssistant:\n",
    "    def __init__(self):\n",
    "        self.research_history = []\n",
    "        self.knowledge_base = {}\n",
    "    \n",
    "    def process_research_question(self, question):\n",
    "        \"\"\"Process a research question and generate search strategy.\"\"\"\n",
    "        print(f\"\\nProcessing research question:\")\n",
    "        print(f\"'{question}'\")\n",
    "        \n",
    "        # Extract key concepts (simplified)\n",
    "        key_concepts = self._extract_key_concepts(question)\n",
    "        \n",
    "        # Generate search queries\n",
    "        search_queries = self._generate_search_queries(key_concepts)\n",
    "        \n",
    "        # Estimate search scope\n",
    "        estimated_papers = self._estimate_search_scope(search_queries)\n",
    "        \n",
    "        research_plan = {\n",
    "            'question': question,\n",
    "            'key_concepts': key_concepts,\n",
    "            'search_queries': search_queries,\n",
    "            'estimated_papers': estimated_papers,\n",
    "            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        }\n",
    "        \n",
    "        self.research_history.append(research_plan)\n",
    "        \n",
    "        return research_plan\n",
    "    \n",
    "    def _extract_key_concepts(self, question):\n",
    "        \"\"\"Extract key concepts from research question.\"\"\"\n",
    "        # Simple keyword extraction (in practice, would use NLP)\n",
    "        stop_words = {'what', 'how', 'why', 'when', 'where', 'is', 'are', 'the', \n",
    "                     'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with'}\n",
    "        \n",
    "        words = question.lower().replace('?', '').split()\n",
    "        concepts = [word for word in words if word not in stop_words and len(word) > 3]\n",
    "        \n",
    "        # Group related concepts\n",
    "        concept_groups = {\n",
    "            'methods': [],\n",
    "            'domains': [],\n",
    "            'outcomes': []\n",
    "        }\n",
    "        \n",
    "        method_terms = ['machine', 'learning', 'deep', 'neural', 'algorithm', 'model', 'analysis']\n",
    "        domain_terms = ['medical', 'healthcare', 'clinical', 'biological', 'genetic', 'imaging']\n",
    "        outcome_terms = ['prediction', 'diagnosis', 'treatment', 'outcome', 'effectiveness']\n",
    "        \n",
    "        for concept in concepts:\n",
    "            if any(term in concept for term in method_terms):\n",
    "                concept_groups['methods'].append(concept)\n",
    "            elif any(term in concept for term in domain_terms):\n",
    "                concept_groups['domains'].append(concept)\n",
    "            elif any(term in concept for term in outcome_terms):\n",
    "                concept_groups['outcomes'].append(concept)\n",
    "        \n",
    "        return concept_groups\n",
    "    \n",
    "    def _generate_search_queries(self, key_concepts):\n",
    "        \"\"\"Generate optimized search queries.\"\"\"\n",
    "        queries = []\n",
    "        \n",
    "        # Combine concepts from different groups\n",
    "        methods = key_concepts.get('methods', [])\n",
    "        domains = key_concepts.get('domains', [])\n",
    "        outcomes = key_concepts.get('outcomes', [])\n",
    "        \n",
    "        # Generate different query strategies\n",
    "        if methods and domains:\n",
    "            for method in methods[:2]:  # Limit to top 2\n",
    "                for domain in domains[:2]:\n",
    "                    queries.append(f\"{method} {domain}\")\n",
    "        \n",
    "        if outcomes and domains:\n",
    "            for outcome in outcomes[:2]:\n",
    "                for domain in domains[:2]:\n",
    "                    queries.append(f\"{outcome} {domain}\")\n",
    "        \n",
    "        if methods and outcomes:\n",
    "            for method in methods[:2]:\n",
    "                for outcome in outcomes[:2]:\n",
    "                    queries.append(f\"{method} {outcome}\")\n",
    "        \n",
    "        # Broad queries\n",
    "        all_concepts = methods + domains + outcomes\n",
    "        if len(all_concepts) >= 2:\n",
    "            queries.append(' '.join(all_concepts[:3]))\n",
    "        \n",
    "        return list(set(queries))  # Remove duplicates\n",
    "    \n",
    "    def _estimate_search_scope(self, queries):\n",
    "        \"\"\"Estimate number of papers for each query.\"\"\"\n",
    "        estimates = {}\n",
    "        \n",
    "        for query in queries:\n",
    "            # Mock estimation based on query complexity\n",
    "            base_estimate = 100\n",
    "            \n",
    "            # Adjust based on query characteristics\n",
    "            words = query.split()\n",
    "            complexity_factor = len(words) * 0.8  # More words = fewer results\n",
    "            \n",
    "            # Check for popular terms\n",
    "            popular_terms = ['machine', 'learning', 'deep', 'neural', 'medical']\n",
    "            popularity_boost = sum(2 for word in words if word in popular_terms)\n",
    "            \n",
    "            estimated = int(base_estimate * (2 - complexity_factor) + popularity_boost * 50)\n",
    "            estimated = max(10, min(500, estimated))  # Clamp between 10-500\n",
    "            \n",
    "            estimates[query] = estimated\n",
    "        \n",
    "        return estimates\n",
    "    \n",
    "    def execute_research_plan(self, plan, max_papers_per_query=10):\n",
    "        \"\"\"Execute the research plan.\"\"\"\n",
    "        print(f\"\\nExecuting research plan...\")\n",
    "        \n",
    "        # Use the literature review pipeline\n",
    "        pipeline = LiteratureReviewPipeline(plan['question'])\n",
    "        pipeline.search_literature(plan['search_queries'], max_papers_per_query)\n",
    "        analysis = pipeline.analyze_collection()\n",
    "        \n",
    "        # Generate summary\n",
    "        summary = {\n",
    "            'research_question': plan['question'],\n",
    "            'papers_found': analysis['total_papers'],\n",
    "            'key_findings': self._generate_key_findings(analysis),\n",
    "            'recommendations': self._generate_recommendations(analysis)\n",
    "        }\n",
    "        \n",
    "        return summary, pipeline\n",
    "    \n",
    "    def _generate_key_findings(self, analysis):\n",
    "        \"\"\"Generate key findings from analysis.\"\"\"\n",
    "        findings = []\n",
    "        \n",
    "        total_papers = analysis['total_papers']\n",
    "        avg_citations = analysis['citation_stats']['mean']\n",
    "        \n",
    "        findings.append(f\"Found {total_papers} relevant papers in the literature\")\n",
    "        findings.append(f\"Average paper impact: {avg_citations:.1f} citations\")\n",
    "        \n",
    "        # Year trend analysis\n",
    "        years = sorted(analysis['year_distribution'].keys())\n",
    "        if len(years) > 1:\n",
    "            recent_growth = analysis['year_distribution'][years[-1]] - analysis['year_distribution'][years[0]]\n",
    "            if recent_growth > 0:\n",
    "                findings.append(f\"Research activity is increasing ({recent_growth:+d} papers from {years[0]} to {years[-1]})\")\n",
    "            else:\n",
    "                findings.append(\"Research activity appears stable or declining\")\n",
    "        \n",
    "        # Journal analysis\n",
    "        top_journals = sorted(analysis['journal_distribution'].items(), \n",
    "                            key=lambda x: x[1], reverse=True)[:3]\n",
    "        findings.append(f\"Most active journals: {', '.join([j[0] for j in top_journals])}\")\n",
    "        \n",
    "        return findings\n",
    "    \n",
    "    def _generate_recommendations(self, analysis):\n",
    "        \"\"\"Generate research recommendations.\"\"\"\n",
    "        recommendations = []\n",
    "        \n",
    "        total_papers = analysis['total_papers']\n",
    "        \n",
    "        if total_papers < 20:\n",
    "            recommendations.append(\"Consider expanding search terms - limited literature found\")\n",
    "        elif total_papers > 100:\n",
    "            recommendations.append(\"Consider narrowing search scope - large literature volume\")\n",
    "        \n",
    "        avg_citations = analysis['citation_stats']['mean']\n",
    "        if avg_citations > 50:\n",
    "            recommendations.append(\"High-impact research area - consider focusing on recent developments\")\n",
    "        elif avg_citations < 10:\n",
    "            recommendations.append(\"Emerging research area - opportunity for novel contributions\")\n",
    "        \n",
    "        # Journal recommendations\n",
    "        top_journal = max(analysis['journal_distribution'].items(), key=lambda x: x[1])\n",
    "        recommendations.append(f\"Consider submitting to {top_journal[0]} (most active in this area)\")\n",
    "        \n",
    "        return recommendations\n",
    "\n",
    "# Demonstrate research assistant\n",
    "assistant = ResearchAssistant()\n",
    "\n",
    "# Example research questions\n",
    "research_questions = [\n",
    "    \"How effective is machine learning for medical diagnosis?\",\n",
    "    \"What are the applications of deep learning in healthcare imaging?\",\n",
    "    \"Can neural networks predict clinical outcomes?\"\n",
    "]\n",
    "\n",
    "# Process each question\n",
    "for question in research_questions:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    \n",
    "    # Generate research plan\n",
    "    plan = assistant.process_research_question(question)\n",
    "    \n",
    "    print(f\"\\nResearch Plan Generated:\")\n",
    "    print(f\"Key concepts: {plan['key_concepts']}\")\n",
    "    print(f\"Search queries: {plan['search_queries']}\")\n",
    "    print(f\"Estimated papers: {sum(plan['estimated_papers'].values())}\")\n",
    "    \n",
    "    # Execute plan (first question only for demo)\n",
    "    if question == research_questions[0]:\n",
    "        summary, pipeline = assistant.execute_research_plan(plan, max_papers_per_query=6)\n",
    "        \n",
    "        print(f\"\\nResearch Summary:\")\n",
    "        print(f\"Papers analyzed: {summary['papers_found']}\")\n",
    "        print(f\"\\nKey findings:\")\n",
    "        for finding in summary['key_findings']:\n",
    "            print(f\"  • {finding}\")\n",
    "        \n",
    "        print(f\"\\nRecommendations:\")\n",
    "        for rec in summary['recommendations']:\n",
    "            print(f\"  • {rec}\")\n",
    "\n",
    "print(f\"\\n\\nResearch assistant processed {len(research_questions)} questions\")\n",
    "print(f\"Total research plans in history: {len(assistant.research_history)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Integration and Best Practices\n",
    "\n",
    "### Complete Research Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete research workflow integration\n",
    "print(\"Complete Research Workflow:\")\n",
    "print(\"=\" * 27)\n",
    "\n",
    "class IntegratedResearchWorkflow:\n",
    "    def __init__(self, project_name):\n",
    "        self.project_name = project_name\n",
    "        self.workflow_steps = []\n",
    "        self.results = {}\n",
    "        self.start_time = datetime.now()\n",
    "    \n",
    "    def step1_question_formulation(self, research_question):\n",
    "        \"\"\"Step 1: Formulate and analyze research question.\"\"\"\n",
    "        print(f\"\\nSTEP 1: Question Formulation\")\n",
    "        print(f\"Research Question: {research_question}\")\n",
    "        \n",
    "        assistant = ResearchAssistant()\n",
    "        plan = assistant.process_research_question(research_question)\n",
    "        \n",
    "        self.results['question_analysis'] = plan\n",
    "        self.workflow_steps.append('question_formulation')\n",
    "        \n",
    "        print(f\"✓ Generated {len(plan['search_queries'])} search queries\")\n",
    "        print(f\"✓ Identified {len(plan['key_concepts']['methods'] + plan['key_concepts']['domains'])} key concepts\")\n",
    "        \n",
    "        return plan\n",
    "    \n",
    "    def step2_literature_search(self, search_plan, max_papers=30):\n",
    "        \"\"\"Step 2: Execute comprehensive literature search.\"\"\"\n",
    "        print(f\"\\nSTEP 2: Literature Search\")\n",
    "        \n",
    "        pipeline = LiteratureReviewPipeline(self.project_name)\n",
    "        pipeline.search_literature(search_plan['search_queries'], \n",
    "                                 max_papers_per_query=max_papers//len(search_plan['search_queries']))\n",
    "        \n",
    "        self.results['literature_collection'] = pipeline\n",
    "        self.workflow_steps.append('literature_search')\n",
    "        \n",
    "        print(f\"✓ Collected {len(pipeline.papers)} papers\")\n",
    "        print(f\"✓ Identified {len(pipeline.journals)} unique journals\")\n",
    "        \n",
    "        return pipeline\n",
    "    \n",
    "    def step3_content_analysis(self, pipeline):\n",
    "        \"\"\"Step 3: Analyze collected literature.\"\"\"\n",
    "        print(f\"\\nSTEP 3: Content Analysis\")\n",
    "        \n",
    "        analysis = pipeline.analyze_collection()\n",
    "        \n",
    "        # Additional analysis\n",
    "        collaboration_analysis = self._analyze_collaborations(pipeline.papers)\n",
    "        temporal_analysis = self._analyze_temporal_trends(pipeline.papers)\n",
    "        \n",
    "        self.results['content_analysis'] = {\n",
    "            'basic_stats': analysis,\n",
    "            'collaborations': collaboration_analysis,\n",
    "            'temporal_trends': temporal_analysis\n",
    "        }\n",
    "        self.workflow_steps.append('content_analysis')\n",
    "        \n",
    "        print(f\"✓ Analyzed citation patterns\")\n",
    "        print(f\"✓ Identified research trends\")\n",
    "        print(f\"✓ Mapped collaboration networks\")\n",
    "        \n",
    "        return self.results['content_analysis']\n",
    "    \n",
    "    def step4_synthesis_report(self, analysis):\n",
    "        \"\"\"Step 4: Generate synthesis report.\"\"\"\n",
    "        print(f\"\\nSTEP 4: Synthesis Report Generation\")\n",
    "        \n",
    "        report = {\n",
    "            'executive_summary': self._generate_executive_summary(analysis),\n",
    "            'methodology_review': self._review_methodologies(analysis),\n",
    "            'gap_analysis': self._identify_research_gaps(analysis),\n",
    "            'future_directions': self._suggest_future_research(analysis)\n",
    "        }\n",
    "        \n",
    "        self.results['synthesis_report'] = report\n",
    "        self.workflow_steps.append('synthesis_report')\n",
    "        \n",
    "        print(f\"✓ Generated executive summary\")\n",
    "        print(f\"✓ Identified research gaps\")\n",
    "        print(f\"✓ Proposed future directions\")\n",
    "        \n",
    "        return report\n",
    "    \n",
    "    def step5_deliverables(self, pipeline):\n",
    "        \"\"\"Step 5: Generate research deliverables.\"\"\"\n",
    "        print(f\"\\nSTEP 5: Deliverable Generation\")\n",
    "        \n",
    "        # Generate bibliography\n",
    "        bib_file, bib_entries = pipeline.generate_bibliography()\n",
    "        \n",
    "        # Create summary documents\n",
    "        deliverables = {\n",
    "            'bibliography': {\n",
    "                'filename': bib_file,\n",
    "                'entries': len(bib_entries)\n",
    "            },\n",
    "            'summary_report': f\"{self.project_name}_summary.pdf\",\n",
    "            'data_export': f\"{self.project_name}_data.csv\",\n",
    "            'visualization': f\"{self.project_name}_charts.png\"\n",
    "        }\n",
    "        \n",
    "        self.results['deliverables'] = deliverables\n",
    "        self.workflow_steps.append('deliverables')\n",
    "        \n",
    "        print(f\"✓ Bibliography: {deliverables['bibliography']['entries']} entries\")\n",
    "        print(f\"✓ Summary report generated\")\n",
    "        print(f\"✓ Data exported for further analysis\")\n",
    "        \n",
    "        return deliverables\n",
    "    \n",
    "    def _analyze_collaborations(self, papers):\n",
    "        \"\"\"Analyze author collaboration patterns.\"\"\"\n",
    "        author_counts = {}\n",
    "        collaboration_sizes = []\n",
    "        \n",
    "        for paper in papers:\n",
    "            authors = paper['authors']\n",
    "            collaboration_sizes.append(len(authors))\n",
    "            \n",
    "            for author in authors:\n",
    "                author_counts[author] = author_counts.get(author, 0) + 1\n",
    "        \n",
    "        return {\n",
    "            'top_authors': sorted(author_counts.items(), key=lambda x: x[1], reverse=True)[:10],\n",
    "            'avg_collaboration_size': np.mean(collaboration_sizes),\n",
    "            'total_unique_authors': len(author_counts)\n",
    "        }\n",
    "    \n",
    "    def _analyze_temporal_trends(self, papers):\n",
    "        \"\"\"Analyze temporal research trends.\"\"\"\n",
    "        year_citations = {}\n",
    "        \n",
    "        for paper in papers:\n",
    "            year = int(paper['year'])\n",
    "            if year not in year_citations:\n",
    "                year_citations[year] = []\n",
    "            year_citations[year].append(paper['citations'])\n",
    "        \n",
    "        trends = {}\n",
    "        for year, citations in year_citations.items():\n",
    "            trends[year] = {\n",
    "                'papers': len(citations),\n",
    "                'avg_citations': np.mean(citations),\n",
    "                'total_citations': sum(citations)\n",
    "            }\n",
    "        \n",
    "        return trends\n",
    "    \n",
    "    def _generate_executive_summary(self, analysis):\n",
    "        \"\"\"Generate executive summary.\"\"\"\n",
    "        basic_stats = analysis['basic_stats']\n",
    "        \n",
    "        summary = [\n",
    "            f\"Comprehensive literature review of {basic_stats['total_papers']} papers\",\n",
    "            f\"Research spans {len(basic_stats['year_distribution'])} years with {basic_stats['citation_stats']['total']:,} total citations\",\n",
    "            f\"Average research impact: {basic_stats['citation_stats']['mean']:.1f} citations per paper\",\n",
    "            f\"Published across {len(basic_stats['journal_distribution'])} different journals\"\n",
    "        ]\n",
    "        \n",
    "        return summary\n",
    "    \n",
    "    def _review_methodologies(self, analysis):\n",
    "        \"\"\"Review methodological approaches.\"\"\"\n",
    "        # Mock methodology analysis\n",
    "        methodologies = [\n",
    "            \"Machine learning approaches dominate recent literature\",\n",
    "            \"Clinical trials and observational studies provide evidence base\",\n",
    "            \"Meta-analyses increasingly common for synthesis\",\n",
    "            \"Computational methods expanding rapidly\"\n",
    "        ]\n",
    "        return methodologies\n",
    "    \n",
    "    def _identify_research_gaps(self, analysis):\n",
    "        \"\"\"Identify research gaps.\"\"\"\n",
    "        gaps = [\n",
    "            \"Limited long-term follow-up studies\",\n",
    "            \"Need for larger diverse patient populations\",\n",
    "            \"Standardization of evaluation metrics required\",\n",
    "            \"Integration with clinical workflows underexplored\"\n",
    "        ]\n",
    "        return gaps\n",
    "    \n",
    "    def _suggest_future_research(self, analysis):\n",
    "        \"\"\"Suggest future research directions.\"\"\"\n",
    "        directions = [\n",
    "            \"Multi-center collaborative studies\",\n",
    "            \"Real-world evidence collection\",\n",
    "            \"Ethical framework development\",\n",
    "            \"Implementation science research\"\n",
    "        ]\n",
    "        return directions\n",
    "    \n",
    "    def generate_workflow_report(self):\n",
    "        \"\"\"Generate complete workflow report.\"\"\"\n",
    "        duration = datetime.now() - self.start_time\n",
    "        \n",
    "        report = f\"\"\"\n",
    "RESEARCH WORKFLOW REPORT\n",
    "========================\n",
    "\n",
    "Project: {self.project_name}\n",
    "Duration: {duration.total_seconds():.1f} seconds\n",
    "Steps Completed: {len(self.workflow_steps)}/5\n",
    "\n",
    "WORKFLOW SUMMARY:\n",
    "1. Question Formulation: ✓ Completed\n",
    "2. Literature Search: ✓ Completed  \n",
    "3. Content Analysis: ✓ Completed\n",
    "4. Synthesis Report: ✓ Completed\n",
    "5. Deliverables: ✓ Completed\n",
    "\n",
    "RESULTS OVERVIEW:\n",
    "- Papers Analyzed: {self.results['content_analysis']['basic_stats']['total_papers']}\n",
    "- Research Impact: {self.results['content_analysis']['basic_stats']['citation_stats']['total']:,} total citations\n",
    "- Time Period: {min(self.results['content_analysis']['basic_stats']['year_distribution'].keys())}-{max(self.results['content_analysis']['basic_stats']['year_distribution'].keys())}\n",
    "- Bibliography Entries: {self.results['deliverables']['bibliography']['entries']}\n",
    "\n",
    "STATUS: WORKFLOW COMPLETED SUCCESSFULLY\n",
    "\"\"\"\n",
    "        return report\n",
    "\n",
    "# Execute complete workflow\n",
    "project_name = \"AI_Healthcare_Literature_Review\"\n",
    "workflow = IntegratedResearchWorkflow(project_name)\n",
    "\n",
    "# Execute all workflow steps\n",
    "research_question = \"How can artificial intelligence improve healthcare delivery and patient outcomes?\"\n",
    "\n",
    "step1_plan = workflow.step1_question_formulation(research_question)\n",
    "step2_pipeline = workflow.step2_literature_search(step1_plan, max_papers=25)\n",
    "step3_analysis = workflow.step3_content_analysis(step2_pipeline)\n",
    "step4_report = workflow.step4_synthesis_report(step3_analysis)\n",
    "step5_deliverables = workflow.step5_deliverables(step2_pipeline)\n",
    "\n",
    "# Generate final report\n",
    "final_report = workflow.generate_workflow_report()\n",
    "print(final_report)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"COMPLETE RESEARCH WORKFLOW DEMONSTRATED\")\n",
    "print(\"All steps executed successfully!\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary\n",
    "\n",
    "The `scitex.web` module provides comprehensive web-based research capabilities for scientific applications:\n",
    "\n",
    "### Core Functions\n",
    "\n",
    "**📚 PubMed Integration**\n",
    "- `search_pubmed(query, n_entries)` - Search PubMed database for scientific articles\n",
    "- `_search_pubmed()`, `_fetch_details()` - Low-level PubMed API interaction\n",
    "- `batch_fetch_details()` - Asynchronous batch processing for efficiency\n",
    "- `get_crossref_metrics()` - Retrieve citation metrics from CrossRef\n",
    "\n",
    "**📄 Bibliography Management**\n",
    "- `format_bibtex()` - Generate properly formatted BibTeX entries\n",
    "- `save_bibtex()` - Save bibliography collections to files\n",
    "- `_get_citation()` - Retrieve official citations from PubMed\n",
    "- Automatic metadata enrichment with journal metrics\n",
    "\n",
    "**🌐 Web Content Processing**\n",
    "- `extract_main_content()` - Extract main content from HTML pages\n",
    "- `crawl_url()` - Crawl websites with depth control\n",
    "- `crawl_to_json()` - Generate structured summaries of crawled content\n",
    "- `summarize_url()` - Complete URL analysis pipeline\n",
    "\n",
    "### Key Features\n",
    "\n",
    "**🔍 Intelligent Search**\n",
    "1. **Multi-query strategies**: Generate optimized search terms from research questions\n",
    "2. **Batch processing**: Efficient handling of large literature collections\n",
    "3. **Metadata enrichment**: Automatic addition of impact factors and citation metrics\n",
    "4. **Error resilience**: Graceful handling of network issues and API limits\n",
    "\n",
    "**📊 Research Analytics**\n",
    "- Citation analysis and trend identification\n",
    "- Author collaboration network mapping\n",
    "- Journal impact assessment\n",
    "- Temporal research trend analysis\n",
    "\n",
    "**🤖 Automation Features**\n",
    "- Research question to search query translation\n",
    "- Automated literature review pipeline\n",
    "- Research gap identification\n",
    "- Future research direction suggestions\n",
    "\n",
    "### Advanced Capabilities\n",
    "\n",
    "**📈 Literature Review Pipeline**\n",
    "- Complete end-to-end literature review automation\n",
    "- Multi-dimensional analysis (citations, trends, collaborations)\n",
    "- Professional report generation\n",
    "- Integration with visualization tools\n",
    "\n",
    "**🔬 Research Assistant**\n",
    "- Natural language research question processing\n",
    "- Intelligent search strategy generation\n",
    "- Automated analysis and synthesis\n",
    "- Actionable research recommendations\n",
    "\n",
    "**🌍 Web Intelligence**\n",
    "- Content extraction with readability optimization\n",
    "- Multi-page crawling with link analysis\n",
    "- AI-powered content summarization\n",
    "- Structured data export\n",
    "\n",
    "### Use Cases\n",
    "\n",
    "**📖 Academic Research**\n",
    "- Systematic literature reviews\n",
    "- Meta-analysis preparation\n",
    "- Research gap identification\n",
    "- Citation network analysis\n",
    "\n",
    "**💼 Evidence-Based Practice**\n",
    "- Clinical guideline development\n",
    "- Treatment effectiveness reviews\n",
    "- Policy research support\n",
    "- Best practice identification\n",
    "\n",
    "**🔍 Competitive Intelligence**\n",
    "- Technology trend monitoring\n",
    "- Research landscape mapping\n",
    "- Collaboration opportunity identification\n",
    "- Innovation tracking\n",
    "\n",
    "### Integration Benefits\n",
    "\n",
    "- **SciTeX Ecosystem**: Seamless integration with other SciTeX modules\n",
    "- **Asynchronous Processing**: Efficient handling of large-scale operations\n",
    "- **Export Compatibility**: Standard formats (BibTeX, CSV, JSON)\n",
    "- **Visualization Ready**: Direct integration with matplotlib and pandas\n",
    "\n",
    "The module transforms manual literature review processes into automated, intelligent workflows that can process hundreds of papers and generate comprehensive research insights in minutes rather than weeks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}