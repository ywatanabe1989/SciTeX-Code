{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16fb5ce3",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [9]</a>'.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ddd429",
   "metadata": {
    "papermill": {
     "duration": 0.00448,
     "end_time": "2025-07-04T01:53:32.930777",
     "exception": false,
     "start_time": "2025-07-04T01:53:32.926297",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SciTeX General Utilities\n",
    "\n",
    "This comprehensive notebook demonstrates the SciTeX utils module capabilities, covering general utilities for scientific computing, system operations, and data management.\n",
    "\n",
    "## Features Covered\n",
    "\n",
    "### Data Compression\n",
    "* HDF5 compression utilities\n",
    "* Storage optimization\n",
    "* File size management\n",
    "\n",
    "### Communication\n",
    "* Email notifications\n",
    "* ANSI escape handling\n",
    "* System notifications\n",
    "\n",
    "### Grid Operations\n",
    "* Grid counting and generation\n",
    "* Parameter space exploration\n",
    "* Combinatorial utilities\n",
    "\n",
    "### System Information\n",
    "* Git branch detection\n",
    "* Hostname and user information\n",
    "* Environment detection\n",
    "\n",
    "### Search and Analysis\n",
    "* Advanced search capabilities\n",
    "* Content analysis\n",
    "* Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0462077",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T01:53:32.943593Z",
     "iopub.status.busy": "2025-07-04T01:53:32.941967Z",
     "iopub.status.idle": "2025-07-04T01:53:32.961982Z",
     "shell.execute_reply": "2025-07-04T01:53:32.959706Z"
    },
    "papermill": {
     "duration": 0.029604,
     "end_time": "2025-07-04T01:53:32.964808",
     "exception": false,
     "start_time": "2025-07-04T01:53:32.935204",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SciTeX Utils Module Tutorial - Ready to begin!\n",
      "Available utils functions: 11\n",
      "Functions: ['ansi_escape', 'compress_hdf5', 'count_grids', 'gen_footer', 'get_git_branch', 'get_hostname', 'get_username', 'notify', 'search', 'send_gmail', 'yield_grids']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "import scitex\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Set up example data directory\n",
    "data_dir = Path(\"./utils_examples\")\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"SciTeX Utils Module Tutorial - Ready to begin!\")\n",
    "print(f\"Available utils functions: {len(scitex.utils.__all__)}\")\n",
    "print(f\"Functions: {scitex.utils.__all__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47caf46f",
   "metadata": {
    "papermill": {
     "duration": 0.005915,
     "end_time": "2025-07-04T01:53:32.977583",
     "exception": false,
     "start_time": "2025-07-04T01:53:32.971668",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Part 1: System Information and Environment\n",
    "\n",
    "### 1.1 System Information Gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b615cbef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T01:53:32.990478Z",
     "iopub.status.busy": "2025-07-04T01:53:32.988997Z",
     "iopub.status.idle": "2025-07-04T01:53:33.006156Z",
     "shell.execute_reply": "2025-07-04T01:53:33.004116Z"
    },
    "papermill": {
     "duration": 0.025853,
     "end_time": "2025-07-04T01:53:33.008350",
     "exception": false,
     "start_time": "2025-07-04T01:53:32.982497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System Information:\n",
      "======================\n",
      "Hostname: ywata-note-win\n",
      "Username: ywatanabe\n",
      "Error getting git branch: get_git_branch() missing 1 required positional argument: 'scitex'\n",
      "Error generating footer: gen_footer() missing 4 required positional arguments: 'sender', 'script_name', 'scitex', and 'branch'\n",
      "\n",
      "Additional System Info:\n",
      "=========================\n",
      "Python version: 3.11.0rc1\n",
      "Platform: linux\n",
      "Current working directory: /home/ywatanabe/proj/SciTeX-Code\n",
      "Process ID: 257290\n",
      "\n",
      "Environment Variables:\n",
      "  HOME: /home/ywatanabe\n",
      "  USER: ywatanabe\n",
      "  PATH: /home/ywatanabe/.env-3.11/bin:/home/ywatanabe/.bin/git-tools/commands:/opt/mu-1.12.6/bin:/home/ywata...\n",
      "  SHELL: /bin/bash\n",
      "  LANG: en_US.UTF-8\n"
     ]
    }
   ],
   "source": [
    "# System information gathering\n",
    "print(\"System Information:\")\n",
    "print(\"=\" * 22)\n",
    "\n",
    "try:\n",
    "    # Get hostname\n",
    "    hostname = scitex.utils.get_hostname()\n",
    "    print(f\"Hostname: {hostname}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error getting hostname: {e}\")\n",
    "\n",
    "try:\n",
    "    # Get username\n",
    "    username = scitex.utils.get_username()\n",
    "    print(f\"Username: {username}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error getting username: {e}\")\n",
    "\n",
    "try:\n",
    "    # Get git branch\n",
    "    git_branch = scitex.utils.get_git_branch()\n",
    "    print(f\"Git branch: {git_branch}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error getting git branch: {e}\")\n",
    "\n",
    "# Generate footer with system info\n",
    "try:\n",
    "    footer = scitex.utils.gen_footer()\n",
    "    print(f\"\\nGenerated footer:\")\n",
    "    print(footer)\n",
    "except Exception as e:\n",
    "    print(f\"Error generating footer: {e}\")\n",
    "\n",
    "# Additional system information\n",
    "print(\"\\nAdditional System Info:\")\n",
    "print(\"=\" * 25)\n",
    "print(f\"Python version: {sys.version.split()[0]}\")\n",
    "print(f\"Platform: {sys.platform}\")\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "print(f\"Process ID: {os.getpid()}\")\n",
    "\n",
    "# Environment variables (selected)\n",
    "env_vars = ['HOME', 'USER', 'PATH', 'SHELL', 'LANG']\n",
    "print(\"\\nEnvironment Variables:\")\n",
    "for var in env_vars:\n",
    "    value = os.environ.get(var, 'Not set')\n",
    "    # Truncate PATH for readability\n",
    "    if var == 'PATH' and len(value) > 100:\n",
    "        value = value[:100] + '...'\n",
    "    print(f\"  {var}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08137169",
   "metadata": {
    "papermill": {
     "duration": 0.006702,
     "end_time": "2025-07-04T01:53:33.020470",
     "exception": false,
     "start_time": "2025-07-04T01:53:33.013768",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1.2 Notification System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91006152",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T01:53:33.034638Z",
     "iopub.status.busy": "2025-07-04T01:53:33.033344Z",
     "iopub.status.idle": "2025-07-04T01:53:33.047070Z",
     "shell.execute_reply": "2025-07-04T01:53:33.044915Z"
    },
    "papermill": {
     "duration": 0.02328,
     "end_time": "2025-07-04T01:53:33.049212",
     "exception": false,
     "start_time": "2025-07-04T01:53:33.025932",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notification System:\n",
      "======================\n",
      "\n",
      "Sending info notification...\n",
      "Notification failed: notify() got an unexpected keyword argument 'level'\n",
      "\n",
      "Sending success notification...\n",
      "Notification failed: notify() got an unexpected keyword argument 'level'\n",
      "\n",
      "Sending warning notification...\n",
      "Notification failed: notify() got an unexpected keyword argument 'level'\n",
      "\n",
      "Sending error notification...\n",
      "Notification failed: notify() got an unexpected keyword argument 'level'\n",
      "\n",
      "ANSI Escape Handling:\n",
      "=========================\n",
      "ANSI escape error: 're.Pattern' object is not callable\n",
      "ANSI escape error: 're.Pattern' object is not callable\n",
      "ANSI escape error: 're.Pattern' object is not callable\n",
      "ANSI escape error: 're.Pattern' object is not callable\n",
      "ANSI escape error: 're.Pattern' object is not callable\n"
     ]
    }
   ],
   "source": [
    "# Notification system demonstration\n",
    "print(\"Notification System:\")\n",
    "print(\"=\" * 22)\n",
    "\n",
    "# Test notification with different messages\n",
    "notification_tests = [\n",
    "    {\n",
    "        'message': 'Test notification from SciTeX utils',\n",
    "        'level': 'info'\n",
    "    },\n",
    "    {\n",
    "        'message': 'Computation completed successfully',\n",
    "        'level': 'success'\n",
    "    },\n",
    "    {\n",
    "        'message': 'Warning: Low memory detected',\n",
    "        'level': 'warning'\n",
    "    },\n",
    "    {\n",
    "        'message': 'Error: Unable to process data',\n",
    "        'level': 'error'\n",
    "    }\n",
    "]\n",
    "\n",
    "for test in notification_tests:\n",
    "    try:\n",
    "        print(f\"\\nSending {test['level']} notification...\")\n",
    "        result = scitex.utils.notify(\n",
    "            message=test['message'],\n",
    "            level=test['level']\n",
    "        )\n",
    "        print(f\"Notification sent: {result}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Notification failed: {e}\")\n",
    "\n",
    "# ANSI escape sequence handling\n",
    "print(\"\\nANSI Escape Handling:\")\n",
    "print(\"=\" * 25)\n",
    "\n",
    "ansi_test_strings = [\n",
    "    \"\\033[31mRed text\\033[0m\",\n",
    "    \"\\033[1;32mBold green text\\033[0m\",\n",
    "    \"\\033[4;34mUnderlined blue text\\033[0m\",\n",
    "    \"Normal text without ANSI\",\n",
    "    \"\\033[91mBright red\\033[0m mixed with \\033[92mgreen\\033[0m\"\n",
    "]\n",
    "\n",
    "for test_string in ansi_test_strings:\n",
    "    try:\n",
    "        cleaned = scitex.utils.ansi_escape(test_string)\n",
    "        print(f\"Original: '{test_string}'\")\n",
    "        print(f\"Cleaned:  '{cleaned}'\")\n",
    "        print()\n",
    "    except Exception as e:\n",
    "        print(f\"ANSI escape error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e648ed5",
   "metadata": {
    "papermill": {
     "duration": 0.005786,
     "end_time": "2025-07-04T01:53:33.060884",
     "exception": false,
     "start_time": "2025-07-04T01:53:33.055098",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Part 2: Grid Operations and Parameter Space\n",
    "\n",
    "### 2.1 Grid Generation and Counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "937712cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T01:53:33.075474Z",
     "iopub.status.busy": "2025-07-04T01:53:33.073723Z",
     "iopub.status.idle": "2025-07-04T01:53:33.095275Z",
     "shell.execute_reply": "2025-07-04T01:53:33.093146Z"
    },
    "papermill": {
     "duration": 0.030544,
     "end_time": "2025-07-04T01:53:33.097444",
     "exception": false,
     "start_time": "2025-07-04T01:53:33.066900",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Operations:\n",
      "==================\n",
      "\n",
      "Machine Learning Parameter Space:\n",
      "  Parameters: ['learning_rate', 'batch_size', 'dropout', 'epochs']\n",
      "  Parameter counts: [3, 4, 3, 3]\n",
      "  Total combinations: 108\n",
      "    learning_rate: 3 values\n",
      "    batch_size: 4 values\n",
      "    dropout: 3 values\n",
      "    epochs: 3 values\n",
      "\n",
      "Signal Processing Parameter Space:\n",
      "  Parameters: ['window_size', 'overlap', 'filter_type', 'cutoff_freq']\n",
      "  Parameter counts: [4, 3, 3, 5]\n",
      "  Total combinations: 180\n",
      "    window_size: 4 values\n",
      "    overlap: 3 values\n",
      "    filter_type: 3 values\n",
      "    cutoff_freq: 5 values\n",
      "\n",
      "Optimization Parameter Space:\n",
      "  Parameters: ['algorithm', 'momentum', 'weight_decay']\n",
      "  Parameter counts: [3, 3, 4]\n",
      "  Total combinations: 36\n",
      "    algorithm: 3 values\n",
      "    momentum: 3 values\n",
      "    weight_decay: 4 values\n",
      "\n",
      "Memory Estimation for Large Spaces:\n",
      "======================================\n",
      "\n",
      "Image Processing:\n",
      "  Total combinations: 1,260\n",
      "  Estimated memory: 123.0 KiB\n",
      "  ✓ Manageable parameter space size\n",
      "\n",
      "Hyperparameter Search:\n",
      "  Total combinations: 2,160\n",
      "  Estimated memory: 210.9 KiB\n",
      "  ✓ Manageable parameter space size\n"
     ]
    }
   ],
   "source": [
    "# Grid operations for parameter space exploration\n",
    "print(\"Grid Operations:\")\n",
    "print(\"=\" * 18)\n",
    "\n",
    "# Define parameter spaces for different scenarios\n",
    "parameter_spaces = {\n",
    "    'machine_learning': {\n",
    "        'learning_rate': [0.001, 0.01, 0.1],\n",
    "        'batch_size': [16, 32, 64, 128],\n",
    "        'dropout': [0.2, 0.3, 0.5],\n",
    "        'epochs': [50, 100, 200]\n",
    "    },\n",
    "    'signal_processing': {\n",
    "        'window_size': [64, 128, 256, 512],\n",
    "        'overlap': [0.25, 0.5, 0.75],\n",
    "        'filter_type': ['lowpass', 'highpass', 'bandpass'],\n",
    "        'cutoff_freq': [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "    },\n",
    "    'optimization': {\n",
    "        'algorithm': ['gradient_descent', 'adam', 'rmsprop'],\n",
    "        'momentum': [0.9, 0.95, 0.99],\n",
    "        'weight_decay': [0.0, 1e-4, 1e-3, 1e-2]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Count grids for each parameter space\n",
    "for space_name, params in parameter_spaces.items():\n",
    "    try:\n",
    "        grid_count = scitex.utils.count_grids(params)\n",
    "        print(f\"\\n{space_name.replace('_', ' ').title()} Parameter Space:\")\n",
    "        print(f\"  Parameters: {list(params.keys())}\")\n",
    "        print(f\"  Parameter counts: {[len(v) for v in params.values()]}\")\n",
    "        print(f\"  Total combinations: {grid_count}\")\n",
    "        \n",
    "        # Show size of each parameter\n",
    "        for param_name, param_values in params.items():\n",
    "            print(f\"    {param_name}: {len(param_values)} values\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error counting grids for {space_name}: {e}\")\n",
    "\n",
    "# Demonstrate memory estimation for large parameter spaces\n",
    "print(\"\\nMemory Estimation for Large Spaces:\")\n",
    "print(\"=\" * 38)\n",
    "\n",
    "large_spaces = {\n",
    "    'image_processing': {\n",
    "        'kernel_size': list(range(3, 16, 2)),  # 3, 5, 7, 9, 11, 13, 15\n",
    "        'stride': [1, 2, 3, 4],\n",
    "        'padding': [0, 1, 2],\n",
    "        'dilation': [1, 2, 3],\n",
    "        'activation': ['relu', 'tanh', 'sigmoid', 'leaky_relu', 'elu']\n",
    "    },\n",
    "    'hyperparameter_search': {\n",
    "        'num_layers': list(range(1, 11)),  # 1 to 10\n",
    "        'hidden_units': [32, 64, 128, 256, 512, 1024],\n",
    "        'learning_rate': [10**(-i) for i in range(1, 7)],  # 0.1 to 0.000001\n",
    "        'regularization': [0.0, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1]\n",
    "    }\n",
    "}\n",
    "\n",
    "for space_name, params in large_spaces.items():\n",
    "    try:\n",
    "        grid_count = scitex.utils.count_grids(params)\n",
    "        \n",
    "        # Estimate memory usage (rough calculation)\n",
    "        # Assume each parameter combination takes ~100 bytes\n",
    "        estimated_memory = grid_count * 100\n",
    "        readable_memory = scitex.str.readable_bytes(estimated_memory)\n",
    "        \n",
    "        print(f\"\\n{space_name.replace('_', ' ').title()}:\")\n",
    "        print(f\"  Total combinations: {grid_count:,}\")\n",
    "        print(f\"  Estimated memory: {readable_memory}\")\n",
    "        \n",
    "        if grid_count > 1000000:\n",
    "            print(f\"  ⚠️  Very large parameter space - consider reduction!\")\n",
    "        elif grid_count > 100000:\n",
    "            print(f\"  ⚠️  Large parameter space - may require distributed computing\")\n",
    "        else:\n",
    "            print(f\"  ✓ Manageable parameter space size\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing {space_name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b527d8",
   "metadata": {
    "papermill": {
     "duration": 0.00526,
     "end_time": "2025-07-04T01:53:33.108781",
     "exception": false,
     "start_time": "2025-07-04T01:53:33.103521",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 2.2 Grid Generation and Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1542088",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T01:53:33.123416Z",
     "iopub.status.busy": "2025-07-04T01:53:33.122291Z",
     "iopub.status.idle": "2025-07-04T01:53:33.143619Z",
     "shell.execute_reply": "2025-07-04T01:53:33.141560Z"
    },
    "papermill": {
     "duration": 0.030602,
     "end_time": "2025-07-04T01:53:33.145725",
     "exception": false,
     "start_time": "2025-07-04T01:53:33.115123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Generation and Iteration:\n",
      "=================================\n",
      "Demo parameter space: {'learning_rate': [0.01, 0.1], 'batch_size': [32, 64], 'optimizer': ['adam', 'sgd']}\n",
      "Expected combinations: 8\n",
      "\n",
      "Generated parameter combinations:\n",
      "  1: {'learning_rate': 0.01, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "  2: {'learning_rate': 0.01, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "  3: {'learning_rate': 0.01, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "  4: {'learning_rate': 0.01, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "  5: {'learning_rate': 0.1, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "  6: {'learning_rate': 0.1, 'batch_size': 32, 'optimizer': 'sgd'}\n",
      "  7: {'learning_rate': 0.1, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "  8: {'learning_rate': 0.1, 'batch_size': 64, 'optimizer': 'sgd'}\n",
      "\n",
      "Total generated: 8 combinations\n",
      "\n",
      "Large Grid Sampling:\n",
      "======================\n",
      "Large parameter space: 240 total combinations\n",
      "\n",
      "Sampling first 10 combinations:\n",
      "  1: {'alpha': 0.1, 'beta': 0.01, 'gamma': 0.9, 'method': 'A'}\n",
      "  2: {'alpha': 0.1, 'beta': 0.01, 'gamma': 0.9, 'method': 'B'}\n",
      "  3: {'alpha': 0.1, 'beta': 0.01, 'gamma': 0.9, 'method': 'C'}\n",
      "  4: {'alpha': 0.1, 'beta': 0.01, 'gamma': 0.95, 'method': 'A'}\n",
      "  5: {'alpha': 0.1, 'beta': 0.01, 'gamma': 0.95, 'method': 'B'}\n",
      "  6: {'alpha': 0.1, 'beta': 0.01, 'gamma': 0.95, 'method': 'C'}\n",
      "  7: {'alpha': 0.1, 'beta': 0.01, 'gamma': 0.99, 'method': 'A'}\n",
      "  8: {'alpha': 0.1, 'beta': 0.01, 'gamma': 0.99, 'method': 'B'}\n",
      "  9: {'alpha': 0.1, 'beta': 0.01, 'gamma': 0.99, 'method': 'C'}\n",
      "  10: {'alpha': 0.1, 'beta': 0.01, 'gamma': 0.999, 'method': 'A'}\n",
      "  ... and 230 more combinations\n",
      "\n",
      "Hyperparameter Optimization Simulation:\n",
      "==========================================\n",
      "Running optimization over 27 combinations...\n",
      "  1/27: {'learning_rate': 0.001, 'hidden_units': 64, 'dropout': 0.2} -> 0.7177\n",
      "  2/27: {'learning_rate': 0.001, 'hidden_units': 64, 'dropout': 0.3} -> 0.7692\n",
      "  3/27: {'learning_rate': 0.001, 'hidden_units': 64, 'dropout': 0.5} -> 0.6587\n",
      "  4/27: {'learning_rate': 0.001, 'hidden_units': 128, 'dropout': 0.2} -> 0.7422\n",
      "  5/27: {'learning_rate': 0.001, 'hidden_units': 128, 'dropout': 0.3} -> 0.7330\n",
      "  6/27: {'learning_rate': 0.001, 'hidden_units': 128, 'dropout': 0.5} -> 0.7219\n",
      "  7/27: {'learning_rate': 0.001, 'hidden_units': 256, 'dropout': 0.2} -> 0.7205\n",
      "  8/27: {'learning_rate': 0.001, 'hidden_units': 256, 'dropout': 0.3} -> 0.7027\n",
      "  9/27: {'learning_rate': 0.001, 'hidden_units': 256, 'dropout': 0.5} -> 0.6899\n",
      "  10/27: {'learning_rate': 0.01, 'hidden_units': 64, 'dropout': 0.2} -> 0.8150\n",
      "  11/27: {'learning_rate': 0.01, 'hidden_units': 64, 'dropout': 0.3} -> 0.8345\n",
      "  12/27: {'learning_rate': 0.01, 'hidden_units': 64, 'dropout': 0.5} -> 0.7720\n",
      "  13/27: {'learning_rate': 0.01, 'hidden_units': 128, 'dropout': 0.2} -> 0.8589\n",
      "  14/27: {'learning_rate': 0.01, 'hidden_units': 128, 'dropout': 0.3} -> 0.9109\n",
      "  15/27: {'learning_rate': 0.01, 'hidden_units': 128, 'dropout': 0.5} -> 0.8006\n",
      "  16/27: {'learning_rate': 0.01, 'hidden_units': 256, 'dropout': 0.2} -> 0.8506\n",
      "  17/27: {'learning_rate': 0.01, 'hidden_units': 256, 'dropout': 0.3} -> 0.8698\n",
      "  18/27: {'learning_rate': 0.01, 'hidden_units': 256, 'dropout': 0.5} -> 0.8040\n",
      "  19/27: {'learning_rate': 0.1, 'hidden_units': 64, 'dropout': 0.2} -> 0.6155\n",
      "  20/27: {'learning_rate': 0.1, 'hidden_units': 64, 'dropout': 0.3} -> 0.7257\n",
      "  21/27: {'learning_rate': 0.1, 'hidden_units': 64, 'dropout': 0.5} -> 0.6337\n",
      "  22/27: {'learning_rate': 0.1, 'hidden_units': 128, 'dropout': 0.2} -> 0.6593\n",
      "  23/27: {'learning_rate': 0.1, 'hidden_units': 128, 'dropout': 0.3} -> 0.6897\n",
      "  24/27: {'learning_rate': 0.1, 'hidden_units': 128, 'dropout': 0.5} -> 0.7347\n",
      "  25/27: {'learning_rate': 0.1, 'hidden_units': 256, 'dropout': 0.2} -> 0.6804\n",
      "  26/27: {'learning_rate': 0.1, 'hidden_units': 256, 'dropout': 0.3} -> 0.7307\n",
      "  27/27: {'learning_rate': 0.1, 'hidden_units': 256, 'dropout': 0.5} -> 0.6930\n",
      "\n",
      "Best combination:\n",
      "  Parameters: {'learning_rate': 0.01, 'hidden_units': 128, 'dropout': 0.3}\n",
      "  Performance: 0.9109\n",
      "\n",
      "Performance Statistics:\n",
      "  Mean: 0.7457\n",
      "  Std:  0.0744\n",
      "  Min:  0.6155\n",
      "  Max:  0.9109\n"
     ]
    }
   ],
   "source": [
    "# Grid generation for parameter exploration\n",
    "print(\"Grid Generation and Iteration:\")\n",
    "print(\"=\" * 33)\n",
    "\n",
    "# Small parameter space for demonstration\n",
    "demo_params = {\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'batch_size': [32, 64],\n",
    "    'optimizer': ['adam', 'sgd']\n",
    "}\n",
    "\n",
    "print(f\"Demo parameter space: {demo_params}\")\n",
    "print(f\"Expected combinations: {scitex.utils.count_grids(demo_params)}\")\n",
    "print(\"\\nGenerated parameter combinations:\")\n",
    "\n",
    "try:\n",
    "    # Generate all combinations\n",
    "    combination_count = 0\n",
    "    for combination in scitex.utils.yield_grids(demo_params):\n",
    "        combination_count += 1\n",
    "        print(f\"  {combination_count}: {combination}\")\n",
    "    \n",
    "    print(f\"\\nTotal generated: {combination_count} combinations\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error generating grids: {e}\")\n",
    "\n",
    "# Larger example with sampling\n",
    "print(\"\\nLarge Grid Sampling:\")\n",
    "print(\"=\" * 22)\n",
    "\n",
    "large_params = {\n",
    "    'alpha': [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "    'beta': [0.01, 0.05, 0.1, 0.2],\n",
    "    'gamma': [0.9, 0.95, 0.99, 0.999],\n",
    "    'method': ['A', 'B', 'C']\n",
    "}\n",
    "\n",
    "total_combinations = scitex.utils.count_grids(large_params)\n",
    "print(f\"Large parameter space: {total_combinations} total combinations\")\n",
    "print(\"\\nSampling first 10 combinations:\")\n",
    "\n",
    "try:\n",
    "    sample_count = 0\n",
    "    for combination in scitex.utils.yield_grids(large_params):\n",
    "        sample_count += 1\n",
    "        print(f\"  {sample_count}: {combination}\")\n",
    "        \n",
    "        if sample_count >= 10:\n",
    "            print(f\"  ... and {total_combinations - 10} more combinations\")\n",
    "            break\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"Error sampling grids: {e}\")\n",
    "\n",
    "# Practical application: Hyperparameter optimization simulation\n",
    "print(\"\\nHyperparameter Optimization Simulation:\")\n",
    "print(\"=\" * 42)\n",
    "\n",
    "# Simulate evaluating different hyperparameter combinations\n",
    "optimization_params = {\n",
    "    'learning_rate': [0.001, 0.01, 0.1],\n",
    "    'hidden_units': [64, 128, 256],\n",
    "    'dropout': [0.2, 0.3, 0.5]\n",
    "}\n",
    "\n",
    "def simulate_model_performance(params):\n",
    "    \"\"\"Simulate model performance based on hyperparameters.\"\"\"\n",
    "    # Simulate some realistic performance based on parameters\n",
    "    base_score = 0.7\n",
    "    \n",
    "    # Learning rate effect\n",
    "    if params['learning_rate'] == 0.01:\n",
    "        base_score += 0.1\n",
    "    elif params['learning_rate'] == 0.1:\n",
    "        base_score -= 0.05\n",
    "    \n",
    "    # Hidden units effect\n",
    "    if params['hidden_units'] == 128:\n",
    "        base_score += 0.05\n",
    "    elif params['hidden_units'] == 256:\n",
    "        base_score += 0.02\n",
    "    \n",
    "    # Dropout effect\n",
    "    if params['dropout'] == 0.3:\n",
    "        base_score += 0.03\n",
    "    \n",
    "    # Add some random noise\n",
    "    import random\n",
    "    noise = random.uniform(-0.05, 0.05)\n",
    "    \n",
    "    return min(1.0, max(0.0, base_score + noise))\n",
    "\n",
    "# Run optimization simulation\n",
    "results = []\n",
    "total_combinations = scitex.utils.count_grids(optimization_params)\n",
    "\n",
    "print(f\"Running optimization over {total_combinations} combinations...\")\n",
    "\n",
    "for i, params in enumerate(scitex.utils.yield_grids(optimization_params), 1):\n",
    "    performance = simulate_model_performance(params)\n",
    "    results.append({\n",
    "        'combination': i,\n",
    "        'params': params.copy(),\n",
    "        'performance': performance\n",
    "    })\n",
    "    print(f\"  {i}/{total_combinations}: {params} -> {performance:.4f}\")\n",
    "\n",
    "# Find best combination\n",
    "best_result = max(results, key=lambda x: x['performance'])\n",
    "print(f\"\\nBest combination:\")\n",
    "print(f\"  Parameters: {best_result['params']}\")\n",
    "print(f\"  Performance: {best_result['performance']:.4f}\")\n",
    "\n",
    "# Performance statistics\n",
    "performances = [r['performance'] for r in results]\n",
    "print(f\"\\nPerformance Statistics:\")\n",
    "print(f\"  Mean: {np.mean(performances):.4f}\")\n",
    "print(f\"  Std:  {np.std(performances):.4f}\")\n",
    "print(f\"  Min:  {np.min(performances):.4f}\")\n",
    "print(f\"  Max:  {np.max(performances):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754e40b9",
   "metadata": {
    "papermill": {
     "duration": 0.005839,
     "end_time": "2025-07-04T01:53:33.157822",
     "exception": false,
     "start_time": "2025-07-04T01:53:33.151983",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Part 3: Data Compression and Storage\n",
    "\n",
    "### 3.1 HDF5 Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e81298f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T01:53:33.172246Z",
     "iopub.status.busy": "2025-07-04T01:53:33.171359Z",
     "iopub.status.idle": "2025-07-04T01:53:33.355105Z",
     "shell.execute_reply": "2025-07-04T01:53:33.353107Z"
    },
    "papermill": {
     "duration": 0.193445,
     "end_time": "2025-07-04T01:53:33.357466",
     "exception": false,
     "start_time": "2025-07-04T01:53:33.164021",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HDF5 Compression:\n",
      "====================\n",
      "Test datasets created:\n",
      "  random_data: shape (1000, 100), dtype float64\n",
      "  structured_data: shape (1000, 100), dtype int64\n",
      "  sparse_data: shape (1000, 100), dtype float64\n",
      "  time_series: shape (100, 100), dtype float64\n",
      "  image_like: shape (100, 100, 3), dtype uint8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing SciTeX HDF5 compression:\n",
      "Compressing utils_examples/compression_tests/random_data_uncompressed.h5 to utils_examples/compression_tests/random_data_scitex_compressed.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compression complete. Original size: 0.00 GB, New size: 0.00 GB\n",
      "  random_data: SciTeX compression result - utils_examples/compression_tests/random_data_scitex_compressed.h5\n",
      "Compressing utils_examples/compression_tests/structured_data_uncompressed.h5 to utils_examples/compression_tests/structured_data_scitex_compressed.h5\n",
      "Compression complete. Original size: 0.00 GB, New size: 0.00 GB\n",
      "  structured_data: SciTeX compression result - utils_examples/compression_tests/structured_data_scitex_compressed.h5\n",
      "Compressing utils_examples/compression_tests/sparse_data_uncompressed.h5 to utils_examples/compression_tests/sparse_data_scitex_compressed.h5\n",
      "Compression complete. Original size: 0.00 GB, New size: 0.00 GB\n",
      "  sparse_data: SciTeX compression result - utils_examples/compression_tests/sparse_data_scitex_compressed.h5\n",
      "Compressing utils_examples/compression_tests/time_series_uncompressed.h5 to utils_examples/compression_tests/time_series_scitex_compressed.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compression complete. Original size: 0.00 GB, New size: 0.00 GB\n",
      "  time_series: SciTeX compression result - utils_examples/compression_tests/time_series_scitex_compressed.h5\n",
      "Compressing utils_examples/compression_tests/image_like_uncompressed.h5 to utils_examples/compression_tests/image_like_scitex_compressed.h5\n",
      "Compression complete. Original size: 0.00 GB, New size: 0.00 GB\n",
      "  image_like: SciTeX compression result - utils_examples/compression_tests/image_like_scitex_compressed.h5\n",
      "\n",
      "File size comparison:\n",
      "=========================\n",
      "\n",
      "random_data:\n",
      "  Uncompressed: 783.2 KiB\n",
      "  Compressed:   756.9 KiB\n",
      "  Ratio: 1.03x, Space saved: 3.4%\n",
      "  SciTeX:       757.0 KiB\n",
      "\n",
      "structured_data:\n",
      "  Uncompressed: 783.2 KiB\n",
      "  Compressed:   9.8 KiB\n",
      "  Ratio: 80.14x, Space saved: 98.8%\n",
      "  SciTeX:       11.6 KiB\n",
      "\n",
      "sparse_data:\n",
      "  Uncompressed: 783.2 KiB\n",
      "  Compressed:   7.5 KiB\n",
      "  Ratio: 104.43x, Space saved: 99.0%\n",
      "  SciTeX:       8.7 KiB\n",
      "\n",
      "time_series:\n",
      "  Uncompressed: 80.1 KiB\n",
      "  Compressed:   78.3 KiB\n",
      "  Ratio: 1.02x, Space saved: 2.3%\n",
      "  SciTeX:       78.3 KiB\n",
      "\n",
      "image_like:\n",
      "  Uncompressed: 31.3 KiB\n",
      "  Compressed:   33.8 KiB\n",
      "  Ratio: 0.93x, Space saved: -7.9%\n",
      "  SciTeX:       33.8 KiB\n"
     ]
    }
   ],
   "source": [
    "# HDF5 compression demonstration\n",
    "print(\"HDF5 Compression:\")\n",
    "print(\"=\" * 20)\n",
    "\n",
    "# Create test data for compression\n",
    "compression_test_dir = data_dir / \"compression_tests\"\n",
    "compression_test_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Generate different types of data\n",
    "test_datasets = {\n",
    "    'random_data': np.random.randn(1000, 100),\n",
    "    'structured_data': np.tile(np.arange(100), (1000, 1)),\n",
    "    'sparse_data': np.zeros((1000, 100)),\n",
    "    'time_series': np.sin(np.linspace(0, 100*np.pi, 10000)).reshape(100, 100),\n",
    "    'image_like': np.random.randint(0, 256, (100, 100, 3), dtype=np.uint8)\n",
    "}\n",
    "\n",
    "# Add some structure to sparse data\n",
    "test_datasets['sparse_data'][::10, ::10] = 1.0\n",
    "\n",
    "print(\"Test datasets created:\")\n",
    "for name, data in test_datasets.items():\n",
    "    print(f\"  {name}: shape {data.shape}, dtype {data.dtype}\")\n",
    "\n",
    "# Test HDF5 compression if h5py is available\n",
    "try:\n",
    "    import h5py\n",
    "    \n",
    "    # Create uncompressed HDF5 files\n",
    "    uncompressed_files = {}\n",
    "    compressed_files = {}\n",
    "    \n",
    "    for name, data in test_datasets.items():\n",
    "        # Uncompressed file\n",
    "        uncompressed_file = compression_test_dir / f\"{name}_uncompressed.h5\"\n",
    "        with h5py.File(uncompressed_file, 'w') as f:\n",
    "            f.create_dataset('data', data=data)\n",
    "        uncompressed_files[name] = uncompressed_file\n",
    "        \n",
    "        # Compressed file\n",
    "        compressed_file = compression_test_dir / f\"{name}_compressed.h5\"\n",
    "        with h5py.File(compressed_file, 'w') as f:\n",
    "            f.create_dataset('data', data=data, compression='gzip', compression_opts=9)\n",
    "        compressed_files[name] = compressed_file\n",
    "    \n",
    "    # Test scitex compression utility\n",
    "    print(\"\\nTesting SciTeX HDF5 compression:\")\n",
    "    for name, uncompressed_file in uncompressed_files.items():\n",
    "        try:\n",
    "            scitex_compressed_file = compression_test_dir / f\"{name}_scitex_compressed.h5\"\n",
    "            \n",
    "            # Use scitex compression\n",
    "            result = scitex.utils.compress_hdf5(\n",
    "                str(uncompressed_file), \n",
    "                str(scitex_compressed_file)\n",
    "            )\n",
    "            \n",
    "            print(f\"  {name}: SciTeX compression result - {result}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  {name}: SciTeX compression error - {e}\")\n",
    "    \n",
    "    # Compare file sizes\n",
    "    print(\"\\nFile size comparison:\")\n",
    "    print(\"=\" * 25)\n",
    "    \n",
    "    for name in test_datasets.keys():\n",
    "        print(f\"\\n{name}:\")\n",
    "        \n",
    "        # Uncompressed size\n",
    "        if name in uncompressed_files:\n",
    "            uncompressed_size = uncompressed_files[name].stat().st_size\n",
    "            print(f\"  Uncompressed: {scitex.str.readable_bytes(uncompressed_size)}\")\n",
    "        \n",
    "        # Compressed size\n",
    "        if name in compressed_files:\n",
    "            compressed_size = compressed_files[name].stat().st_size\n",
    "            print(f\"  Compressed:   {scitex.str.readable_bytes(compressed_size)}\")\n",
    "            \n",
    "            if name in uncompressed_files:\n",
    "                compression_ratio = uncompressed_size / compressed_size\n",
    "                space_saved = (1 - compressed_size / uncompressed_size) * 100\n",
    "                print(f\"  Ratio: {compression_ratio:.2f}x, Space saved: {space_saved:.1f}%\")\n",
    "        \n",
    "        # SciTeX compressed size\n",
    "        scitex_file = compression_test_dir / f\"{name}_scitex_compressed.h5\"\n",
    "        if scitex_file.exists():\n",
    "            scitex_size = scitex_file.stat().st_size\n",
    "            print(f\"  SciTeX:       {scitex.str.readable_bytes(scitex_size)}\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"h5py not available - skipping HDF5 compression tests\")\n",
    "except Exception as e:\n",
    "    print(f\"HDF5 compression test error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f845273b",
   "metadata": {
    "papermill": {
     "duration": 0.006763,
     "end_time": "2025-07-04T01:53:33.371286",
     "exception": false,
     "start_time": "2025-07-04T01:53:33.364523",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Part 4: Search and Analysis Utilities\n",
    "\n",
    "### 4.1 Advanced Search Capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca608433",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T01:53:33.386596Z",
     "iopub.status.busy": "2025-07-04T01:53:33.386219Z",
     "iopub.status.idle": "2025-07-04T01:53:33.408986Z",
     "shell.execute_reply": "2025-07-04T01:53:33.407272Z"
    },
    "papermill": {
     "duration": 0.03339,
     "end_time": "2025-07-04T01:53:33.411684",
     "exception": false,
     "start_time": "2025-07-04T01:53:33.378294",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advanced Search Utilities:\n",
      "============================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 5 test files:\n",
      "  experiment_log.txt: 339.0 B\n",
      "  data_analysis.py: 559.0 B\n",
      "  config.json: 444.0 B\n",
      "  results.csv: 248.0 B\n",
      "  readme.md: 328.0 B\n",
      "\n",
      "Search Tests:\n",
      "===============\n",
      "\n",
      "Find files containing \"accuracy\":\n",
      "Query: 'accuracy'\n",
      "  Search error: search() got an unexpected keyword argument 'pattern'\n",
      "\n",
      "Find files containing \"learning_rate\":\n",
      "Query: 'learning_rate'\n",
      "  Search error: search() got an unexpected keyword argument 'pattern'\n",
      "\n",
      "Find files containing \"ResNet\":\n",
      "Query: 'ResNet'\n",
      "  Search error: search() got an unexpected keyword argument 'pattern'\n",
      "\n",
      "Find files with pandas import (regex):\n",
      "Query: 'import.*pandas'\n",
      "  Search error: search() got an unexpected keyword argument 'pattern'\n",
      "\n",
      "Find files with decimal numbers (regex):\n",
      "Query: '0\\.[0-9]+'\n",
      "  Search error: search() got an unexpected keyword argument 'pattern'\n",
      "\n",
      "File Content Analysis:\n",
      "=========================\n",
      "\n",
      "experiment_log.txt:\n",
      "  Lines: 17\n",
      "  Words: 40\n",
      "  Characters: 341\n",
      "  Numbers found: 11 (['2024', '01', '15', '50', '0.001']...)\n",
      "  Keywords: ['accuracy', 'model', 'data', 'training', 'learning', 'neural', 'network']\n",
      "\n",
      "data_analysis.py:\n",
      "  Lines: 22\n",
      "  Words: 54\n",
      "  Characters: 561\n",
      "  Keywords: ['accuracy', 'model', 'data']\n",
      "\n",
      "config.json:\n",
      "  Lines: 23\n",
      "  Words: 39\n",
      "  Characters: 446\n",
      "  Numbers found: 7 (['224', '224', '3', '1000', '0.001']...)\n",
      "  Keywords: ['model', 'data', 'training', 'learning', 'neural', 'network']\n",
      "\n",
      "results.csv:\n",
      "  Lines: 8\n",
      "  Words: 6\n",
      "  Characters: 250\n",
      "  Numbers found: 35 (['1', '0.234', '0.245', '0.223', '2.345']...)\n",
      "  Keywords: ['accuracy']\n",
      "\n",
      "readme.md:\n",
      "  Lines: 21\n",
      "  Words: 47\n",
      "  Characters: 330\n",
      "  Numbers found: 4 (['50', '88.5', '87.2', '86.8'])\n",
      "  Keywords: ['accuracy', 'model', 'data', 'learning']\n"
     ]
    }
   ],
   "source": [
    "# Advanced search utilities\n",
    "print(\"Advanced Search Utilities:\")\n",
    "print(\"=\" * 28)\n",
    "\n",
    "# Create test data for searching\n",
    "search_test_dir = data_dir / \"search_tests\"\n",
    "search_test_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Create test files with different content types\n",
    "test_files_content = {\n",
    "    'experiment_log.txt': '''\n",
    "Experiment Log - Neural Network Training\n",
    "Date: 2024-01-15\n",
    "Model: ResNet-50\n",
    "Dataset: ImageNet subset\n",
    "Hyperparameters:\n",
    "  learning_rate: 0.001\n",
    "  batch_size: 32\n",
    "  epochs: 100\n",
    "  optimizer: Adam\n",
    "Results:\n",
    "  Training accuracy: 0.945\n",
    "  Validation accuracy: 0.892\n",
    "  Test accuracy: 0.885\n",
    "  Training time: 2.5 hours\n",
    "Notes: Model converged successfully\n",
    "''',\n",
    "    'data_analysis.py': '''\n",
    "#!/usr/bin/env python3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_data(filename):\n",
    "    \"\"\"Load data from CSV file.\"\"\"\n",
    "    return pd.read_csv(filename)\n",
    "\n",
    "def analyze_performance(data):\n",
    "    \"\"\"Analyze model performance metrics.\"\"\"\n",
    "    accuracy = data['accuracy'].mean()\n",
    "    precision = data['precision'].mean()\n",
    "    recall = data['recall'].mean()\n",
    "    return accuracy, precision, recall\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data = load_data(\"results.csv\")\n",
    "    metrics = analyze_performance(data)\n",
    "    print(f\"Performance: {metrics}\")\n",
    "''',\n",
    "    'config.json': '''\n",
    "{\n",
    "  \"model\": {\n",
    "    \"type\": \"neural_network\",\n",
    "    \"architecture\": \"resnet50\",\n",
    "    \"input_size\": [224, 224, 3],\n",
    "    \"num_classes\": 1000\n",
    "  },\n",
    "  \"training\": {\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"batch_size\": 32,\n",
    "    \"epochs\": 100,\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"loss_function\": \"categorical_crossentropy\"\n",
    "  },\n",
    "  \"data\": {\n",
    "    \"train_path\": \"/data/train\",\n",
    "    \"val_path\": \"/data/validation\",\n",
    "    \"test_path\": \"/data/test\",\n",
    "    \"augmentation\": true\n",
    "  }\n",
    "}\n",
    "''',\n",
    "    'results.csv': '''\n",
    "epoch,accuracy,precision,recall,loss,val_accuracy,val_loss\n",
    "1,0.234,0.245,0.223,2.345,0.245,2.234\n",
    "2,0.345,0.356,0.334,1.876,0.356,1.765\n",
    "3,0.456,0.467,0.445,1.543,0.467,1.432\n",
    "4,0.567,0.578,0.556,1.234,0.578,1.123\n",
    "5,0.678,0.689,0.667,0.987,0.689,0.876\n",
    "''',\n",
    "    'readme.md': '''\n",
    "# Machine Learning Project\n",
    "\n",
    "This project implements a deep learning model for image classification.\n",
    "\n",
    "## Features\n",
    "- ResNet-50 architecture\n",
    "- Data augmentation\n",
    "- Transfer learning\n",
    "- Performance monitoring\n",
    "\n",
    "## Usage\n",
    "```python\n",
    "python train.py --config config.json\n",
    "```\n",
    "\n",
    "## Results\n",
    "- Accuracy: 88.5%\n",
    "- Precision: 87.2%\n",
    "- Recall: 86.8%\n",
    "'''\n",
    "}\n",
    "\n",
    "# Create test files\n",
    "for filename, content in test_files_content.items():\n",
    "    filepath = search_test_dir / filename\n",
    "    filepath.write_text(content.strip())\n",
    "\n",
    "print(f\"Created {len(test_files_content)} test files:\")\n",
    "for filename in test_files_content.keys():\n",
    "    filepath = search_test_dir / filename\n",
    "    size = filepath.stat().st_size\n",
    "    print(f\"  {filename}: {scitex.str.readable_bytes(size)}\")\n",
    "\n",
    "# Test search functionality\n",
    "print(\"\\nSearch Tests:\")\n",
    "print(\"=\" * 15)\n",
    "\n",
    "search_queries = [\n",
    "    {\n",
    "        'query': 'accuracy',\n",
    "        'description': 'Find files containing \"accuracy\"'\n",
    "    },\n",
    "    {\n",
    "        'query': 'learning_rate',\n",
    "        'description': 'Find files containing \"learning_rate\"'\n",
    "    },\n",
    "    {\n",
    "        'query': 'ResNet',\n",
    "        'description': 'Find files containing \"ResNet\"'\n",
    "    },\n",
    "    {\n",
    "        'query': 'import.*pandas',\n",
    "        'description': 'Find files with pandas import (regex)'\n",
    "    },\n",
    "    {\n",
    "        'query': '0\\.[0-9]+',\n",
    "        'description': 'Find files with decimal numbers (regex)'\n",
    "    }\n",
    "]\n",
    "\n",
    "for search_test in search_queries:\n",
    "    try:\n",
    "        print(f\"\\n{search_test['description']}:\")\n",
    "        print(f\"Query: '{search_test['query']}'\")\n",
    "        \n",
    "        # Search using scitex.utils.search\n",
    "        search_results = scitex.utils.search(\n",
    "            pattern=search_test['query'],\n",
    "            directory=str(search_test_dir)\n",
    "        )\n",
    "        \n",
    "        if search_results:\n",
    "            print(f\"Found in {len(search_results)} locations:\")\n",
    "            for result in search_results:\n",
    "                print(f\"  {result}\")\n",
    "        else:\n",
    "            print(\"  No matches found\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  Search error: {e}\")\n",
    "\n",
    "# File content analysis\n",
    "print(\"\\nFile Content Analysis:\")\n",
    "print(\"=\" * 25)\n",
    "\n",
    "for filename, content in test_files_content.items():\n",
    "    print(f\"\\n{filename}:\")\n",
    "    \n",
    "    # Basic statistics\n",
    "    lines = content.split('\\n')\n",
    "    words = content.split()\n",
    "    chars = len(content)\n",
    "    \n",
    "    print(f\"  Lines: {len(lines)}\")\n",
    "    print(f\"  Words: {len(words)}\")\n",
    "    print(f\"  Characters: {chars}\")\n",
    "    \n",
    "    # Find numbers in content\n",
    "    import re\n",
    "    numbers = re.findall(r'\\b\\d+\\.\\d+\\b|\\b\\d+\\b', content)\n",
    "    if numbers:\n",
    "        print(f\"  Numbers found: {len(numbers)} ({numbers[:5]}{'...' if len(numbers) > 5 else ''})\")\n",
    "    \n",
    "    # Find common keywords\n",
    "    keywords = ['accuracy', 'model', 'data', 'training', 'learning', 'neural', 'network']\n",
    "    found_keywords = [kw for kw in keywords if kw.lower() in content.lower()]\n",
    "    if found_keywords:\n",
    "        print(f\"  Keywords: {found_keywords}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab27836c",
   "metadata": {
    "papermill": {
     "duration": 0.006872,
     "end_time": "2025-07-04T01:53:33.425749",
     "exception": false,
     "start_time": "2025-07-04T01:53:33.418877",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Part 5: Email and Communication\n",
    "\n",
    "### 5.1 Email Utilities (Demonstration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df432632",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T01:53:33.441940Z",
     "iopub.status.busy": "2025-07-04T01:53:33.440940Z",
     "iopub.status.idle": "2025-07-04T01:53:33.460780Z",
     "shell.execute_reply": "2025-07-04T01:53:33.459047Z"
    },
    "papermill": {
     "duration": 0.030792,
     "end_time": "2025-07-04T01:53:33.463301",
     "exception": false,
     "start_time": "2025-07-04T01:53:33.432509",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email Utilities Demonstration:\n",
      "=================================\n",
      "Note: This is a demonstration only - no actual emails will be sent.\n",
      "\n",
      "Email Type: Experiment Completion\n",
      "Priority: NORMAL\n",
      "Subject: Experiment Completed Successfully\n",
      "Body length: 382 characters\n",
      "Body lines: 48 words\n",
      "Preview: Dear Researcher,  Your machine learning experiment has completed successfully....\n",
      "\n",
      "Email Type: Error Notification\n",
      "Priority: HIGH\n",
      "Subject: URGENT: Training Failed - Action Required\n",
      "Body length: 487 characters\n",
      "Body lines: 70 words\n",
      "Preview: ATTENTION: Your machine learning experiment has failed.  Error Details:...\n",
      "\n",
      "Email Type: Weekly Summary\n",
      "Priority: LOW\n",
      "Subject: Weekly Training Summary\n",
      "Body length: 520 characters\n",
      "Body lines: 73 words\n",
      "Preview: Weekly Training Summary (Week of Jan 15-21, 2024)  Experiments Completed: 12...\n",
      "\n",
      "Email Sending Workflow Demo:\n",
      "==============================\n",
      "\n",
      "Scenario: experiment_completed\n",
      "Triggered email type: experiment_completion\n",
      "[MOCK EMAIL SEND]\n",
      "  To: researcher@university.edu\n",
      "  Subject: Experiment Completed Successfully\n",
      "  Priority: normal\n",
      "  Body size: 382 chars\n",
      "  Status: Would be sent successfully\n",
      "Email sent successfully: True\n",
      "\n",
      "Scenario: training_failed\n",
      "Triggered email type: error_notification\n",
      "[MOCK EMAIL SEND]\n",
      "  To: admin@lab.org\n",
      "  Subject: URGENT: Training Failed - Action Required\n",
      "  Priority: high\n",
      "  Body size: 487 chars\n",
      "  Status: Would be sent successfully\n",
      "Email sent successfully: True\n",
      "\n",
      "Scenario: weekly_report\n",
      "Triggered email type: weekly_summary\n",
      "[MOCK EMAIL SEND]\n",
      "  To: team@company.com\n",
      "  Subject: Weekly Training Summary\n",
      "  Priority: low\n",
      "  Body size: 520 chars\n",
      "  Status: Would be sent successfully\n",
      "Email sent successfully: True\n",
      "\n",
      "Note: To use actual email sending, configure scitex.utils.send_gmail() with:\n",
      "- Gmail credentials\n",
      "- App password or OAuth\n",
      "- Recipient addresses\n",
      "- SMTP server settings\n"
     ]
    }
   ],
   "source": [
    "# Email utilities demonstration (without actually sending emails)\n",
    "print(\"Email Utilities Demonstration:\")\n",
    "print(\"=\" * 33)\n",
    "\n",
    "# Note: We won't actually send emails in this demo\n",
    "print(\"Note: This is a demonstration only - no actual emails will be sent.\\n\")\n",
    "\n",
    "# Email configuration examples\n",
    "email_configs = {\n",
    "    'experiment_completion': {\n",
    "        'subject': 'Experiment Completed Successfully',\n",
    "        'body': '''\n",
    "Dear Researcher,\n",
    "\n",
    "Your machine learning experiment has completed successfully.\n",
    "\n",
    "Results Summary:\n",
    "- Training Accuracy: 94.5%\n",
    "- Validation Accuracy: 89.2%\n",
    "- Training Time: 2.5 hours\n",
    "- Model Size: 45.2 MB\n",
    "\n",
    "The trained model has been saved to:\n",
    "/models/experiment_20240115_142330.pkl\n",
    "\n",
    "Detailed logs are available in:\n",
    "/logs/training_20240115.log\n",
    "\n",
    "Best regards,\n",
    "Automated Training System\n",
    "''',\n",
    "        'priority': 'normal'\n",
    "    },\n",
    "    'error_notification': {\n",
    "        'subject': 'URGENT: Training Failed - Action Required',\n",
    "        'body': '''\n",
    "ATTENTION: Your machine learning experiment has failed.\n",
    "\n",
    "Error Details:\n",
    "- Error Type: OutOfMemoryError\n",
    "- Error Message: CUDA out of memory\n",
    "- Batch Size: 128 (consider reducing)\n",
    "- Model: ResNet-50\n",
    "- Epoch: 15/100\n",
    "\n",
    "Suggested Actions:\n",
    "1. Reduce batch size to 64 or 32\n",
    "2. Use gradient accumulation\n",
    "3. Enable mixed precision training\n",
    "4. Use a smaller model variant\n",
    "\n",
    "Error log: /logs/error_20240115_143045.log\n",
    "\n",
    "Please restart the training with adjusted parameters.\n",
    "\n",
    "Automated Training System\n",
    "''',\n",
    "        'priority': 'high'\n",
    "    },\n",
    "    'weekly_summary': {\n",
    "        'subject': 'Weekly Training Summary',\n",
    "        'body': '''\n",
    "Weekly Training Summary (Week of Jan 15-21, 2024)\n",
    "\n",
    "Experiments Completed: 12\n",
    "Success Rate: 91.7% (11/12)\n",
    "Total Training Time: 18.5 hours\n",
    "Best Model Accuracy: 96.2%\n",
    "\n",
    "Top Performing Models:\n",
    "1. ResNet-101: 96.2% accuracy\n",
    "2. EfficientNet-B4: 95.8% accuracy\n",
    "3. DenseNet-121: 94.9% accuracy\n",
    "\n",
    "Resource Usage:\n",
    "- GPU Hours: 18.5\n",
    "- Storage Used: 2.3 GB\n",
    "- Models Saved: 11\n",
    "\n",
    "Upcoming Experiments:\n",
    "- Vision Transformer evaluation\n",
    "- Hyperparameter optimization\n",
    "- Cross-validation study\n",
    "\n",
    "Have a great week!\n",
    "Training Management System\n",
    "''',\n",
    "        'priority': 'low'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Demonstrate email preparation\n",
    "for email_type, config in email_configs.items():\n",
    "    print(f\"Email Type: {email_type.replace('_', ' ').title()}\")\n",
    "    print(f\"Priority: {config['priority'].upper()}\")\n",
    "    print(f\"Subject: {config['subject']}\")\n",
    "    print(f\"Body length: {len(config['body'])} characters\")\n",
    "    print(f\"Body lines: {len(config['body'].split())} words\")\n",
    "    \n",
    "    # Show email preview (first few lines)\n",
    "    body_lines = config['body'].strip().split('\\n')\n",
    "    preview_lines = body_lines[:3]\n",
    "    print(f\"Preview: {' '.join(preview_lines)}...\")\n",
    "    print()\n",
    "\n",
    "# Email sending function demonstration (mock)\n",
    "def mock_send_email(subject, body, recipient, priority='normal'):\n",
    "    \"\"\"Mock email sending function for demonstration.\"\"\"\n",
    "    print(f\"[MOCK EMAIL SEND]\")\n",
    "    print(f\"  To: {recipient}\")\n",
    "    print(f\"  Subject: {subject}\")\n",
    "    print(f\"  Priority: {priority}\")\n",
    "    print(f\"  Body size: {len(body)} chars\")\n",
    "    print(f\"  Status: Would be sent successfully\")\n",
    "    return True\n",
    "\n",
    "# Demonstrate email sending workflow\n",
    "print(\"Email Sending Workflow Demo:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "recipients = [\n",
    "    'researcher@university.edu',\n",
    "    'admin@lab.org',\n",
    "    'team@company.com'\n",
    "]\n",
    "\n",
    "# Simulate sending different types of notifications\n",
    "notification_scenarios = [\n",
    "    {\n",
    "        'trigger': 'experiment_completed',\n",
    "        'email_type': 'experiment_completion',\n",
    "        'recipient': 'researcher@university.edu'\n",
    "    },\n",
    "    {\n",
    "        'trigger': 'training_failed',\n",
    "        'email_type': 'error_notification',\n",
    "        'recipient': 'admin@lab.org'\n",
    "    },\n",
    "    {\n",
    "        'trigger': 'weekly_report',\n",
    "        'email_type': 'weekly_summary',\n",
    "        'recipient': 'team@company.com'\n",
    "    }\n",
    "]\n",
    "\n",
    "for scenario in notification_scenarios:\n",
    "    email_config = email_configs[scenario['email_type']]\n",
    "    \n",
    "    print(f\"\\nScenario: {scenario['trigger']}\")\n",
    "    print(f\"Triggered email type: {scenario['email_type']}\")\n",
    "    \n",
    "    # Simulate email sending\n",
    "    try:\n",
    "        # In a real implementation, you would use scitex.utils.send_gmail here\n",
    "        result = mock_send_email(\n",
    "            subject=email_config['subject'],\n",
    "            body=email_config['body'],\n",
    "            recipient=scenario['recipient'],\n",
    "            priority=email_config['priority']\n",
    "        )\n",
    "        print(f\"Email sent successfully: {result}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Email sending failed: {e}\")\n",
    "\n",
    "print(\"\\nNote: To use actual email sending, configure scitex.utils.send_gmail() with:\")\n",
    "print(\"- Gmail credentials\")\n",
    "print(\"- App password or OAuth\")\n",
    "print(\"- Recipient addresses\")\n",
    "print(\"- SMTP server settings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8766a870",
   "metadata": {
    "papermill": {
     "duration": 0.007846,
     "end_time": "2025-07-04T01:53:33.479419",
     "exception": false,
     "start_time": "2025-07-04T01:53:33.471573",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Part 6: Practical Applications\n",
    "\n",
    "### 6.1 Experiment Management System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b493bc",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cb72314",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T01:53:33.501889Z",
     "iopub.status.busy": "2025-07-04T01:53:33.499452Z",
     "iopub.status.idle": "2025-07-04T01:53:35.923585Z",
     "shell.execute_reply": "2025-07-04T01:53:35.921785Z"
    },
    "papermill": {
     "duration": 2.437538,
     "end_time": "2025-07-04T01:53:35.925360",
     "exception": true,
     "start_time": "2025-07-04T01:53:33.487822",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting parameter sweep: neural_network_optimization\n",
      "Total parameter combinations: 18\n",
      "Created experiment: neural_network_optimization_run_001_20250704_115333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created experiment: neural_network_optimization_run_002_20250704_115333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created experiment: neural_network_optimization_run_003_20250704_115333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created experiment: neural_network_optimization_run_004_20250704_115333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created experiment: neural_network_optimization_run_005_20250704_115333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created experiment: neural_network_optimization_run_006_20250704_115334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created experiment: neural_network_optimization_run_007_20250704_115334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created experiment: neural_network_optimization_run_008_20250704_115334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created experiment: neural_network_optimization_run_009_20250704_115334\n",
      "Created experiment: neural_network_optimization_run_010_20250704_115334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created experiment: neural_network_optimization_run_011_20250704_115334\n",
      "Created experiment: neural_network_optimization_run_012_20250704_115334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created experiment: neural_network_optimization_run_013_20250704_115334\n",
      "Created experiment: neural_network_optimization_run_014_20250704_115334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created experiment: neural_network_optimization_run_015_20250704_115335\n",
      "Created experiment: neural_network_optimization_run_016_20250704_115335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created experiment: neural_network_optimization_run_017_20250704_115335\n",
      "Created experiment: neural_network_optimization_run_018_20250704_115335\n",
      "\n",
      "Parameter sweep completed: 18 experiments\n",
      "\n",
      "Experiment Results Analysis:\n",
      "==============================\n",
      "Total experiments: 18\n",
      "Completed: 18\n",
      "Failed: 0\n",
      "Success rate: 100.0%\n",
      "\n",
      "Performance Statistics:\n",
      "  Accuracy - Mean: 0.7361, Std: 0.0728\n",
      "  Best accuracy: 0.9253\n",
      "  Worst accuracy: 0.6501\n",
      "  Training time - Mean: 76.4s\n",
      "  Memory usage - Mean: 1241.7MB\n",
      "\n",
      "Best Experiment: neural_network_optimization_run_009_20250704_115334\n",
      "  Parameters: {'learning_rate': 0.01, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "  Accuracy: 0.9253\n",
      "\n",
      "Storage Usage:\n",
      "  Logs: 30.5 KiB\n",
      "  Results: 14.0 KiB\n",
      "  Configs: 37.3 KiB\n",
      "  Total: 81.7 KiB\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "get_git_branch() missing 1 required positional argument: 'scitex'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 245\u001b[39m\n\u001b[32m    242\u001b[39m experiment_manager.analyze_results()\n\u001b[32m    244\u001b[39m \u001b[38;5;66;03m# Generate summary report\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m245\u001b[39m report_file = \u001b[43mexperiment_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_summary_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[38;5;66;03m# Show report content\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(report_file, \u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 193\u001b[39m, in \u001b[36mExperimentManager.generate_summary_report\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    191\u001b[39m f.write(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mHostname: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscitex.utils.get_hostname()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    192\u001b[39m f.write(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUsername: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscitex.utils.get_username()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m f.write(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGit branch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mscitex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mutils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_git_branch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    194\u001b[39m f.write(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGenerated: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime.strftime(\u001b[33m'\u001b[39m\u001b[33m%\u001b[39m\u001b[33mY-\u001b[39m\u001b[33m%\u001b[39m\u001b[33mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m%\u001b[39m\u001b[33mH:\u001b[39m\u001b[33m%\u001b[39m\u001b[33mM:\u001b[39m\u001b[33m%\u001b[39m\u001b[33mS\u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    196\u001b[39m \u001b[38;5;66;03m# Experiment statistics\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: get_git_branch() missing 1 required positional argument: 'scitex'"
     ]
    }
   ],
   "source": [
    "# Comprehensive experiment management system\n",
    "class ExperimentManager:\n",
    "    def __init__(self, base_dir):\n",
    "        self.base_dir = Path(base_dir)\n",
    "        self.base_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Create subdirectories\n",
    "        self.experiments_dir = self.base_dir / \"experiments\"\n",
    "        self.logs_dir = self.base_dir / \"logs\"\n",
    "        self.results_dir = self.base_dir / \"results\"\n",
    "        \n",
    "        for dir_path in [self.experiments_dir, self.logs_dir, self.results_dir]:\n",
    "            dir_path.mkdir(exist_ok=True)\n",
    "        \n",
    "        self.experiment_history = []\n",
    "    \n",
    "    def create_experiment(self, name, parameters):\n",
    "        \"\"\"Create a new experiment configuration.\"\"\"\n",
    "        import datetime\n",
    "        \n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        experiment_id = f\"{name}_{timestamp}\"\n",
    "        \n",
    "        experiment = {\n",
    "            'id': experiment_id,\n",
    "            'name': name,\n",
    "            'parameters': parameters,\n",
    "            'created': timestamp,\n",
    "            'status': 'created',\n",
    "            'results': None,\n",
    "            'log_file': self.logs_dir / f\"{experiment_id}.log\",\n",
    "            'results_file': self.results_dir / f\"{experiment_id}_results.json\"\n",
    "        }\n",
    "        \n",
    "        # Save experiment configuration\n",
    "        config_file = self.experiments_dir / f\"{experiment_id}_config.json\"\n",
    "        import json\n",
    "        with open(config_file, 'w') as f:\n",
    "            json.dump(experiment, f, indent=2, default=str)\n",
    "        \n",
    "        self.experiment_history.append(experiment)\n",
    "        \n",
    "        print(f\"Created experiment: {experiment_id}\")\n",
    "        return experiment\n",
    "    \n",
    "    def run_parameter_sweep(self, base_name, parameter_space):\n",
    "        \"\"\"Run experiments for all parameter combinations.\"\"\"\n",
    "        print(f\"Starting parameter sweep: {base_name}\")\n",
    "        \n",
    "        # Count total combinations\n",
    "        total_combinations = scitex.utils.count_grids(parameter_space)\n",
    "        print(f\"Total parameter combinations: {total_combinations}\")\n",
    "        \n",
    "        # Generate experiments\n",
    "        experiments = []\n",
    "        for i, params in enumerate(scitex.utils.yield_grids(parameter_space), 1):\n",
    "            experiment_name = f\"{base_name}_run_{i:03d}\"\n",
    "            experiment = self.create_experiment(experiment_name, params)\n",
    "            experiments.append(experiment)\n",
    "            \n",
    "            # Simulate running the experiment\n",
    "            self.simulate_experiment_run(experiment)\n",
    "        \n",
    "        print(f\"\\nParameter sweep completed: {len(experiments)} experiments\")\n",
    "        return experiments\n",
    "    \n",
    "    def simulate_experiment_run(self, experiment):\n",
    "        \"\"\"Simulate running an experiment.\"\"\"\n",
    "        import random\n",
    "        import time\n",
    "        \n",
    "        # Simulate some processing time\n",
    "        time.sleep(0.1)\n",
    "        \n",
    "        # Update status\n",
    "        experiment['status'] = 'running'\n",
    "        \n",
    "        # Write to log file\n",
    "        with open(experiment['log_file'], 'w') as f:\n",
    "            f.write(f\"Experiment: {experiment['id']}\\n\")\n",
    "            f.write(f\"Parameters: {experiment['parameters']}\\n\")\n",
    "            f.write(f\"Status: {experiment['status']}\\n\")\n",
    "            f.write(f\"Started: {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        \n",
    "        # Simulate results based on parameters\n",
    "        base_performance = 0.7\n",
    "        \n",
    "        # Add parameter-based adjustments\n",
    "        params = experiment['parameters']\n",
    "        if 'learning_rate' in params:\n",
    "            if params['learning_rate'] == 0.01:\n",
    "                base_performance += 0.1\n",
    "            elif params['learning_rate'] == 0.1:\n",
    "                base_performance -= 0.05\n",
    "        \n",
    "        if 'batch_size' in params:\n",
    "            if params['batch_size'] == 64:\n",
    "                base_performance += 0.05\n",
    "        \n",
    "        # Add random variation\n",
    "        performance = base_performance + random.uniform(-0.1, 0.1)\n",
    "        performance = max(0.0, min(1.0, performance))\n",
    "        \n",
    "        # Create results\n",
    "        results = {\n",
    "            'accuracy': performance,\n",
    "            'precision': performance * random.uniform(0.9, 1.1),\n",
    "            'recall': performance * random.uniform(0.9, 1.1),\n",
    "            'training_time': random.uniform(30, 120),  # seconds\n",
    "            'memory_usage': random.uniform(500, 2000),  # MB\n",
    "            'converged': performance > 0.6\n",
    "        }\n",
    "        \n",
    "        # Clamp precision and recall\n",
    "        results['precision'] = max(0.0, min(1.0, results['precision']))\n",
    "        results['recall'] = max(0.0, min(1.0, results['recall']))\n",
    "        \n",
    "        experiment['results'] = results\n",
    "        experiment['status'] = 'completed' if results['converged'] else 'failed'\n",
    "        \n",
    "        # Save results\n",
    "        import json\n",
    "        with open(experiment['results_file'], 'w') as f:\n",
    "            json.dump(results, f, indent=2)\n",
    "        \n",
    "        # Update log\n",
    "        with open(experiment['log_file'], 'a') as f:\n",
    "            f.write(f\"Completed: {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "            f.write(f\"Results: {results}\\n\")\n",
    "            f.write(f\"Final status: {experiment['status']}\\n\")\n",
    "    \n",
    "    def analyze_results(self):\n",
    "        \"\"\"Analyze results across all experiments.\"\"\"\n",
    "        print(\"\\nExperiment Results Analysis:\")\n",
    "        print(\"=\" * 30)\n",
    "        \n",
    "        if not self.experiment_history:\n",
    "            print(\"No experiments to analyze\")\n",
    "            return\n",
    "        \n",
    "        # Filter completed experiments\n",
    "        completed = [e for e in self.experiment_history if e['status'] == 'completed']\n",
    "        failed = [e for e in self.experiment_history if e['status'] == 'failed']\n",
    "        \n",
    "        print(f\"Total experiments: {len(self.experiment_history)}\")\n",
    "        print(f\"Completed: {len(completed)}\")\n",
    "        print(f\"Failed: {len(failed)}\")\n",
    "        print(f\"Success rate: {len(completed)/len(self.experiment_history)*100:.1f}%\")\n",
    "        \n",
    "        if completed:\n",
    "            # Performance statistics\n",
    "            accuracies = [e['results']['accuracy'] for e in completed]\n",
    "            training_times = [e['results']['training_time'] for e in completed]\n",
    "            memory_usage = [e['results']['memory_usage'] for e in completed]\n",
    "            \n",
    "            print(f\"\\nPerformance Statistics:\")\n",
    "            print(f\"  Accuracy - Mean: {np.mean(accuracies):.4f}, Std: {np.std(accuracies):.4f}\")\n",
    "            print(f\"  Best accuracy: {np.max(accuracies):.4f}\")\n",
    "            print(f\"  Worst accuracy: {np.min(accuracies):.4f}\")\n",
    "            print(f\"  Training time - Mean: {np.mean(training_times):.1f}s\")\n",
    "            print(f\"  Memory usage - Mean: {np.mean(memory_usage):.1f}MB\")\n",
    "            \n",
    "            # Find best experiment\n",
    "            best_experiment = max(completed, key=lambda x: x['results']['accuracy'])\n",
    "            print(f\"\\nBest Experiment: {best_experiment['id']}\")\n",
    "            print(f\"  Parameters: {best_experiment['parameters']}\")\n",
    "            print(f\"  Accuracy: {best_experiment['results']['accuracy']:.4f}\")\n",
    "            \n",
    "        # Storage analysis\n",
    "        total_log_size = sum(f.stat().st_size for f in self.logs_dir.rglob('*.log'))\n",
    "        total_results_size = sum(f.stat().st_size for f in self.results_dir.rglob('*.json'))\n",
    "        total_config_size = sum(f.stat().st_size for f in self.experiments_dir.rglob('*.json'))\n",
    "        \n",
    "        print(f\"\\nStorage Usage:\")\n",
    "        print(f\"  Logs: {scitex.str.readable_bytes(total_log_size)}\")\n",
    "        print(f\"  Results: {scitex.str.readable_bytes(total_results_size)}\")\n",
    "        print(f\"  Configs: {scitex.str.readable_bytes(total_config_size)}\")\n",
    "        print(f\"  Total: {scitex.str.readable_bytes(total_log_size + total_results_size + total_config_size)}\")\n",
    "    \n",
    "    def generate_summary_report(self):\n",
    "        \"\"\"Generate a comprehensive summary report.\"\"\"\n",
    "        report_file = self.base_dir / \"experiment_summary.txt\"\n",
    "        \n",
    "        with open(report_file, 'w') as f:\n",
    "            f.write(\"EXPERIMENT SUMMARY REPORT\\n\")\n",
    "            f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "            \n",
    "            # System information\n",
    "            f.write(\"System Information:\\n\")\n",
    "            f.write(\"-\" * 20 + \"\\n\")\n",
    "            f.write(f\"Hostname: {scitex.utils.get_hostname()}\\n\")\n",
    "            f.write(f\"Username: {scitex.utils.get_username()}\\n\")\n",
    "            f.write(f\"Git branch: {scitex.utils.get_git_branch()}\\n\")\n",
    "            f.write(f\"Generated: {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "            \n",
    "            # Experiment statistics\n",
    "            completed = [e for e in self.experiment_history if e['status'] == 'completed']\n",
    "            \n",
    "            f.write(\"Experiment Statistics:\\n\")\n",
    "            f.write(\"-\" * 22 + \"\\n\")\n",
    "            f.write(f\"Total experiments: {len(self.experiment_history)}\\n\")\n",
    "            f.write(f\"Completed: {len(completed)}\\n\")\n",
    "            f.write(f\"Success rate: {len(completed)/len(self.experiment_history)*100:.1f}%\\n\\n\")\n",
    "            \n",
    "            if completed:\n",
    "                accuracies = [e['results']['accuracy'] for e in completed]\n",
    "                f.write(f\"Best accuracy: {np.max(accuracies):.4f}\\n\")\n",
    "                f.write(f\"Mean accuracy: {np.mean(accuracies):.4f}\\n\")\n",
    "                f.write(f\"Std accuracy: {np.std(accuracies):.4f}\\n\\n\")\n",
    "                \n",
    "                # Top experiments\n",
    "                top_experiments = sorted(completed, key=lambda x: x['results']['accuracy'], reverse=True)[:3]\n",
    "                f.write(\"Top 3 Experiments:\\n\")\n",
    "                f.write(\"-\" * 18 + \"\\n\")\n",
    "                for i, exp in enumerate(top_experiments, 1):\n",
    "                    f.write(f\"{i}. {exp['id']} - Accuracy: {exp['results']['accuracy']:.4f}\\n\")\n",
    "                    f.write(f\"   Parameters: {exp['parameters']}\\n\")\n",
    "            \n",
    "            # Footer\n",
    "            f.write(\"\\n\" + scitex.utils.gen_footer())\n",
    "        \n",
    "        print(f\"\\nSummary report saved to: {report_file}\")\n",
    "        return report_file\n",
    "\n",
    "# Test the experiment management system\n",
    "experiment_manager = ExperimentManager(data_dir / \"experiment_management\")\n",
    "\n",
    "# Define parameter space for hyperparameter optimization\n",
    "hyperparameter_space = {\n",
    "    'learning_rate': [0.001, 0.01, 0.1],\n",
    "    'batch_size': [32, 64, 128],\n",
    "    'optimizer': ['adam', 'sgd']\n",
    "}\n",
    "\n",
    "# Run parameter sweep\n",
    "experiments = experiment_manager.run_parameter_sweep(\n",
    "    \"neural_network_optimization\",\n",
    "    hyperparameter_space\n",
    ")\n",
    "\n",
    "# Analyze results\n",
    "experiment_manager.analyze_results()\n",
    "\n",
    "# Generate summary report\n",
    "report_file = experiment_manager.generate_summary_report()\n",
    "\n",
    "# Show report content\n",
    "with open(report_file, 'r') as f:\n",
    "    report_content = f.read()\n",
    "    print(f\"\\nReport content preview:\")\n",
    "    print(\"=\" * 30)\n",
    "    print(report_content[:500] + \"...\" if len(report_content) > 500 else report_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd2c1c6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Summary and Best Practices\n",
    "\n",
    "This tutorial demonstrated the comprehensive utility capabilities of the SciTeX utils module:\n",
    "\n",
    "### Key Features Covered:\n",
    "1. **System Information**: `get_hostname()`, `get_username()`, `get_git_branch()`, `gen_footer()`\n",
    "2. **Grid Operations**: `count_grids()`, `yield_grids()` for parameter space exploration\n",
    "3. **Data Compression**: `compress_hdf5()` for storage optimization\n",
    "4. **Communication**: `send_gmail()`, `notify()`, `ansi_escape()` for notifications\n",
    "5. **Search Utilities**: `search()` for advanced content analysis\n",
    "6. **Experiment Management**: Comprehensive parameter sweep and result analysis\n",
    "7. **File Management**: Automated logging and result storage\n",
    "8. **Report Generation**: Summary reports with system information\n",
    "\n",
    "### Best Practices:\n",
    "- Use **grid operations** for systematic parameter space exploration\n",
    "- Apply **HDF5 compression** for large dataset storage\n",
    "- Implement **notification systems** for long-running experiments\n",
    "- Use **search utilities** for comprehensive data analysis\n",
    "- Create **experiment management** systems for reproducible research\n",
    "- Generate **automated reports** with system information\n",
    "- Use **system information** functions for environment tracking\n",
    "- Implement **proper logging** for experiment tracking\n",
    "\n",
    "### Recommended Workflows:\n",
    "1. **Hyperparameter Optimization**: Use grid operations with experiment management\n",
    "2. **Data Storage**: Apply compression utilities for large datasets\n",
    "3. **Result Analysis**: Use search utilities for pattern detection\n",
    "4. **Communication**: Set up notification systems for experiment completion\n",
    "5. **Documentation**: Generate automated reports with system context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7605e28d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "import shutil\n",
    "\n",
    "cleanup = input(\"Clean up example files? (y/n): \").lower().startswith('y')\n",
    "if cleanup:\n",
    "    shutil.rmtree(data_dir)\n",
    "    print(\"✓ Example files cleaned up\")\n",
    "else:\n",
    "    print(f\"Example files preserved in: {data_dir}\")\n",
    "    print(f\"Directories created: {len([d for d in data_dir.rglob('*') if d.is_dir()])}\")\n",
    "    print(f\"Files created: {len([f for f in data_dir.rglob('*') if f.is_file()])}\")\n",
    "    total_size = sum(f.stat().st_size for f in data_dir.rglob('*') if f.is_file())\n",
    "    print(f\"Total size: {scitex.str.readable_bytes(total_size)}\")\n",
    "    \n",
    "    # Show structure\n",
    "    print(f\"\\nCreated structure:\")\n",
    "    for item in sorted(data_dir.rglob('*')):\n",
    "        if item.is_dir():\n",
    "            print(f\"  📁 {item.relative_to(data_dir)}/\")\n",
    "        else:\n",
    "            size = scitex.str.readable_bytes(item.stat().st_size)\n",
    "            print(f\"  📄 {item.relative_to(data_dir)} ({size})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 12.588926,
   "end_time": "2025-07-04T01:53:38.657411",
   "environment_variables": {},
   "exception": true,
   "input_path": "./examples/03_scitex_utils.ipynb",
   "output_path": "./examples/03_scitex_utils_test_output.ipynb",
   "parameters": {},
   "start_time": "2025-07-04T01:53:26.068485",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}