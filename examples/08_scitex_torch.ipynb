{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SciTeX Torch Utilities Tutorial\n",
    "\n",
    "This notebook demonstrates the PyTorch utilities in SciTeX, focusing on NaN-safe operations and tensor manipulation functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scitex as stx\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Understanding NaN-Safe Operations\n",
    "\n",
    "In scientific computing, dealing with missing or invalid data (NaN values) is common. Standard PyTorch operations propagate NaN values, which can break computations. SciTeX provides NaN-safe alternatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 The Problem with Standard Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensor with NaN values\n",
    "data = torch.tensor([1.0, 2.0, float('nan'), 4.0, 5.0, float('nan'), 7.0])\n",
    "print(f\"Data with NaNs: {data}\")\n",
    "print(f\"NaN locations: {torch.isnan(data)}\")\n",
    "\n",
    "# Standard operations fail with NaN\n",
    "print(\"\\nStandard PyTorch operations:\")\n",
    "print(f\"torch.max(data): {torch.max(data)}\")  # Returns NaN\n",
    "print(f\"torch.mean(data): {torch.mean(data)}\")  # Returns NaN\n",
    "print(f\"torch.std(data): {torch.std(data)}\")  # Returns NaN\n",
    "print(f\"torch.sum(data): {torch.sum(data)}\")  # Returns NaN\n",
    "\n",
    "# SciTeX NaN-safe operations\n",
    "print(\"\\nSciTeX NaN-safe operations:\")\n",
    "print(f\"stx.torch.nanmax(data): {stx.torch.nanmax(data)}\")  # Ignores NaN\n",
    "print(f\"torch.nanmean(data): {torch.nanmean(data)}\")  # PyTorch's built-in\n",
    "print(f\"stx.torch.nanstd(data): {stx.torch.nanstd(data)}\")  # Ignores NaN\n",
    "print(f\"torch.nansum(data): {torch.nansum(data)}\")  # PyTorch's built-in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 NaN-Safe Min/Max Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 2D tensor with NaN values\n",
    "data_2d = torch.randn(5, 4)\n",
    "# Insert some NaN values\n",
    "data_2d[1, 2] = float('nan')\n",
    "data_2d[3, 0] = float('nan')\n",
    "data_2d[4, 3] = float('nan')\n",
    "\n",
    "print(\"2D data with NaNs:\")\n",
    "print(data_2d)\n",
    "\n",
    "# Compare standard vs NaN-safe operations\n",
    "print(\"\\nMax along rows (dim=1):\")\n",
    "print(f\"Standard max: {torch.max(data_2d, dim=1)[0]}\")\n",
    "print(f\"NaN-safe max: {stx.torch.nanmax(data_2d, dim=1)[0]}\")\n",
    "\n",
    "print(\"\\nMin along columns (dim=0):\")\n",
    "print(f\"Standard min: {torch.min(data_2d, dim=0)[0]}\")\n",
    "print(f\"NaN-safe min: {stx.torch.nanmin(data_2d, dim=0)[0]}\")\n",
    "\n",
    "# Finding indices with argmax/argmin\n",
    "print(\"\\nArgmax along rows (dim=1):\")\n",
    "print(f\"NaN-safe argmax: {stx.torch.nanargmax(data_2d, dim=1)}\")\n",
    "print(f\"NaN-safe argmin: {stx.torch.nanargmin(data_2d, dim=1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 NaN-Safe Statistical Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate time series data with missing values\n",
    "time_series = torch.randn(100, 3)  # 100 time points, 3 channels\n",
    "\n",
    "# Simulate missing data (10% NaN)\n",
    "mask = torch.rand_like(time_series) < 0.1\n",
    "time_series[mask] = float('nan')\n",
    "\n",
    "print(f\"Time series shape: {time_series.shape}\")\n",
    "print(f\"NaN count: {torch.isnan(time_series).sum().item()} / {time_series.numel()}\")\n",
    "\n",
    "# Compute statistics per channel\n",
    "print(\"\\nPer-channel statistics (ignoring NaNs):\")\n",
    "print(f\"Mean: {torch.nanmean(time_series, dim=0)}\")\n",
    "print(f\"Std:  {stx.torch.nanstd(time_series, dim=0)}\")\n",
    "print(f\"Var:  {stx.torch.nanvar(time_series, dim=0)}\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(3, 1, figsize=(10, 8), sharex=True)\n",
    "t = torch.arange(len(time_series))\n",
    "\n",
    "for i in range(3):\n",
    "    channel_data = time_series[:, i]\n",
    "    valid_mask = ~torch.isnan(channel_data)\n",
    "    \n",
    "    # Plot valid data points\n",
    "    axes[i].plot(t[valid_mask], channel_data[valid_mask], 'b-', alpha=0.7)\n",
    "    \n",
    "    # Mark NaN locations\n",
    "    nan_mask = torch.isnan(channel_data)\n",
    "    if nan_mask.any():\n",
    "        axes[i].scatter(t[nan_mask], torch.zeros(nan_mask.sum()), \n",
    "                       color='red', marker='x', s=50, label='NaN')\n",
    "    \n",
    "    # Add statistics\n",
    "    mean = torch.nanmean(channel_data)\n",
    "    std = stx.torch.nanstd(channel_data)\n",
    "    axes[i].axhline(mean, color='green', linestyle='--', alpha=0.5, label=f'Mean: {mean:.2f}')\n",
    "    axes[i].fill_between(t, mean-std, mean+std, alpha=0.2, color='green')\n",
    "    \n",
    "    axes[i].set_ylabel(f'Channel {i+1}')\n",
    "    axes[i].legend()\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "axes[-1].set_xlabel('Time')\n",
    "plt.suptitle('Time Series with Missing Data (NaN-safe statistics)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 NaN-Safe Cumulative Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate cumulative operations with NaN\n",
    "data = torch.tensor([1.0, 2.0, float('nan'), 3.0, float('nan'), 4.0, 5.0])\n",
    "\n",
    "print(\"Original data:\")\n",
    "print(data)\n",
    "\n",
    "# Cumulative sum\n",
    "print(\"\\nCumulative sum:\")\n",
    "print(f\"Standard cumsum: {torch.cumsum(data, dim=0)}\")\n",
    "print(f\"NaN-safe cumsum: {stx.torch.nancumsum(data, dim=0)}\")\n",
    "\n",
    "# Cumulative product\n",
    "print(\"\\nCumulative product:\")\n",
    "print(f\"Standard cumprod: {torch.cumprod(data, dim=0)}\")\n",
    "print(f\"NaN-safe cumprod: {stx.torch.nancumprod(data, dim=0)}\")\n",
    "\n",
    "# Visualize cumulative operations\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "x = torch.arange(len(data))\n",
    "\n",
    "# Cumulative sum plot\n",
    "ax1.plot(x, stx.torch.nancumsum(data, dim=0), 'b-', linewidth=2, label='NaN-safe cumsum')\n",
    "ax1.scatter(x[torch.isnan(data)], stx.torch.nancumsum(data, dim=0)[torch.isnan(data)], \n",
    "           color='red', s=100, zorder=5, label='NaN positions')\n",
    "ax1.set_xlabel('Index')\n",
    "ax1.set_ylabel('Cumulative Sum')\n",
    "ax1.set_title('NaN-Safe Cumulative Sum')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Cumulative product plot\n",
    "ax2.plot(x, stx.torch.nancumprod(data, dim=0), 'g-', linewidth=2, label='NaN-safe cumprod')\n",
    "ax2.scatter(x[torch.isnan(data)], stx.torch.nancumprod(data, dim=0)[torch.isnan(data)], \n",
    "           color='red', s=100, zorder=5, label='NaN positions')\n",
    "ax2.set_xlabel('Index')\n",
    "ax2.set_ylabel('Cumulative Product')\n",
    "ax2.set_title('NaN-Safe Cumulative Product')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The apply_to Function\n",
    "\n",
    "The `apply_to` function is a powerful utility for applying any function along a specific dimension of a tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Basic Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 3D tensor\n",
    "data = torch.randn(2, 3, 4)\n",
    "print(f\"Data shape: {data.shape}\")\n",
    "print(f\"Data:\\n{data}\")\n",
    "\n",
    "# Apply sum along different dimensions\n",
    "print(\"\\nApplying sum along different dimensions:\")\n",
    "result_dim0 = stx.torch.apply_to(torch.sum, data, dim=0)\n",
    "print(f\"Sum along dim=0, shape: {result_dim0.shape}\")\n",
    "\n",
    "result_dim1 = stx.torch.apply_to(torch.sum, data, dim=1)\n",
    "print(f\"Sum along dim=1, shape: {result_dim1.shape}\")\n",
    "\n",
    "result_dim2 = stx.torch.apply_to(torch.sum, data, dim=2)\n",
    "print(f\"Sum along dim=2, shape: {result_dim2.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Custom Functions with apply_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom functions to apply\n",
    "def normalize_slice(x):\n",
    "    \"\"\"Normalize a tensor slice to have mean=0 and std=1.\"\"\"\n",
    "    if x.numel() == 0:\n",
    "        return x\n",
    "    mean = x.mean()\n",
    "    std = x.std()\n",
    "    if std == 0:\n",
    "        return x - mean\n",
    "    return (x - mean) / std\n",
    "\n",
    "def compute_range(x):\n",
    "    \"\"\"Compute the range (max - min) of a tensor.\"\"\"\n",
    "    return x.max() - x.min()\n",
    "\n",
    "def percentile_95(x):\n",
    "    \"\"\"Compute 95th percentile.\"\"\"\n",
    "    return torch.quantile(x.float(), 0.95)\n",
    "\n",
    "# Create sample data\n",
    "data = torch.randn(4, 5, 6) * 10 + 5\n",
    "\n",
    "# Apply custom functions\n",
    "print(\"Original data shape:\", data.shape)\n",
    "\n",
    "# Normalize along last dimension\n",
    "normalized = stx.torch.apply_to(normalize_slice, data, dim=2)\n",
    "print(f\"\\nAfter normalization along dim=2:\")\n",
    "print(f\"Mean along dim=2: {normalized.mean(dim=2)}\")\n",
    "print(f\"Std along dim=2: {normalized.std(dim=2)}\")\n",
    "\n",
    "# Compute range along different dimensions\n",
    "range_dim0 = stx.torch.apply_to(compute_range, data, dim=0)\n",
    "range_dim1 = stx.torch.apply_to(compute_range, data, dim=1)\n",
    "print(f\"\\nRange along dim=0 shape: {range_dim0.shape}\")\n",
    "print(f\"Range along dim=1 shape: {range_dim1.shape}\")\n",
    "\n",
    "# Compute percentiles\n",
    "p95_dim2 = stx.torch.apply_to(percentile_95, data, dim=2)\n",
    "print(f\"\\n95th percentile along dim=2 shape: {p95_dim2.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Advanced Example: Sliding Window Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create time series data\n",
    "n_samples = 1000\n",
    "n_channels = 3\n",
    "time_series = torch.cumsum(torch.randn(n_samples, n_channels), dim=0)\n",
    "\n",
    "# Define sliding window function\n",
    "def sliding_window_stats(data, window_size=50, step=10):\n",
    "    \"\"\"Compute statistics over sliding windows.\"\"\"\n",
    "    n_windows = (len(data) - window_size) // step + 1\n",
    "    \n",
    "    means = torch.zeros(n_windows)\n",
    "    stds = torch.zeros(n_windows)\n",
    "    \n",
    "    for i in range(n_windows):\n",
    "        start = i * step\n",
    "        end = start + window_size\n",
    "        window = data[start:end]\n",
    "        means[i] = window.mean()\n",
    "        stds[i] = window.std()\n",
    "    \n",
    "    return torch.stack([means, stds])\n",
    "\n",
    "# Apply sliding window statistics to each channel\n",
    "window_stats = stx.torch.apply_to(\n",
    "    lambda x: sliding_window_stats(x, window_size=50, step=10),\n",
    "    time_series.T,  # Transpose to have channels as first dimension\n",
    "    dim=0\n",
    ")\n",
    "\n",
    "print(f\"Time series shape: {time_series.shape}\")\n",
    "print(f\"Window stats shape: {window_stats.shape}  # [channels, 2 (mean/std), n_windows]\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(3, 1, figsize=(12, 8), sharex=True)\n",
    "t = torch.arange(n_samples)\n",
    "window_t = torch.arange(0, n_samples-50, 10) + 25  # Window centers\n",
    "\n",
    "for i in range(n_channels):\n",
    "    # Plot original time series\n",
    "    axes[i].plot(t, time_series[:, i], 'b-', alpha=0.5, label='Original')\n",
    "    \n",
    "    # Plot sliding window statistics\n",
    "    means = window_stats[i, 0, :]\n",
    "    stds = window_stats[i, 1, :]\n",
    "    \n",
    "    axes[i].plot(window_t, means, 'r-', linewidth=2, label='Window mean')\n",
    "    axes[i].fill_between(window_t, means - stds, means + stds, \n",
    "                        alpha=0.3, color='red', label='±1 std')\n",
    "    \n",
    "    axes[i].set_ylabel(f'Channel {i+1}')\n",
    "    axes[i].legend()\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "axes[-1].set_xlabel('Time')\n",
    "plt.suptitle('Sliding Window Statistics with apply_to')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Practical Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate multi-channel sensor data with varying quality\n",
    "n_sensors = 8\n",
    "n_timepoints = 500\n",
    "\n",
    "# Generate base signals\n",
    "t = torch.linspace(0, 10, n_timepoints)\n",
    "signals = torch.zeros(n_sensors, n_timepoints)\n",
    "\n",
    "for i in range(n_sensors):\n",
    "    # Different frequency components per sensor\n",
    "    freq = 0.5 + i * 0.2\n",
    "    signals[i] = torch.sin(2 * np.pi * freq * t) + 0.1 * torch.randn(n_timepoints)\n",
    "\n",
    "# Introduce quality issues\n",
    "# Sensor 2: Intermittent failures (NaN)\n",
    "failure_mask = torch.rand(n_timepoints) < 0.15\n",
    "signals[2, failure_mask] = float('nan')\n",
    "\n",
    "# Sensor 5: Drift\n",
    "signals[5] += 0.3 * t\n",
    "\n",
    "# Sensor 7: High noise\n",
    "signals[7] += 0.5 * torch.randn(n_timepoints)\n",
    "\n",
    "# Compute quality metrics\n",
    "print(\"Data Quality Assessment:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# NaN count per sensor\n",
    "nan_counts = torch.isnan(signals).sum(dim=1)\n",
    "print(f\"\\nNaN counts per sensor: {nan_counts.tolist()}\")\n",
    "\n",
    "# Signal-to-noise ratio (using NaN-safe operations)\n",
    "signal_power = stx.torch.nanvar(signals, dim=1)\n",
    "noise_estimate = stx.torch.apply_to(\n",
    "    lambda x: stx.torch.nanvar(x[1:] - x[:-1]) / 2,  # Variance of first differences\n",
    "    signals,\n",
    "    dim=0\n",
    ")\n",
    "snr_db = 10 * torch.log10(signal_power / noise_estimate)\n",
    "\n",
    "print(f\"\\nSNR (dB) per sensor: {snr_db.tolist()}\")\n",
    "\n",
    "# Data range (detect outliers)\n",
    "ranges = stx.torch.apply_to(\n",
    "    lambda x: stx.torch.nanmax(x) - stx.torch.nanmin(x),\n",
    "    signals,\n",
    "    dim=0\n",
    ")\n",
    "print(f\"\\nData ranges per sensor: {ranges.tolist()}\")\n",
    "\n",
    "# Visualize sensor quality\n",
    "fig, axes = plt.subplots(2, 4, figsize=(15, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(n_sensors):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Plot signal\n",
    "    valid_mask = ~torch.isnan(signals[i])\n",
    "    ax.plot(t[valid_mask], signals[i][valid_mask], 'b-', linewidth=0.5)\n",
    "    \n",
    "    # Highlight NaN regions\n",
    "    if nan_counts[i] > 0:\n",
    "        nan_mask = torch.isnan(signals[i])\n",
    "        ax.scatter(t[nan_mask], torch.zeros(nan_mask.sum()), \n",
    "                  color='red', s=20, alpha=0.5)\n",
    "    \n",
    "    # Add quality info\n",
    "    quality_text = f\"SNR: {snr_db[i]:.1f} dB\\nNaN: {nan_counts[i]}/{n_timepoints}\"\n",
    "    ax.text(0.02, 0.98, quality_text, transform=ax.transAxes, \n",
    "            verticalalignment='top', fontsize=8,\n",
    "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    ax.set_title(f'Sensor {i+1}')\n",
    "    ax.set_ylim(-3, 3)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Multi-Sensor Data Quality Assessment')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Robust Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract robust features from noisy multi-channel data\n",
    "def extract_robust_features(data):\n",
    "    \"\"\"Extract features that are robust to NaN values.\"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    # Basic statistics (NaN-safe)\n",
    "    features['mean'] = torch.nanmean(data, dim=1)\n",
    "    features['std'] = stx.torch.nanstd(data, dim=1)\n",
    "    features['max'] = stx.torch.nanmax(data, dim=1)[0]\n",
    "    features['min'] = stx.torch.nanmin(data, dim=1)[0]\n",
    "    \n",
    "    # Percentiles (using NaN-safe approach)\n",
    "    features['q25'] = stx.torch.apply_to(\n",
    "        lambda x: torch.quantile(x[~torch.isnan(x)], 0.25) if (~torch.isnan(x)).any() else torch.tensor(float('nan')),\n",
    "        data, dim=0\n",
    "    )\n",
    "    features['q75'] = stx.torch.apply_to(\n",
    "        lambda x: torch.quantile(x[~torch.isnan(x)], 0.75) if (~torch.isnan(x)).any() else torch.tensor(float('nan')),\n",
    "        data, dim=0\n",
    "    )\n",
    "    \n",
    "    # Trend (linear fit, NaN-safe)\n",
    "    t = torch.arange(data.shape[1], dtype=torch.float32)\n",
    "    features['trend'] = stx.torch.apply_to(\n",
    "        lambda x: torch.tensor(\n",
    "            np.polyfit(t[~torch.isnan(x)].numpy(), \n",
    "                      x[~torch.isnan(x)].numpy(), 1)[0]\n",
    "        ) if (~torch.isnan(x)).sum() > 10 else torch.tensor(0.0),\n",
    "        data, dim=0\n",
    "    )\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Extract features from the sensor data\n",
    "features = extract_robust_features(signals)\n",
    "\n",
    "# Create feature matrix\n",
    "feature_names = list(features.keys())\n",
    "feature_matrix = torch.stack([features[name] for name in feature_names], dim=1)\n",
    "\n",
    "print(f\"Feature matrix shape: {feature_matrix.shape}  # [n_sensors, n_features]\")\n",
    "print(f\"Features: {feature_names}\")\n",
    "\n",
    "# Visualize feature matrix\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "im = ax.imshow(feature_matrix.T, aspect='auto', cmap='RdBu_r')\n",
    "ax.set_yticks(range(len(feature_names)))\n",
    "ax.set_yticklabels(feature_names)\n",
    "ax.set_xticks(range(n_sensors))\n",
    "ax.set_xticklabels([f'S{i+1}' for i in range(n_sensors)])\n",
    "ax.set_xlabel('Sensors')\n",
    "ax.set_title('Robust Feature Extraction (NaN-safe)')\n",
    "plt.colorbar(im, ax=ax)\n",
    "\n",
    "# Add values to heatmap\n",
    "for i in range(len(feature_names)):\n",
    "    for j in range(n_sensors):\n",
    "        val = feature_matrix[j, i].item()\n",
    "        if not np.isnan(val):\n",
    "            text = ax.text(j, i, f'{val:.2f}', ha='center', va='center',\n",
    "                         color='white' if abs(val) > feature_matrix.max()/2 else 'black',\n",
    "                         fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Compare performance of NaN-safe operations\n",
    "sizes = [100, 1000, 10000, 100000]\n",
    "nan_percentages = [0, 0.1, 0.3, 0.5]\n",
    "\n",
    "results = []\n",
    "\n",
    "for size in sizes:\n",
    "    for nan_pct in nan_percentages:\n",
    "        # Create data with specified NaN percentage\n",
    "        data = torch.randn(size)\n",
    "        nan_mask = torch.rand(size) < nan_pct\n",
    "        data[nan_mask] = float('nan')\n",
    "        \n",
    "        # Time standard operation (will return NaN if any NaN present)\n",
    "        start = time.time()\n",
    "        _ = torch.max(data)\n",
    "        std_time = time.time() - start\n",
    "        \n",
    "        # Time NaN-safe operation\n",
    "        start = time.time()\n",
    "        _ = stx.torch.nanmax(data)\n",
    "        nan_safe_time = time.time() - start\n",
    "        \n",
    "        results.append({\n",
    "            'size': size,\n",
    "            'nan_pct': nan_pct,\n",
    "            'std_time': std_time * 1000,  # Convert to ms\n",
    "            'nan_safe_time': nan_safe_time * 1000,\n",
    "            'overhead': (nan_safe_time / std_time - 1) * 100 if std_time > 0 else 0\n",
    "        })\n",
    "\n",
    "# Display results\n",
    "import pandas as pd\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "print(\"Performance Comparison: Standard vs NaN-safe Operations\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nExecution times (milliseconds):\")\n",
    "pivot_table = df_results.pivot_table(\n",
    "    values='nan_safe_time', \n",
    "    index='size', \n",
    "    columns='nan_pct'\n",
    ")\n",
    "print(pivot_table.round(3))\n",
    "\n",
    "# Visualize overhead\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "for nan_pct in nan_percentages:\n",
    "    subset = df_results[df_results['nan_pct'] == nan_pct]\n",
    "    ax.plot(subset['size'], subset['overhead'], \n",
    "           marker='o', label=f'{int(nan_pct*100)}% NaN')\n",
    "\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('Tensor Size')\n",
    "ax.set_ylabel('Overhead (%)')\n",
    "ax.set_title('NaN-safe Operation Overhead vs Standard Operations')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nNote: NaN-safe operations have some overhead but provide correct results\")\n",
    "print(\"with missing data, while standard operations fail (return NaN).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Integration with Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class NaNRobustLayer(nn.Module):\n",
    "    \"\"\"A layer that handles NaN values in inputs.\"\"\"\n",
    "    \n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Replace NaN with zeros (or could use mean imputation)\n",
    "        x_clean = torch.where(torch.isnan(x), torch.zeros_like(x), x)\n",
    "        \n",
    "        # Track NaN mask for potential use\n",
    "        nan_mask = torch.isnan(x)\n",
    "        \n",
    "        # Apply linear transformation\n",
    "        output = self.linear(x_clean)\n",
    "        \n",
    "        return output, nan_mask\n",
    "\n",
    "class RobustFeatureExtractor(nn.Module):\n",
    "    \"\"\"Extract robust statistical features from time series with NaN.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: [batch, channels, time]\n",
    "        batch_size, n_channels, _ = x.shape\n",
    "        \n",
    "        features = []\n",
    "        \n",
    "        # Extract NaN-safe features for each sample in batch\n",
    "        for i in range(batch_size):\n",
    "            sample_features = []\n",
    "            \n",
    "            # Per-channel features\n",
    "            sample_features.append(torch.nanmean(x[i], dim=1))  # Mean\n",
    "            sample_features.append(stx.torch.nanstd(x[i], dim=1))  # Std\n",
    "            sample_features.append(stx.torch.nanmax(x[i], dim=1)[0])  # Max\n",
    "            sample_features.append(stx.torch.nanmin(x[i], dim=1)[0])  # Min\n",
    "            \n",
    "            # Stack features\n",
    "            features.append(torch.cat(sample_features))\n",
    "        \n",
    "        return torch.stack(features)\n",
    "\n",
    "# Example usage\n",
    "# Create data with NaN\n",
    "batch_size = 16\n",
    "n_channels = 8\n",
    "seq_length = 100\n",
    "\n",
    "data = torch.randn(batch_size, n_channels, seq_length)\n",
    "# Add random NaN values\n",
    "nan_mask = torch.rand_like(data) < 0.1\n",
    "data[nan_mask] = float('nan')\n",
    "\n",
    "# Extract features\n",
    "extractor = RobustFeatureExtractor()\n",
    "features = extractor(data)\n",
    "\n",
    "print(f\"Input shape: {data.shape}\")\n",
    "print(f\"Feature shape: {features.shape}  # [batch, n_features]\")\n",
    "print(f\"NaN count in input: {torch.isnan(data).sum().item()}\")\n",
    "print(f\"NaN count in features: {torch.isnan(features).sum().item()}\")\n",
    "\n",
    "# Use in a complete model\n",
    "class TimeSeriesClassifier(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = RobustFeatureExtractor()\n",
    "        # 4 features per channel (mean, std, max, min)\n",
    "        n_features = n_channels * 4\n",
    "        self.classifier = nn.Sequential(\n",
    "            NaNRobustLayer(n_features, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(64, n_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = self.feature_extractor(x)\n",
    "        # Handle the NaNRobustLayer output\n",
    "        output, _ = self.classifier[0](features)\n",
    "        # Apply rest of classifier\n",
    "        for layer in self.classifier[1:]:\n",
    "            output = layer(output)\n",
    "        return output\n",
    "\n",
    "# Test the classifier\n",
    "model = TimeSeriesClassifier(n_channels=8, n_classes=4)\n",
    "output = model(data)\n",
    "print(f\"\\nClassifier output shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary and Best Practices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Takeaways\n",
    "\n",
    "1. **NaN-Safe Operations**: Essential for real-world data with missing values\n",
    "2. **apply_to Function**: Flexible way to apply any function along tensor dimensions\n",
    "3. **Performance**: Small overhead for NaN-safety is worth the robustness\n",
    "4. **Integration**: Easy to integrate with PyTorch models and workflows\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "1. **Data Validation**:\n",
    "   ```python\n",
    "   # Always check for NaN before processing\n",
    "   if torch.isnan(data).any():\n",
    "       # Use NaN-safe operations\n",
    "       result = stx.torch.nanmean(data)\n",
    "   else:\n",
    "       # Use standard operations for better performance\n",
    "       result = torch.mean(data)\n",
    "   ```\n",
    "\n",
    "2. **Feature Engineering**:\n",
    "   ```python\n",
    "   # Create robust features that handle missing data\n",
    "   features = {\n",
    "       'mean': torch.nanmean(data, dim=-1),\n",
    "       'std': stx.torch.nanstd(data, dim=-1),\n",
    "       'valid_ratio': (~torch.isnan(data)).float().mean(dim=-1)\n",
    "   }\n",
    "   ```\n",
    "\n",
    "3. **Custom Functions with apply_to**:\n",
    "   ```python\n",
    "   # Define reusable processing functions\n",
    "   def robust_normalize(x):\n",
    "       mean = torch.nanmean(x)\n",
    "       std = stx.torch.nanstd(x)\n",
    "       return (x - mean) / (std + 1e-8)\n",
    "   \n",
    "   normalized = stx.torch.apply_to(robust_normalize, data, dim=1)\n",
    "   ```\n",
    "\n",
    "4. **Model Design**:\n",
    "   ```python\n",
    "   # Build models that gracefully handle missing data\n",
    "   class RobustModel(nn.Module):\n",
    "       def forward(self, x):\n",
    "           # Track data quality\n",
    "           nan_ratio = torch.isnan(x).float().mean()\n",
    "           if nan_ratio > 0.5:\n",
    "               warnings.warn(f\"High NaN ratio: {nan_ratio:.2f}\")\n",
    "           # Process with NaN-safe operations\n",
    "           return self.process(x)\n",
    "   ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTorch utilities tutorial completed!\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Apply NaN-safe operations to your data pipelines\")\n",
    "print(\"2. Use apply_to for custom tensor transformations\")\n",
    "print(\"3. Build robust models that handle missing data\")\n",
    "print(\"4. Monitor data quality in production systems\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}