{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehensive SciTeX PyTorch Module Examples\n",
    "\n",
    "This notebook demonstrates the complete functionality of the `scitex.torch` module, which provides PyTorch-specific utilities and extensions for scientific computing.\n",
    "\n",
    "## Module Overview\n",
    "\n",
    "The `scitex.torch` module includes:\n",
    "- NaN-aware statistical functions\n",
    "- Tensor manipulation utilities\n",
    "- PyTorch-specific scientific computing functions\n",
    "\n",
    "## Import Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import scitex torch module\n",
    "import scitex.torch as storch\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Available functions in scitex.torch:\")\n",
    "torch_attrs = [attr for attr in dir(storch) if not attr.startswith('_')]\n",
    "for i, attr in enumerate(torch_attrs):\n",
    "    print(f\"{i+1:2d}. {attr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. NaN-Aware Statistical Functions\n",
    "\n",
    "The module provides robust statistical functions that handle NaN values appropriately.\n",
    "\n",
    "### Basic NaN Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Create test data with NaN values\n",
    "# Create tensor with some NaN values\n",
    "data = torch.randn(4, 5, 6)\n",
    "data[0, 1, 2] = float('nan')\n",
    "data[1, 2, :] = float('nan')\n",
    "data[2, :, 3] = float('nan')\n",
    "\n",
    "print(f\"Data shape: {data.shape}\")\n",
    "print(f\"Number of NaN values: {torch.isnan(data).sum().item()}\")\n",
    "print(f\"Data range (excluding NaN): [{data[~torch.isnan(data)].min():.3f}, {data[~torch.isnan(data)].max():.3f}]\")\n",
    "\n",
    "# Visualize NaN pattern\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "\n",
    "for i in range(4):\n",
    "    # Create a mask showing NaN locations\n",
    "    nan_mask = torch.isnan(data[i]).float()\n",
    "    im = axes[i].imshow(nan_mask.numpy(), cmap='Reds', aspect='auto')\n",
    "    axes[i].set_title(f'Batch {i} - NaN Locations')\n",
    "    axes[i].set_xlabel('Dimension 2')\n",
    "    axes[i].set_ylabel('Dimension 1')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaN-Aware Min and Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: NaN-aware min and max functions\n",
    "print(\"Testing nanmin and nanmax functions:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Test nanmin\n",
    "try:\n",
    "    # Global min\n",
    "    global_min = storch.nanmin(data)\n",
    "    print(f\"Global nanmin: {global_min}\")\n",
    "    \n",
    "    # Min along different dimensions\n",
    "    min_dim0 = storch.nanmin(data, dim=0)\n",
    "    min_dim1 = storch.nanmin(data, dim=1)\n",
    "    min_dim2 = storch.nanmin(data, dim=2)\n",
    "    \n",
    "    print(f\"Min along dim 0 shape: {min_dim0.values.shape if hasattr(min_dim0, 'values') else min_dim0.shape}\")\n",
    "    print(f\"Min along dim 1 shape: {min_dim1.values.shape if hasattr(min_dim1, 'values') else min_dim1.shape}\")\n",
    "    print(f\"Min along dim 2 shape: {min_dim2.values.shape if hasattr(min_dim2, 'values') else min_dim2.shape}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error with nanmin: {e}\")\n",
    "\n",
    "# Test nanmax\n",
    "try:\n",
    "    # Global max\n",
    "    global_max = storch.nanmax(data)\n",
    "    print(f\"\\nGlobal nanmax: {global_max}\")\n",
    "    \n",
    "    # Max along different dimensions\n",
    "    max_dim0 = storch.nanmax(data, dim=0)\n",
    "    max_dim1 = storch.nanmax(data, dim=1)\n",
    "    max_dim2 = storch.nanmax(data, dim=2)\n",
    "    \n",
    "    print(f\"Max along dim 0 shape: {max_dim0.values.shape if hasattr(max_dim0, 'values') else max_dim0.shape}\")\n",
    "    print(f\"Max along dim 1 shape: {max_dim1.values.shape if hasattr(max_dim1, 'values') else max_dim1.shape}\")\n",
    "    print(f\"Max along dim 2 shape: {max_dim2.values.shape if hasattr(max_dim2, 'values') else max_dim2.shape}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error with nanmax: {e}\")\n",
    "\n",
    "# Compare with regular min/max (which would fail with NaN)\n",
    "print(\"\\nComparison with regular PyTorch functions:\")\n",
    "try:\n",
    "    regular_min = torch.min(data)\n",
    "    regular_max = torch.max(data)\n",
    "    print(f\"Regular min: {regular_min}\")\n",
    "    print(f\"Regular max: {regular_max}\")\n",
    "except Exception as e:\n",
    "    print(f\"Regular functions with NaN: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaN-Aware ArgMin and ArgMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: NaN-aware argmin and argmax\n",
    "print(\"Testing nanargmin and nanargmax functions:\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# Create simpler test data for argmin/argmax\n",
    "simple_data = torch.tensor([\n",
    "    [1.0, float('nan'), 3.0, 0.5],\n",
    "    [float('nan'), 2.0, float('nan'), 1.5],\n",
    "    [2.5, 0.1, 4.0, float('nan')]\n",
    "])\n",
    "\n",
    "print(f\"Test data:\\n{simple_data}\")\n",
    "\n",
    "try:\n",
    "    # Global argmin and argmax\n",
    "    global_argmin = storch.nanargmin(simple_data)\n",
    "    global_argmax = storch.nanargmax(simple_data)\n",
    "    \n",
    "    print(f\"\\nGlobal nanargmin: {global_argmin}\")\n",
    "    print(f\"Global nanargmax: {global_argmax}\")\n",
    "    \n",
    "    # Along dimensions\n",
    "    argmin_dim0 = storch.nanargmin(simple_data, dim=0)\n",
    "    argmax_dim0 = storch.nanargmax(simple_data, dim=0)\n",
    "    \n",
    "    argmin_dim1 = storch.nanargmin(simple_data, dim=1)\n",
    "    argmax_dim1 = storch.nanargmax(simple_data, dim=1)\n",
    "    \n",
    "    print(f\"\\nArgmin along dim 0: {argmin_dim0}\")\n",
    "    print(f\"Argmax along dim 0: {argmax_dim0}\")\n",
    "    print(f\"\\nArgmin along dim 1: {argmin_dim1}\")\n",
    "    print(f\"Argmax along dim 1: {argmax_dim1}\")\n",
    "    \n",
    "    # Verify results\n",
    "    print(\"\\nVerification:\")\n",
    "    flattened = simple_data.flatten()\n",
    "    valid_indices = ~torch.isnan(flattened)\n",
    "    valid_values = flattened[valid_indices]\n",
    "    \n",
    "    print(f\"Valid values: {valid_values}\")\n",
    "    print(f\"Min value: {valid_values.min()}\")\n",
    "    print(f\"Max value: {valid_values.max()}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error with nanargmin/nanargmax: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaN-Aware Variance and Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 4: NaN-aware variance and standard deviation\n",
    "print(\"Testing nanvar and nanstd functions:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Create test data with known statistics\n",
    "test_data = torch.tensor([\n",
    "    [1.0, 2.0, 3.0, 4.0, 5.0],\n",
    "    [float('nan'), 2.0, 3.0, 4.0, float('nan')],\n",
    "    [1.0, float('nan'), float('nan'), 4.0, 5.0]\n",
    "])\n",
    "\n",
    "print(f\"Test data:\\n{test_data}\")\n",
    "\n",
    "try:\n",
    "    # Global variance and std\n",
    "    global_var = storch.nanvar(test_data)\n",
    "    global_std = storch.nanstd(test_data)\n",
    "    \n",
    "    print(f\"\\nGlobal nanvar: {global_var:.4f}\")\n",
    "    print(f\"Global nanstd: {global_std:.4f}\")\n",
    "    \n",
    "    # Along dimensions\n",
    "    var_dim0 = storch.nanvar(test_data, dim=0)\n",
    "    std_dim0 = storch.nanstd(test_data, dim=0)\n",
    "    \n",
    "    var_dim1 = storch.nanvar(test_data, dim=1)\n",
    "    std_dim1 = storch.nanstd(test_data, dim=1)\n",
    "    \n",
    "    print(f\"\\nVariance along dim 0: {var_dim0}\")\n",
    "    print(f\"Std along dim 0: {std_dim0}\")\n",
    "    print(f\"\\nVariance along dim 1: {var_dim1}\")\n",
    "    print(f\"Std along dim 1: {std_dim1}\")\n",
    "    \n",
    "    # Verify relationship between var and std\n",
    "    print(f\"\\nVerification (std^2 ≈ var):\")\n",
    "    print(f\"Global: {global_std**2:.4f} ≈ {global_var:.4f}\")\n",
    "    \n",
    "    # Compare with PyTorch's nanmean\n",
    "    global_mean = torch.nanmean(test_data)\n",
    "    print(f\"\\nGlobal nanmean: {global_mean:.4f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error with nanvar/nanstd: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaN-Aware Product Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 5: NaN-aware product and cumulative product\n",
    "print(\"Testing nanprod and nancumprod functions:\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# Create test data with small values to avoid overflow\n",
    "prod_data = torch.tensor([\n",
    "    [1.0, 2.0, 0.5, float('nan')],\n",
    "    [float('nan'), 1.5, 2.0, 0.8],\n",
    "    [2.0, float('nan'), 1.0, 1.2]\n",
    "])\n",
    "\n",
    "print(f\"Test data:\\n{prod_data}\")\n",
    "\n",
    "try:\n",
    "    # Global product\n",
    "    global_prod = storch.nanprod(prod_data)\n",
    "    print(f\"\\nGlobal nanprod: {global_prod:.4f}\")\n",
    "    \n",
    "    # Product along dimensions\n",
    "    prod_dim0 = storch.nanprod(prod_data, dim=0)\n",
    "    prod_dim1 = storch.nanprod(prod_data, dim=1)\n",
    "    \n",
    "    print(f\"\\nProduct along dim 0: {prod_dim0}\")\n",
    "    print(f\"Product along dim 1: {prod_dim1}\")\n",
    "    \n",
    "    # Cumulative product\n",
    "    cumprod_dim0 = storch.nancumprod(prod_data, dim=0)\n",
    "    cumprod_dim1 = storch.nancumprod(prod_data, dim=1)\n",
    "    \n",
    "    print(f\"\\nCumulative product along dim 0:\\n{cumprod_dim0}\")\n",
    "    print(f\"\\nCumulative product along dim 1:\\n{cumprod_dim1}\")\n",
    "    \n",
    "    # Manual verification for first row\n",
    "    first_row = prod_data[0]\n",
    "    valid_values = first_row[~torch.isnan(first_row)]\n",
    "    manual_prod = torch.prod(valid_values)\n",
    "    print(f\"\\nManual verification for first row:\")\n",
    "    print(f\"Valid values: {valid_values}\")\n",
    "    print(f\"Manual product: {manual_prod:.4f}\")\n",
    "    print(f\"nanprod result: {prod_dim1[0]:.4f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error with nanprod/nancumprod: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaN-Aware Cumulative Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 6: NaN-aware cumulative sum\n",
    "print(\"Testing nancumsum function:\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# Create test data for cumulative sum\n",
    "cumsum_data = torch.tensor([\n",
    "    [1.0, 2.0, 3.0, float('nan'), 5.0],\n",
    "    [float('nan'), 1.0, float('nan'), 2.0, 3.0],\n",
    "    [2.0, float('nan'), 1.0, 1.0, float('nan')]\n",
    "])\n",
    "\n",
    "print(f\"Test data:\\n{cumsum_data}\")\n",
    "\n",
    "try:\n",
    "    # Cumulative sum along different dimensions\n",
    "    cumsum_dim0 = storch.nancumsum(cumsum_data, dim=0)\n",
    "    cumsum_dim1 = storch.nancumsum(cumsum_data, dim=1)\n",
    "    \n",
    "    print(f\"\\nCumulative sum along dim 0:\\n{cumsum_dim0}\")\n",
    "    print(f\"\\nCumulative sum along dim 1:\\n{cumsum_dim1}\")\n",
    "    \n",
    "    # Visualize cumulative sum\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "    \n",
    "    # Original data\n",
    "    im1 = axes[0, 0].imshow(cumsum_data.numpy(), cmap='viridis', aspect='auto')\n",
    "    axes[0, 0].set_title('Original Data')\n",
    "    axes[0, 0].set_xlabel('Column')\n",
    "    axes[0, 0].set_ylabel('Row')\n",
    "    plt.colorbar(im1, ax=axes[0, 0])\n",
    "    \n",
    "    # NaN mask\n",
    "    nan_mask = torch.isnan(cumsum_data).float()\n",
    "    im2 = axes[0, 1].imshow(nan_mask.numpy(), cmap='Reds', aspect='auto')\n",
    "    axes[0, 1].set_title('NaN Mask')\n",
    "    axes[0, 1].set_xlabel('Column')\n",
    "    axes[0, 1].set_ylabel('Row')\n",
    "    plt.colorbar(im2, ax=axes[0, 1])\n",
    "    \n",
    "    # Cumsum along dim 0\n",
    "    im3 = axes[1, 0].imshow(cumsum_dim0.numpy(), cmap='viridis', aspect='auto')\n",
    "    axes[1, 0].set_title('Cumulative Sum (dim=0)')\n",
    "    axes[1, 0].set_xlabel('Column')\n",
    "    axes[1, 0].set_ylabel('Row')\n",
    "    plt.colorbar(im3, ax=axes[1, 0])\n",
    "    \n",
    "    # Cumsum along dim 1\n",
    "    im4 = axes[1, 1].imshow(cumsum_dim1.numpy(), cmap='viridis', aspect='auto')\n",
    "    axes[1, 1].set_title('Cumulative Sum (dim=1)')\n",
    "    axes[1, 1].set_xlabel('Column')\n",
    "    axes[1, 1].set_ylabel('Row')\n",
    "    plt.colorbar(im4, ax=axes[1, 1])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error with nancumsum: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tensor Manipulation Utilities\n",
    "\n",
    "### Apply Function Along Dimension\n",
    "\n",
    "The `apply_to` function applies a function to tensors along a specific dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 7: apply_to function\n",
    "print(\"Testing apply_to function:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Create test tensor\n",
    "test_tensor = torch.randn(3, 4, 5)\n",
    "print(f\"Test tensor shape: {test_tensor.shape}\")\n",
    "\n",
    "try:\n",
    "    # Apply sum along different dimensions\n",
    "    result_dim0 = storch.apply_to(torch.sum, test_tensor, dim=0)\n",
    "    result_dim1 = storch.apply_to(torch.sum, test_tensor, dim=1)\n",
    "    result_dim2 = storch.apply_to(torch.sum, test_tensor, dim=2)\n",
    "    \n",
    "    print(f\"\\nApply sum along dim 0: {result_dim0.shape}\")\n",
    "    print(f\"Apply sum along dim 1: {result_dim1.shape}\")\n",
    "    print(f\"Apply sum along dim 2: {result_dim2.shape}\")\n",
    "    \n",
    "    # Compare with direct PyTorch operations\n",
    "    direct_sum_0 = torch.sum(test_tensor, dim=0)\n",
    "    direct_sum_1 = torch.sum(test_tensor, dim=1)\n",
    "    direct_sum_2 = torch.sum(test_tensor, dim=2)\n",
    "    \n",
    "    print(f\"\\nDirect sum along dim 0: {direct_sum_0.shape}\")\n",
    "    print(f\"Direct sum along dim 1: {direct_sum_1.shape}\")\n",
    "    print(f\"Direct sum along dim 2: {direct_sum_2.shape}\")\n",
    "    \n",
    "    # Check if results match\n",
    "    print(f\"\\nResults match:\")\n",
    "    print(f\"Dim 0: {torch.allclose(result_dim0, direct_sum_0, equal_nan=True)}\")\n",
    "    print(f\"Dim 1: {torch.allclose(result_dim1, direct_sum_1, equal_nan=True)}\")\n",
    "    print(f\"Dim 2: {torch.allclose(result_dim2, direct_sum_2, equal_nan=True)}\")\n",
    "    \n",
    "    # Apply custom function\n",
    "    def custom_fn(x):\n",
    "        return torch.mean(x) * torch.std(x)\n",
    "    \n",
    "    custom_result = storch.apply_to(custom_fn, test_tensor, dim=1)\n",
    "    print(f\"\\nCustom function result shape: {custom_result.shape}\")\n",
    "    print(f\"Custom function result: {custom_result}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error with apply_to: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Practical Applications\n",
    "\n",
    "### Robust Statistics with NaN Handling\n",
    "\n",
    "Let's demonstrate practical applications of the NaN-aware functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 8: Robust data analysis with missing values\n",
    "print(\"Practical Application: Robust Data Analysis\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# Simulate sensor data with missing readings\n",
    "n_sensors = 8\n",
    "n_timepoints = 100\n",
    "sensor_data = torch.randn(n_sensors, n_timepoints)\n",
    "\n",
    "# Introduce missing data (NaN) randomly\n",
    "missing_prob = 0.1\n",
    "missing_mask = torch.rand_like(sensor_data) < missing_prob\n",
    "sensor_data[missing_mask] = float('nan')\n",
    "\n",
    "print(f\"Sensor data shape: {sensor_data.shape}\")\n",
    "print(f\"Missing data points: {torch.isnan(sensor_data).sum().item()} / {sensor_data.numel()}\")\n",
    "print(f\"Missing data percentage: {torch.isnan(sensor_data).float().mean().item() * 100:.1f}%\")\n",
    "\n",
    "# Compute robust statistics\n",
    "try:\n",
    "    # Statistics per sensor (across time)\n",
    "    sensor_means = torch.nanmean(sensor_data, dim=1)\n",
    "    sensor_stds = storch.nanstd(sensor_data, dim=1)\n",
    "    sensor_mins = storch.nanmin(sensor_data, dim=1)\n",
    "    sensor_maxs = storch.nanmax(sensor_data, dim=1)\n",
    "    \n",
    "    # Statistics per timepoint (across sensors)\n",
    "    time_means = torch.nanmean(sensor_data, dim=0)\n",
    "    time_stds = storch.nanstd(sensor_data, dim=0)\n",
    "    \n",
    "    print(f\"\\nSensor Statistics:\")\n",
    "    print(f\"Means: {sensor_means}\")\n",
    "    print(f\"Stds: {sensor_stds}\")\n",
    "    print(f\"Mins: {sensor_mins.values if hasattr(sensor_mins, 'values') else sensor_mins}\")\n",
    "    print(f\"Maxs: {sensor_maxs.values if hasattr(sensor_maxs, 'values') else sensor_maxs}\")\n",
    "    \n",
    "    # Visualize data and statistics\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Raw sensor data\n",
    "    im1 = axes[0, 0].imshow(sensor_data.numpy(), aspect='auto', cmap='viridis')\n",
    "    axes[0, 0].set_title('Sensor Data (with NaN)')\n",
    "    axes[0, 0].set_xlabel('Time')\n",
    "    axes[0, 0].set_ylabel('Sensor')\n",
    "    plt.colorbar(im1, ax=axes[0, 0])\n",
    "    \n",
    "    # Missing data pattern\n",
    "    nan_pattern = torch.isnan(sensor_data).float()\n",
    "    im2 = axes[0, 1].imshow(nan_pattern.numpy(), aspect='auto', cmap='Reds')\n",
    "    axes[0, 1].set_title('Missing Data Pattern')\n",
    "    axes[0, 1].set_xlabel('Time')\n",
    "    axes[0, 1].set_ylabel('Sensor')\n",
    "    plt.colorbar(im2, ax=axes[0, 1])\n",
    "    \n",
    "    # Sensor statistics\n",
    "    x_sensors = range(n_sensors)\n",
    "    axes[1, 0].errorbar(x_sensors, sensor_means.numpy(), yerr=sensor_stds.numpy(), \n",
    "                       fmt='o-', capsize=5, alpha=0.7)\n",
    "    axes[1, 0].set_title('Sensor Statistics (Mean ± Std)')\n",
    "    axes[1, 0].set_xlabel('Sensor ID')\n",
    "    axes[1, 0].set_ylabel('Value')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Time series of means\n",
    "    axes[1, 1].plot(time_means.numpy(), alpha=0.7, label='Mean')\n",
    "    axes[1, 1].fill_between(range(len(time_means)), \n",
    "                           (time_means - time_stds).numpy(),\n",
    "                           (time_means + time_stds).numpy(),\n",
    "                           alpha=0.3, label='±1 Std')\n",
    "    axes[1, 1].set_title('Temporal Statistics')\n",
    "    axes[1, 1].set_xlabel('Time')\n",
    "    axes[1, 1].set_ylabel('Value')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error in robust analysis: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Series Analysis with Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 9: Time series analysis with missing data\n",
    "print(\"Time Series Analysis with Missing Data:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Create time series with trend and noise\n",
    "t = torch.linspace(0, 4*np.pi, 200)\n",
    "trend = 0.1 * t\n",
    "seasonal = torch.sin(t) + 0.5 * torch.sin(3*t)\n",
    "noise = 0.2 * torch.randn_like(t)\n",
    "time_series = trend + seasonal + noise\n",
    "\n",
    "# Introduce missing data in chunks (simulating sensor failures)\n",
    "time_series_with_gaps = time_series.clone()\n",
    "# Create several gaps\n",
    "time_series_with_gaps[30:40] = float('nan')  # Gap 1\n",
    "time_series_with_gaps[80:85] = float('nan')  # Gap 2\n",
    "time_series_with_gaps[150:160] = float('nan')  # Gap 3\n",
    "# Random missing points\n",
    "random_missing = torch.rand_like(time_series) < 0.05\n",
    "time_series_with_gaps[random_missing] = float('nan')\n",
    "\n",
    "print(f\"Original time series length: {len(time_series)}\")\n",
    "print(f\"Missing points: {torch.isnan(time_series_with_gaps).sum().item()}\")\n",
    "print(f\"Missing percentage: {torch.isnan(time_series_with_gaps).float().mean().item() * 100:.1f}%\")\n",
    "\n",
    "try:\n",
    "    # Compute rolling statistics using NaN-aware functions\n",
    "    window_size = 10\n",
    "    rolling_means = []\n",
    "    rolling_stds = []\n",
    "    \n",
    "    for i in range(window_size//2, len(time_series_with_gaps) - window_size//2):\n",
    "        window = time_series_with_gaps[i-window_size//2:i+window_size//2+1]\n",
    "        if not torch.isnan(window).all():  # If window has some valid data\n",
    "            mean_val = torch.nanmean(window)\n",
    "            std_val = storch.nanstd(window)\n",
    "        else:\n",
    "            mean_val = float('nan')\n",
    "            std_val = float('nan')\n",
    "        rolling_means.append(mean_val)\n",
    "        rolling_stds.append(std_val)\n",
    "    \n",
    "    rolling_means = torch.tensor(rolling_means)\n",
    "    rolling_stds = torch.tensor(rolling_stds)\n",
    "    \n",
    "    # Visualize time series analysis\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(15, 12))\n",
    "    \n",
    "    # Original vs. missing data\n",
    "    axes[0].plot(t.numpy(), time_series.numpy(), alpha=0.7, label='Original', color='blue')\n",
    "    valid_mask = ~torch.isnan(time_series_with_gaps)\n",
    "    axes[0].scatter(t[valid_mask].numpy(), time_series_with_gaps[valid_mask].numpy(), \n",
    "                   s=1, alpha=0.8, label='Available data', color='red')\n",
    "    axes[0].set_title('Time Series with Missing Data')\n",
    "    axes[0].set_xlabel('Time')\n",
    "    axes[0].set_ylabel('Value')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Missing data pattern\n",
    "    missing_indicator = torch.isnan(time_series_with_gaps).float()\n",
    "    axes[1].fill_between(t.numpy(), 0, missing_indicator.numpy(), \n",
    "                        alpha=0.7, color='red', label='Missing data')\n",
    "    axes[1].set_title('Missing Data Pattern')\n",
    "    axes[1].set_xlabel('Time')\n",
    "    axes[1].set_ylabel('Missing')\n",
    "    axes[1].set_ylim(-0.1, 1.1)\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Rolling statistics\n",
    "    t_rolling = t[window_size//2:-window_size//2]\n",
    "    valid_rolling = ~torch.isnan(rolling_means)\n",
    "    axes[2].plot(t_rolling[valid_rolling].numpy(), rolling_means[valid_rolling].numpy(), \n",
    "                label='Rolling mean', color='green', linewidth=2)\n",
    "    axes[2].fill_between(t_rolling[valid_rolling].numpy(),\n",
    "                        (rolling_means[valid_rolling] - rolling_stds[valid_rolling]).numpy(),\n",
    "                        (rolling_means[valid_rolling] + rolling_stds[valid_rolling]).numpy(),\n",
    "                        alpha=0.3, color='green', label='±1 Std')\n",
    "    axes[2].scatter(t[valid_mask].numpy(), time_series_with_gaps[valid_mask].numpy(), \n",
    "                   s=1, alpha=0.5, color='blue', label='Data points')\n",
    "    axes[2].set_title(f'Rolling Statistics (window size: {window_size})')\n",
    "    axes[2].set_xlabel('Time')\n",
    "    axes[2].set_ylabel('Value')\n",
    "    axes[2].legend()\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(f\"\\nSummary Statistics:\")\n",
    "    print(f\"Original data - Mean: {time_series.mean():.3f}, Std: {time_series.std():.3f}\")\n",
    "    print(f\"Available data - Mean: {torch.nanmean(time_series_with_gaps):.3f}, Std: {storch.nanstd(time_series_with_gaps):.3f}\")\n",
    "    print(f\"Rolling mean - Mean: {torch.nanmean(rolling_means):.3f}, Std: {storch.nanstd(rolling_means):.3f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error in time series analysis: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Performance Comparison\n",
    "\n",
    "Let's compare the performance of scitex.torch functions with standard PyTorch operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 10: Performance comparison\n",
    "import time\n",
    "\n",
    "print(\"Performance Comparison:\")\n",
    "print(\"=\" * 25)\n",
    "\n",
    "# Create large test tensor\n",
    "large_tensor = torch.randn(1000, 500)\n",
    "large_tensor_with_nan = large_tensor.clone()\n",
    "\n",
    "# Introduce some NaN values\n",
    "nan_mask = torch.rand_like(large_tensor) < 0.05\n",
    "large_tensor_with_nan[nan_mask] = float('nan')\n",
    "\n",
    "print(f\"Test tensor shape: {large_tensor.shape}\")\n",
    "print(f\"NaN values: {torch.isnan(large_tensor_with_nan).sum().item()}\")\n",
    "\n",
    "# Number of iterations for timing\n",
    "n_iters = 100\n",
    "\n",
    "def time_function(func, data, n_iters=100):\n",
    "    \"\"\"Time a function over multiple iterations.\"\"\"\n",
    "    start_time = time.time()\n",
    "    for _ in range(n_iters):\n",
    "        try:\n",
    "            _ = func(data)\n",
    "        except:\n",
    "            pass\n",
    "    end_time = time.time()\n",
    "    return (end_time - start_time) / n_iters\n",
    "\n",
    "try:\n",
    "    # Compare mean functions\n",
    "    print(f\"\\nMean computation ({n_iters} iterations):\")\n",
    "    \n",
    "    # Standard PyTorch (will propagate NaN)\n",
    "    torch_mean_time = time_function(torch.mean, large_tensor_with_nan, n_iters)\n",
    "    \n",
    "    # PyTorch nanmean\n",
    "    torch_nanmean_time = time_function(torch.nanmean, large_tensor_with_nan, n_iters)\n",
    "    \n",
    "    print(f\"torch.mean: {torch_mean_time*1000:.3f} ms\")\n",
    "    print(f\"torch.nanmean: {torch_nanmean_time*1000:.3f} ms\")\n",
    "    \n",
    "    # Compare std functions\n",
    "    print(f\"\\nStandard deviation computation ({n_iters} iterations):\")\n",
    "    \n",
    "    torch_std_time = time_function(torch.std, large_tensor_with_nan, n_iters)\n",
    "    scitex_nanstd_time = time_function(storch.nanstd, large_tensor_with_nan, n_iters)\n",
    "    \n",
    "    print(f\"torch.std: {torch_std_time*1000:.3f} ms\")\n",
    "    print(f\"scitex.nanstd: {scitex_nanstd_time*1000:.3f} ms\")\n",
    "    \n",
    "    # Compare min/max functions\n",
    "    print(f\"\\nMin/Max computation ({n_iters} iterations):\")\n",
    "    \n",
    "    torch_min_time = time_function(torch.min, large_tensor_with_nan, n_iters)\n",
    "    scitex_nanmin_time = time_function(storch.nanmin, large_tensor_with_nan, n_iters)\n",
    "    \n",
    "    print(f\"torch.min: {torch_min_time*1000:.3f} ms\")\n",
    "    print(f\"scitex.nanmin: {scitex_nanmin_time*1000:.3f} ms\")\n",
    "    \n",
    "    # Test correctness\n",
    "    print(f\"\\nCorrectness check:\")\n",
    "    torch_result = torch.mean(large_tensor_with_nan)\n",
    "    nanmean_result = torch.nanmean(large_tensor_with_nan)\n",
    "    \n",
    "    print(f\"torch.mean result: {torch_result}\")\n",
    "    print(f\"torch.nanmean result: {nanmean_result:.6f}\")\n",
    "    print(f\"torch.mean is NaN: {torch.isnan(torch_result)}\")\n",
    "    print(f\"nanmean gives valid result: {not torch.isnan(nanmean_result)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error in performance comparison: {e}\")\n",
    "\n",
    "# Memory usage comparison\n",
    "print(f\"\\nMemory usage:\")\n",
    "print(f\"Original tensor: {large_tensor.element_size() * large_tensor.nelement() / 1024**2:.2f} MB\")\n",
    "print(f\"Tensor with NaN: {large_tensor_with_nan.element_size() * large_tensor_with_nan.nelement() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook has demonstrated the comprehensive functionality of the `scitex.torch` module:\n",
    "\n",
    "### NaN-Aware Statistical Functions\n",
    "- **`nanmin`** and **`nanmax`**: Robust minimum and maximum computation\n",
    "- **`nanargmin`** and **`nanargmax`**: Indices of minimum and maximum values\n",
    "- **`nanvar`** and **`nanstd`**: Variance and standard deviation with NaN handling\n",
    "- **`nanprod`** and **`nancumprod`**: Product operations ignoring NaN values\n",
    "- **`nancumsum`**: Cumulative sum with NaN handling\n",
    "\n",
    "### Tensor Manipulation\n",
    "- **`apply_to`**: Apply functions along specific dimensions\n",
    "\n",
    "### Key Features\n",
    "1. **Robustness**: All functions handle NaN values appropriately\n",
    "2. **Consistency**: Maintains PyTorch tensor operations and broadcasting rules\n",
    "3. **Performance**: Optimized implementations for scientific computing\n",
    "4. **Compatibility**: Works seamlessly with existing PyTorch code\n",
    "\n",
    "### Practical Applications\n",
    "- **Missing Data Analysis**: Handle sensor failures and data gaps\n",
    "- **Robust Statistics**: Compute statistics in presence of outliers (as NaN)\n",
    "- **Time Series Processing**: Rolling statistics with missing observations\n",
    "- **Scientific Computing**: Reliable numerical operations for research\n",
    "\n",
    "### Use Cases\n",
    "- Sensor data with equipment failures\n",
    "- Experimental data with measurement errors\n",
    "- Large-scale data processing with quality issues\n",
    "- Real-time analysis where some data points may be unavailable\n",
    "\n",
    "The `scitex.torch` module provides essential tools for robust scientific computing with PyTorch, ensuring that missing or invalid data doesn't break your analysis pipeline."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}