{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SciTeX Database Module Tutorial\n",
    "\n",
    "This notebook demonstrates the database utilities in SciTeX for SQLite and PostgreSQL database management, inspection, and maintenance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scitex as stx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import os\n",
    "import shutil\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "\n",
    "# Create temporary directory for database files\n",
    "temp_dir = tempfile.mkdtemp(prefix=\"scitex_db_demo_\")\n",
    "print(f\"Working directory: {temp_dir}\")\n",
    "os.chdir(temp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. SQLite Database Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Creating and Connecting to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new SQLite database\n",
    "db = stx.db.SQLite3(\"example.db\")\n",
    "print(f\"Database created: {db.db_path}\")\n",
    "\n",
    "# Check connection\n",
    "print(f\"Connected: {db.is_connected()}\")\n",
    "\n",
    "# Database summary (empty for now)\n",
    "print(\"\\nDatabase summary:\")\n",
    "print(db.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Creating Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a users table\n",
    "users_schema = {\n",
    "    \"id\": \"INTEGER PRIMARY KEY AUTOINCREMENT\",\n",
    "    \"username\": \"TEXT UNIQUE NOT NULL\",\n",
    "    \"email\": \"TEXT NOT NULL\",\n",
    "    \"age\": \"INTEGER\",\n",
    "    \"created_at\": \"TIMESTAMP DEFAULT CURRENT_TIMESTAMP\"\n",
    "}\n",
    "\n",
    "db.create_table(\"users\", users_schema)\n",
    "print(\"Created 'users' table\")\n",
    "\n",
    "# Create experiments table\n",
    "experiments_schema = {\n",
    "    \"exp_id\": \"INTEGER PRIMARY KEY AUTOINCREMENT\",\n",
    "    \"user_id\": \"INTEGER REFERENCES users(id)\",\n",
    "    \"name\": \"TEXT NOT NULL\",\n",
    "    \"parameters\": \"TEXT\",  # JSON string\n",
    "    \"results\": \"TEXT\",     # JSON string\n",
    "    \"status\": \"TEXT DEFAULT 'pending'\",\n",
    "    \"start_time\": \"TIMESTAMP\",\n",
    "    \"end_time\": \"TIMESTAMP\"\n",
    "}\n",
    "\n",
    "db.create_table(\"experiments\", experiments_schema)\n",
    "print(\"Created 'experiments' table\")\n",
    "\n",
    "# Create measurements table with BLOB data\n",
    "measurements_schema = {\n",
    "    \"id\": \"INTEGER PRIMARY KEY AUTOINCREMENT\",\n",
    "    \"exp_id\": \"INTEGER REFERENCES experiments(exp_id)\",\n",
    "    \"timestamp\": \"TIMESTAMP\",\n",
    "    \"sensor_data\": \"BLOB\",  # Binary data\n",
    "    \"value\": \"REAL\",\n",
    "    \"unit\": \"TEXT\"\n",
    "}\n",
    "\n",
    "db.create_table(\"measurements\", measurements_schema)\n",
    "print(\"Created 'measurements' table\")\n",
    "\n",
    "# Show updated summary\n",
    "print(\"\\nDatabase summary:\")\n",
    "print(db.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. CRUD Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Inserting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert single user\n",
    "user_data = {\n",
    "    \"username\": \"alice\",\n",
    "    \"email\": \"alice@example.com\",\n",
    "    \"age\": 28\n",
    "}\n",
    "user_id = db.insert(\"users\", user_data)\n",
    "print(f\"Inserted user with ID: {user_id}\")\n",
    "\n",
    "# Insert multiple users at once\n",
    "users_batch = [\n",
    "    {\"username\": \"bob\", \"email\": \"bob@example.com\", \"age\": 32},\n",
    "    {\"username\": \"charlie\", \"email\": \"charlie@example.com\", \"age\": 25},\n",
    "    {\"username\": \"diana\", \"email\": \"diana@example.com\", \"age\": 30}\n",
    "]\n",
    "\n",
    "for user in users_batch:\n",
    "    db.insert(\"users\", user)\n",
    "print(f\"\\nInserted {len(users_batch)} additional users\")\n",
    "\n",
    "# Insert experiments\n",
    "experiments = [\n",
    "    {\n",
    "        \"user_id\": 1,\n",
    "        \"name\": \"Neural Network Training\",\n",
    "        \"parameters\": json.dumps({\"lr\": 0.001, \"epochs\": 100}),\n",
    "        \"status\": \"completed\",\n",
    "        \"start_time\": datetime.now() - timedelta(hours=2),\n",
    "        \"end_time\": datetime.now() - timedelta(hours=1)\n",
    "    },\n",
    "    {\n",
    "        \"user_id\": 2,\n",
    "        \"name\": \"Data Processing\",\n",
    "        \"parameters\": json.dumps({\"batch_size\": 32, \"normalize\": True}),\n",
    "        \"status\": \"running\",\n",
    "        \"start_time\": datetime.now() - timedelta(minutes=30)\n",
    "    }\n",
    "]\n",
    "\n",
    "for exp in experiments:\n",
    "    db.insert(\"experiments\", exp)\n",
    "print(\"\\nInserted experiments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Querying Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all users\n",
    "all_users = db.select(\"users\")\n",
    "print(\"All users:\")\n",
    "for user in all_users:\n",
    "    print(f\"  {user}\")\n",
    "\n",
    "# Select with conditions\n",
    "young_users = db.select(\"users\", where=\"age < 30\")\n",
    "print(\"\\nUsers under 30:\")\n",
    "for user in young_users:\n",
    "    print(f\"  {user['username']}: age {user['age']}\")\n",
    "\n",
    "# Select specific columns\n",
    "emails = db.select(\"users\", columns=[\"username\", \"email\"])\n",
    "print(\"\\nUsernames and emails:\")\n",
    "for row in emails:\n",
    "    print(f\"  {row['username']}: {row['email']}\")\n",
    "\n",
    "# Join query\n",
    "query = \"\"\"\n",
    "    SELECT u.username, e.name as experiment, e.status\n",
    "    FROM users u\n",
    "    JOIN experiments e ON u.id = e.user_id\n",
    "\"\"\"\n",
    "results = db.execute_query(query)\n",
    "print(\"\\nUser experiments:\")\n",
    "for row in results:\n",
    "    print(f\"  {row['username']}: {row['experiment']} ({row['status']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Updating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update single row\n",
    "db.update(\"users\", {\"age\": 29}, where=\"username = 'alice'\")\n",
    "print(\"Updated Alice's age\")\n",
    "\n",
    "# Update experiment status\n",
    "db.update(\n",
    "    \"experiments\",\n",
    "    {\n",
    "        \"status\": \"completed\",\n",
    "        \"end_time\": datetime.now(),\n",
    "        \"results\": json.dumps({\"accuracy\": 0.95, \"loss\": 0.12})\n",
    "    },\n",
    "    where=\"status = 'running'\"\n",
    ")\n",
    "print(\"Updated running experiments to completed\")\n",
    "\n",
    "# Verify updates\n",
    "updated_user = db.select(\"users\", where=\"username = 'alice'\")[0]\n",
    "print(f\"\\nAlice's new age: {updated_user['age']}\")\n",
    "\n",
    "completed_exps = db.select(\"experiments\", where=\"status = 'completed'\")\n",
    "print(f\"Completed experiments: {len(completed_exps)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Working with BLOB Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sensor data as numpy array\n",
    "sensor_data = np.random.randn(100, 3)  # 100 samples, 3 channels\n",
    "print(f\"Original sensor data shape: {sensor_data.shape}\")\n",
    "\n",
    "# Convert to bytes for storage\n",
    "sensor_bytes = sensor_data.tobytes()\n",
    "\n",
    "# Store in database\n",
    "measurement = {\n",
    "    \"exp_id\": 1,\n",
    "    \"timestamp\": datetime.now(),\n",
    "    \"sensor_data\": sensor_bytes,\n",
    "    \"value\": sensor_data.mean(),\n",
    "    \"unit\": \"mV\"\n",
    "}\n",
    "\n",
    "measurement_id = db.insert(\"measurements\", measurement)\n",
    "print(f\"\\nStored measurement with ID: {measurement_id}\")\n",
    "\n",
    "# Retrieve and reconstruct\n",
    "retrieved = db.select(\"measurements\", where=f\"id = {measurement_id}\")[0]\n",
    "reconstructed = np.frombuffer(retrieved['sensor_data'], dtype=np.float64).reshape(100, 3)\n",
    "\n",
    "print(f\"\\nReconstructed shape: {reconstructed.shape}\")\n",
    "print(f\"Data integrity check: {np.array_equal(sensor_data, reconstructed)}\")\n",
    "\n",
    "# Store image data example\n",
    "image_data = np.random.randint(0, 255, (64, 64, 3), dtype=np.uint8)\n",
    "image_bytes = image_data.tobytes()\n",
    "\n",
    "# You can also store metadata alongside BLOB\n",
    "image_measurement = {\n",
    "    \"exp_id\": 1,\n",
    "    \"timestamp\": datetime.now(),\n",
    "    \"sensor_data\": image_bytes,\n",
    "    \"value\": float(image_data.shape[0]),  # Store dimensions\n",
    "    \"unit\": f\"image_{image_data.shape}\"\n",
    "}\n",
    "\n",
    "db.insert(\"measurements\", image_measurement)\n",
    "print(\"\\nStored image data as BLOB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transaction example - all or nothing\n",
    "print(\"=== Transaction Example ===\")\n",
    "\n",
    "# Successful transaction\n",
    "with db.transaction():\n",
    "    # Add new user\n",
    "    new_user_id = db.insert(\"users\", {\n",
    "        \"username\": \"eve\",\n",
    "        \"email\": \"eve@example.com\",\n",
    "        \"age\": 27\n",
    "    })\n",
    "    \n",
    "    # Add experiment for new user\n",
    "    db.insert(\"experiments\", {\n",
    "        \"user_id\": new_user_id,\n",
    "        \"name\": \"Transaction Test\",\n",
    "        \"parameters\": json.dumps({\"test\": True})\n",
    "    })\n",
    "    \n",
    "    print(\"Transaction committed successfully\")\n",
    "\n",
    "# Failed transaction (rollback)\n",
    "try:\n",
    "    with db.transaction():\n",
    "        # This will succeed\n",
    "        db.insert(\"users\", {\n",
    "            \"username\": \"frank\",\n",
    "            \"email\": \"frank@example.com\",\n",
    "            \"age\": 35\n",
    "        })\n",
    "        \n",
    "        # This will fail (duplicate username)\n",
    "        db.insert(\"users\", {\n",
    "            \"username\": \"alice\",  # Already exists!\n",
    "            \"email\": \"alice2@example.com\",\n",
    "            \"age\": 30\n",
    "        })\n",
    "except Exception as e:\n",
    "    print(f\"\\nTransaction failed and rolled back: {e}\")\n",
    "\n",
    "# Verify rollback\n",
    "frank = db.select(\"users\", where=\"username = 'frank'\")\n",
    "print(f\"Frank in database: {len(frank) > 0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Database Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect database structure and contents\n",
    "print(\"=== Database Inspection ===\")\n",
    "\n",
    "# Quick inspection\n",
    "stx.db.inspect(\"example.db\")\n",
    "\n",
    "# Detailed inspection of specific tables\n",
    "print(\"\\n=== Detailed Table Inspection ===\")\n",
    "stx.db.inspect(\"example.db\", tables=[\"users\", \"experiments\"])\n",
    "\n",
    "# Using Inspector class for programmatic access\n",
    "from scitex.db._inspect import Inspector\n",
    "\n",
    "inspector = Inspector(\"example.db\")\n",
    "\n",
    "# Get all table names\n",
    "tables = inspector.get_table_names()\n",
    "print(f\"\\nTables in database: {tables}\")\n",
    "\n",
    "# Get detailed info for a table\n",
    "users_info = inspector.get_table_info(\"users\")\n",
    "print(\"\\nUsers table structure:\")\n",
    "for col in users_info:\n",
    "    print(f\"  {col['name']:15} {col['type']:20} {'NOT NULL' if col['notnull'] else 'NULL':8} \"\n",
    "          f\"{'PRIMARY KEY' if col['pk'] else ''}\")\n",
    "\n",
    "# Get summary as DataFrame\n",
    "summary_df = inspector.get_summary()\n",
    "print(\"\\nDatabase summary as DataFrame:\")\n",
    "print(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Handling Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create table with potential duplicates\n",
    "db.create_table(\"sensor_readings\", {\n",
    "    \"id\": \"INTEGER PRIMARY KEY\",\n",
    "    \"device_id\": \"TEXT\",\n",
    "    \"timestamp\": \"TIMESTAMP\",\n",
    "    \"temperature\": \"REAL\",\n",
    "    \"humidity\": \"REAL\"\n",
    "})\n",
    "\n",
    "# Insert data with duplicates\n",
    "readings = [\n",
    "    {\"device_id\": \"SENSOR_01\", \"timestamp\": \"2024-01-01 10:00:00\", \"temperature\": 22.5, \"humidity\": 45.0},\n",
    "    {\"device_id\": \"SENSOR_01\", \"timestamp\": \"2024-01-01 10:00:00\", \"temperature\": 22.5, \"humidity\": 45.0},  # Duplicate\n",
    "    {\"device_id\": \"SENSOR_02\", \"timestamp\": \"2024-01-01 10:00:00\", \"temperature\": 23.1, \"humidity\": 48.0},\n",
    "    {\"device_id\": \"SENSOR_01\", \"timestamp\": \"2024-01-01 11:00:00\", \"temperature\": 23.0, \"humidity\": 44.0},\n",
    "    {\"device_id\": \"SENSOR_02\", \"timestamp\": \"2024-01-01 10:00:00\", \"temperature\": 23.1, \"humidity\": 48.0},  # Duplicate\n",
    "]\n",
    "\n",
    "for reading in readings:\n",
    "    db.insert(\"sensor_readings\", reading)\n",
    "\n",
    "print(f\"Inserted {len(readings)} readings (including duplicates)\")\n",
    "\n",
    "# Check for duplicates (dry run)\n",
    "print(\"\\nChecking for duplicates (dry run)...\")\n",
    "stx.db.delete_duplicates(\n",
    "    \"example.db\",\n",
    "    \"sensor_readings\",\n",
    "    columns=[\"device_id\", \"timestamp\", \"temperature\", \"humidity\"],\n",
    "    dry_run=True\n",
    ")\n",
    "\n",
    "# Actually remove duplicates\n",
    "print(\"\\nRemoving duplicates...\")\n",
    "stx.db.delete_duplicates(\n",
    "    \"example.db\",\n",
    "    \"sensor_readings\",\n",
    "    columns=[\"device_id\", \"timestamp\"],  # Consider these columns for uniqueness\n",
    "    dry_run=False\n",
    ")\n",
    "\n",
    "# Verify\n",
    "remaining = db.select(\"sensor_readings\")\n",
    "print(f\"\\nRemaining readings: {len(remaining)}\")\n",
    "for reading in remaining:\n",
    "    print(f\"  Device: {reading['device_id']}, Time: {reading['timestamp']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Indexes and Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create indexes for better query performance\n",
    "print(\"=== Index Management ===\")\n",
    "\n",
    "# Create single column index\n",
    "db.create_index(\"idx_users_email\", \"users\", [\"email\"])\n",
    "print(\"Created index on users.email\")\n",
    "\n",
    "# Create composite index\n",
    "db.create_index(\"idx_exp_user_status\", \"experiments\", [\"user_id\", \"status\"])\n",
    "print(\"Created composite index on experiments(user_id, status)\")\n",
    "\n",
    "# Create unique index\n",
    "db.create_index(\"idx_sensor_unique\", \"sensor_readings\", \n",
    "                [\"device_id\", \"timestamp\"], unique=True)\n",
    "print(\"Created unique index on sensor_readings\")\n",
    "\n",
    "# List all indexes\n",
    "indexes = db.execute_query(\n",
    "    \"SELECT name, tbl_name FROM sqlite_master WHERE type='index'\"\n",
    ")\n",
    "print(\"\\nAll indexes:\")\n",
    "for idx in indexes:\n",
    "    if not idx['name'].startswith('sqlite_'):\n",
    "        print(f\"  {idx['name']} on {idx['tbl_name']}\")\n",
    "\n",
    "# Demonstrate query performance (conceptual)\n",
    "import time\n",
    "\n",
    "# Insert more data for performance testing\n",
    "print(\"\\nInserting test data...\")\n",
    "with db.transaction():\n",
    "    for i in range(100):\n",
    "        db.insert(\"users\", {\n",
    "            \"username\": f\"user_{i:04d}\",\n",
    "            \"email\": f\"user_{i:04d}@example.com\",\n",
    "            \"age\": 20 + i % 40\n",
    "        })\n",
    "\n",
    "# Query with index\n",
    "start = time.time()\n",
    "result = db.select(\"users\", where=\"email = 'user_0050@example.com'\")\n",
    "print(f\"\\nIndexed query time: {(time.time() - start)*1000:.2f}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Import/Export Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV\n",
    "print(\"=== Import/Export Operations ===\")\n",
    "\n",
    "# Export users table to CSV\n",
    "db.export_to_csv(\"users\", \"users_export.csv\")\n",
    "print(\"Exported users table to users_export.csv\")\n",
    "\n",
    "# Read exported CSV\n",
    "df_users = pd.read_csv(\"users_export.csv\")\n",
    "print(f\"\\nExported {len(df_users)} users\")\n",
    "print(df_users.head())\n",
    "\n",
    "# Create new table for import test\n",
    "db.create_table(\"imported_data\", {\n",
    "    \"id\": \"INTEGER PRIMARY KEY\",\n",
    "    \"name\": \"TEXT\",\n",
    "    \"value\": \"REAL\",\n",
    "    \"category\": \"TEXT\"\n",
    "})\n",
    "\n",
    "# Create sample CSV\n",
    "import_data = pd.DataFrame({\n",
    "    \"name\": [\"Sample A\", \"Sample B\", \"Sample C\"],\n",
    "    \"value\": [1.23, 4.56, 7.89],\n",
    "    \"category\": [\"Type1\", \"Type2\", \"Type1\"]\n",
    "})\n",
    "import_data.to_csv(\"import_test.csv\", index=False)\n",
    "\n",
    "# Import from CSV\n",
    "db.import_from_csv(\"imported_data\", \"import_test.csv\")\n",
    "print(\"\\nImported data from CSV\")\n",
    "\n",
    "# Verify import\n",
    "imported = db.select(\"imported_data\")\n",
    "print(f\"Imported {len(imported)} rows\")\n",
    "for row in imported:\n",
    "    print(f\"  {row}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Advanced Database Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1 Backup and Restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backup database\n",
    "backup_path = \"example_backup.db\"\n",
    "db.backup(backup_path)\n",
    "print(f\"Database backed up to: {backup_path}\")\n",
    "\n",
    "# Verify backup\n",
    "backup_db = stx.db.SQLite3(backup_path)\n",
    "backup_users = backup_db.select(\"users\")\n",
    "print(f\"\\nBackup contains {len(backup_users)} users\")\n",
    "backup_db.close()\n",
    "\n",
    "# You can also work with temporary copies\n",
    "with db.temporary_copy() as temp_db:\n",
    "    # Operations on temp_db don't affect original\n",
    "    temp_db.insert(\"users\", {\n",
    "        \"username\": \"temp_user\",\n",
    "        \"email\": \"temp@example.com\",\n",
    "        \"age\": 99\n",
    "    })\n",
    "    temp_users = temp_db.select(\"users\", where=\"username = 'temp_user'\")\n",
    "    print(f\"\\nTemporary database has user: {len(temp_users) > 0}\")\n",
    "\n",
    "# Verify original is unchanged\n",
    "orig_temp_users = db.select(\"users\", where=\"username = 'temp_user'\")\n",
    "print(f\"Original database has temp user: {len(orig_temp_users) > 0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2 Database Maintenance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database maintenance operations\n",
    "print(\"=== Database Maintenance ===\")\n",
    "\n",
    "# Get database size before\n",
    "size_before = os.path.getsize(\"example.db\")\n",
    "print(f\"Database size before: {size_before:,} bytes\")\n",
    "\n",
    "# Vacuum database (reclaim space)\n",
    "db.vacuum()\n",
    "print(\"\\nVacuumed database\")\n",
    "\n",
    "# Get size after\n",
    "size_after = os.path.getsize(\"example.db\")\n",
    "print(f\"Database size after: {size_after:,} bytes\")\n",
    "print(f\"Space saved: {size_before - size_after:,} bytes\")\n",
    "\n",
    "# Analyze database (update statistics)\n",
    "db.analyze()\n",
    "print(\"\\nAnalyzed database (updated statistics)\")\n",
    "\n",
    "# Check integrity\n",
    "integrity_check = db.execute_query(\"PRAGMA integrity_check\")\n",
    "print(f\"\\nIntegrity check: {integrity_check[0]['integrity_check']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Real-World Example: Experiment Tracking System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperimentTracker:\n",
    "    \"\"\"Complete experiment tracking system using SQLite.\"\"\"\n",
    "    \n",
    "    def __init__(self, db_path=\"experiments.db\"):\n",
    "        self.db = stx.db.SQLite3(db_path)\n",
    "        self._initialize_schema()\n",
    "    \n",
    "    def _initialize_schema(self):\n",
    "        \"\"\"Create tables if they don't exist.\"\"\"\n",
    "        # Projects table\n",
    "        self.db.create_table_if_not_exists(\"projects\", {\n",
    "            \"project_id\": \"INTEGER PRIMARY KEY AUTOINCREMENT\",\n",
    "            \"name\": \"TEXT UNIQUE NOT NULL\",\n",
    "            \"description\": \"TEXT\",\n",
    "            \"created_at\": \"TIMESTAMP DEFAULT CURRENT_TIMESTAMP\"\n",
    "        })\n",
    "        \n",
    "        # Runs table\n",
    "        self.db.create_table_if_not_exists(\"runs\", {\n",
    "            \"run_id\": \"TEXT PRIMARY KEY\",  # Use unique ID\n",
    "            \"project_id\": \"INTEGER REFERENCES projects(project_id)\",\n",
    "            \"name\": \"TEXT\",\n",
    "            \"config\": \"TEXT\",  # JSON\n",
    "            \"status\": \"TEXT DEFAULT 'pending'\",\n",
    "            \"start_time\": \"TIMESTAMP\",\n",
    "            \"end_time\": \"TIMESTAMP\",\n",
    "            \"created_at\": \"TIMESTAMP DEFAULT CURRENT_TIMESTAMP\"\n",
    "        })\n",
    "        \n",
    "        # Metrics table\n",
    "        self.db.create_table_if_not_exists(\"metrics\", {\n",
    "            \"metric_id\": \"INTEGER PRIMARY KEY AUTOINCREMENT\",\n",
    "            \"run_id\": \"TEXT REFERENCES runs(run_id)\",\n",
    "            \"step\": \"INTEGER\",\n",
    "            \"metric_name\": \"TEXT\",\n",
    "            \"value\": \"REAL\",\n",
    "            \"timestamp\": \"TIMESTAMP DEFAULT CURRENT_TIMESTAMP\"\n",
    "        })\n",
    "        \n",
    "        # Create indexes\n",
    "        self.db.create_index(\"idx_runs_project\", \"runs\", [\"project_id\"])\n",
    "        self.db.create_index(\"idx_metrics_run\", \"metrics\", [\"run_id\", \"metric_name\"])\n",
    "    \n",
    "    def create_project(self, name, description=\"\"):\n",
    "        \"\"\"Create a new project.\"\"\"\n",
    "        return self.db.insert(\"projects\", {\n",
    "            \"name\": name,\n",
    "            \"description\": description\n",
    "        })\n",
    "    \n",
    "    def start_run(self, project_name, run_name, config):\n",
    "        \"\"\"Start a new experiment run.\"\"\"\n",
    "        # Get project ID\n",
    "        project = self.db.select(\"projects\", where=f\"name = '{project_name}'\")[0]\n",
    "        \n",
    "        # Generate unique run ID\n",
    "        run_id = stx.repro.gen_id()\n",
    "        \n",
    "        # Insert run\n",
    "        self.db.insert(\"runs\", {\n",
    "            \"run_id\": run_id,\n",
    "            \"project_id\": project['project_id'],\n",
    "            \"name\": run_name,\n",
    "            \"config\": json.dumps(config),\n",
    "            \"status\": \"running\",\n",
    "            \"start_time\": datetime.now()\n",
    "        })\n",
    "        \n",
    "        return run_id\n",
    "    \n",
    "    def log_metric(self, run_id, metric_name, value, step):\n",
    "        \"\"\"Log a metric value.\"\"\"\n",
    "        self.db.insert(\"metrics\", {\n",
    "            \"run_id\": run_id,\n",
    "            \"step\": step,\n",
    "            \"metric_name\": metric_name,\n",
    "            \"value\": value\n",
    "        })\n",
    "    \n",
    "    def end_run(self, run_id, status=\"completed\"):\n",
    "        \"\"\"End an experiment run.\"\"\"\n",
    "        self.db.update(\"runs\", {\n",
    "            \"status\": status,\n",
    "            \"end_time\": datetime.now()\n",
    "        }, where=f\"run_id = '{run_id}'\")\n",
    "    \n",
    "    def get_run_metrics(self, run_id):\n",
    "        \"\"\"Get all metrics for a run.\"\"\"\n",
    "        query = \"\"\"\n",
    "            SELECT metric_name, step, value\n",
    "            FROM metrics\n",
    "            WHERE run_id = ?\n",
    "            ORDER BY metric_name, step\n",
    "        \"\"\"\n",
    "        return self.db.execute_query(query, (run_id,))\n",
    "    \n",
    "    def compare_runs(self, run_ids, metric_name):\n",
    "        \"\"\"Compare a specific metric across multiple runs.\"\"\"\n",
    "        placeholders = ','.join(['?' for _ in run_ids])\n",
    "        query = f\"\"\"\n",
    "            SELECT r.run_id, r.name, m.step, m.value\n",
    "            FROM runs r\n",
    "            JOIN metrics m ON r.run_id = m.run_id\n",
    "            WHERE r.run_id IN ({placeholders})\n",
    "            AND m.metric_name = ?\n",
    "            ORDER BY r.run_id, m.step\n",
    "        \"\"\"\n",
    "        return self.db.execute_query(query, (*run_ids, metric_name))\n",
    "\n",
    "# Use the tracker\n",
    "tracker = ExperimentTracker()\n",
    "\n",
    "# Create project\n",
    "project_id = tracker.create_project(\n",
    "    \"Deep Learning Research\",\n",
    "    \"Experiments with neural architectures\"\n",
    ")\n",
    "print(f\"Created project with ID: {project_id}\")\n",
    "\n",
    "# Run experiments\n",
    "run_ids = []\n",
    "for lr in [0.001, 0.01, 0.1]:\n",
    "    config = {\n",
    "        \"learning_rate\": lr,\n",
    "        \"batch_size\": 32,\n",
    "        \"optimizer\": \"adam\"\n",
    "    }\n",
    "    \n",
    "    run_id = tracker.start_run(\n",
    "        \"Deep Learning Research\",\n",
    "        f\"LR_{lr}_experiment\",\n",
    "        config\n",
    "    )\n",
    "    run_ids.append(run_id)\n",
    "    \n",
    "    # Simulate training\n",
    "    for step in range(10):\n",
    "        # Log metrics\n",
    "        loss = 1.0 / (1 + step) * (1 + lr)  # Simulated loss\n",
    "        accuracy = 1 - loss + 0.5\n",
    "        \n",
    "        tracker.log_metric(run_id, \"loss\", loss, step)\n",
    "        tracker.log_metric(run_id, \"accuracy\", accuracy, step)\n",
    "    \n",
    "    tracker.end_run(run_id)\n",
    "    print(f\"Completed run: {run_id[:20]}... (LR={lr})\")\n",
    "\n",
    "# Compare runs\n",
    "print(\"\\nComparing loss across runs:\")\n",
    "comparison = tracker.compare_runs(run_ids, \"loss\")\n",
    "df_comparison = pd.DataFrame(comparison)\n",
    "print(df_comparison.pivot(index='step', columns='name', values='value').round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close database connections\n",
    "db.close()\n",
    "tracker.db.close()\n",
    "\n",
    "# Return to original directory and cleanup\n",
    "os.chdir(\"..\")\n",
    "shutil.rmtree(temp_dir)\n",
    "print(f\"Cleaned up temporary directory: {temp_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Best Practices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Takeaways\n",
    "\n",
    "1. **Easy Database Management**: Simple API for SQLite and PostgreSQL\n",
    "2. **Comprehensive Features**: CRUD, transactions, BLOB support, indexing\n",
    "3. **Data Integrity**: Built-in duplicate detection and removal\n",
    "4. **Inspection Tools**: Analyze database structure and contents\n",
    "5. **Import/Export**: Easy data exchange with CSV files\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "1. **Use Transactions**:\n",
    "   ```python\n",
    "   with db.transaction():\n",
    "       # Multiple operations\n",
    "       # All succeed or all fail\n",
    "   ```\n",
    "\n",
    "2. **Create Indexes**:\n",
    "   ```python\n",
    "   db.create_index(\"idx_name\", \"table\", [\"column1\", \"column2\"])\n",
    "   ```\n",
    "\n",
    "3. **Handle BLOBs Properly**:\n",
    "   ```python\n",
    "   # Store: numpy_array.tobytes()\n",
    "   # Retrieve: np.frombuffer(blob_data, dtype=original_dtype)\n",
    "   ```\n",
    "\n",
    "4. **Regular Maintenance**:\n",
    "   ```python\n",
    "   db.vacuum()  # Reclaim space\n",
    "   db.analyze()  # Update statistics\n",
    "   ```\n",
    "\n",
    "5. **Use Inspection Tools**:\n",
    "   ```python\n",
    "   stx.db.inspect(\"database.db\")  # Quick overview\n",
    "   stx.db.delete_duplicates(...)  # Clean data\n",
    "   ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nDatabase module tutorial completed!\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Design your database schema carefully\")\n",
    "print(\"2. Use indexes for frequently queried columns\")\n",
    "print(\"3. Implement proper error handling with transactions\")\n",
    "print(\"4. Regular backups and maintenance\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}