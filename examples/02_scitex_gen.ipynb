{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SciTeX Gen Module - Core Generation Utilities\n",
    "\n",
    "This comprehensive notebook demonstrates the SciTeX gen module capabilities, covering core generation utilities and helper functions.\n",
    "\n",
    "## Features Covered\n",
    "\n",
    "### Core Utilities\n",
    "* Data normalization and transformation\n",
    "* Array dimension handling\n",
    "* Type checking and validation\n",
    "* Shell command execution\n",
    "\n",
    "### Development Tools\n",
    "* Configuration printing\n",
    "* Module inspection\n",
    "* Environment checking\n",
    "* Caching mechanisms\n",
    "\n",
    "### File Operations\n",
    "* Symlink management\n",
    "* Text processing\n",
    "* XML/JSON conversion\n",
    "* Path utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "import scitex\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "# Set up example data directory\n",
    "data_dir = Path(\"./gen_examples\")\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"SciTeX Gen Module Tutorial - Ready to begin!\")\n",
    "print(f\"Available gen functions: {len(scitex.gen.__all__)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data Normalization and Transformation\n",
    "\n",
    "### 1.1 Normalization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample data for normalization\n",
    "sample_data = np.random.randn(1000) * 10 + 50  # Mean=50, std=10\n",
    "sample_2d = np.random.randn(100, 20) * 5 + 25   # 2D array\n",
    "\n",
    "print(f\"Original data stats:\")\n",
    "print(f\"  Mean: {np.mean(sample_data):.2f}\")\n",
    "print(f\"  Std: {np.std(sample_data):.2f}\")\n",
    "print(f\"  Min: {np.min(sample_data):.2f}\")\n",
    "print(f\"  Max: {np.max(sample_data):.2f}\")\n",
    "\n",
    "# Normalize to 0-1 range\n",
    "normalized_01 = scitex.gen.to_01(sample_data)\n",
    "print(f\"\\nNormalized to [0,1]:\")\n",
    "print(f\"  Min: {np.min(normalized_01):.2f}\")\n",
    "print(f\"  Max: {np.max(normalized_01):.2f}\")\n",
    "\n",
    "# Z-score normalization\n",
    "z_normalized = scitex.gen.to_z(sample_data)\n",
    "print(f\"\\nZ-score normalized:\")\n",
    "print(f\"  Mean: {np.mean(z_normalized):.2f}\")\n",
    "print(f\"  Std: {np.std(z_normalized):.2f}\")\n",
    "\n",
    "# Remove bias (center at zero)\n",
    "unbiased = scitex.gen.unbias(sample_data)\n",
    "print(f\"\\nUnbiased (centered):\")\n",
    "print(f\"  Mean: {np.mean(unbiased):.2f}\")\n",
    "print(f\"  Original mean: {np.mean(sample_data):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentile-based clipping\n",
    "outlier_data = np.concatenate([sample_data, [200, -50, 150, -30]])  # Add outliers\n",
    "print(f\"Data with outliers:\")\n",
    "print(f\"  Min: {np.min(outlier_data):.2f}\")\n",
    "print(f\"  Max: {np.max(outlier_data):.2f}\")\n",
    "\n",
    "# Clip to 5th and 95th percentiles\n",
    "clipped = scitex.gen.clip_perc(outlier_data, low=5, high=95)\n",
    "print(f\"\\nClipped to 5th-95th percentiles:\")\n",
    "print(f\"  Min: {np.min(clipped):.2f}\")\n",
    "print(f\"  Max: {np.max(clipped):.2f}\")\n",
    "\n",
    "# Visualize transformations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "fig.suptitle('Data Transformation Examples')\n",
    "\n",
    "axes[0, 0].hist(sample_data, bins=50, alpha=0.7, color='blue')\n",
    "axes[0, 0].set_title('Original Data')\n",
    "axes[0, 0].set_xlabel('Value')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "\n",
    "axes[0, 1].hist(normalized_01, bins=50, alpha=0.7, color='green')\n",
    "axes[0, 1].set_title('Normalized to [0,1]')\n",
    "axes[0, 1].set_xlabel('Value')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "\n",
    "axes[1, 0].hist(z_normalized, bins=50, alpha=0.7, color='red')\n",
    "axes[1, 0].set_title('Z-score Normalized')\n",
    "axes[1, 0].set_xlabel('Value')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "\n",
    "axes[1, 1].hist(clipped, bins=50, alpha=0.7, color='orange')\n",
    "axes[1, 1].set_title('Percentile Clipped')\n",
    "axes[1, 1].set_xlabel('Value')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Ranking and Ordering Functions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Create test data for ranking\ntest_values = np.array([85, 92, 78, 95, 88, 91, 73, 96, 82, 89])\nprint(f\"Test values: {test_values}\")\n\n# Convert to ranks\nranks = scitex.gen.to_rank(test_values)\nprint(f\"Ranks: {ranks}\")\n\n# Show correspondence\nranked_data = pd.DataFrame({\n    'Value': test_values,\n    'Rank': ranks\n})\nranked_data = ranked_data.sort_values('Rank')\nprint(f\"\\nRanked data:\")\nprint(ranked_data)\n\n# Even/odd utilities - demonstrate with individual numbers\nprint(f\"\\nEven/Odd Conversion Examples:\")\ntest_numbers = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\nfor num in test_numbers:\n    even = scitex.gen.to_even(num)\n    odd = scitex.gen.to_odd(num)\n    print(f\"  {num} -> even: {even}, odd: {odd}\")\n\n# If you need to apply to arrays, use list comprehension or numpy.vectorize\nnumbers = np.arange(1, 21)\neven_numbers = np.array([scitex.gen.to_even(n) for n in numbers])\nodd_numbers = np.array([scitex.gen.to_odd(n) for n in numbers])\n\nprint(f\"\\nOriginal numbers: {numbers}\")\nprint(f\"To even: {even_numbers}\")\nprint(f\"To odd: {odd_numbers}\")\n\n# Visualize ranking\nfig, axes = plt.subplots(1, 2, figsize=(12, 4))\n\n# Original vs ranked\naxes[0].bar(range(len(test_values)), test_values, alpha=0.7, color='blue')\naxes[0].set_title('Original Values')\naxes[0].set_xlabel('Index')\naxes[0].set_ylabel('Value')\n\naxes[1].bar(range(len(ranks)), ranks, alpha=0.7, color='red')\naxes[1].set_title('Ranks')\naxes[1].set_xlabel('Index')\naxes[1].set_ylabel('Rank')\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Array Dimension Handling\n",
    "\n",
    "### 2.1 DimHandler Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test arrays with different dimensions\n",
    "array_1d = np.random.randn(100)\n",
    "array_2d = np.random.randn(50, 20)\n",
    "array_3d = np.random.randn(10, 8, 5)\n",
    "array_4d = np.random.randn(5, 4, 3, 2)\n",
    "\n",
    "arrays = {\n",
    "    '1D': array_1d,\n",
    "    '2D': array_2d,\n",
    "    '3D': array_3d,\n",
    "    '4D': array_4d\n",
    "}\n",
    "\n",
    "print(\"Array dimensions:\")\n",
    "for name, arr in arrays.items():\n",
    "    print(f\"  {name}: {arr.shape}\")\n",
    "\n",
    "# Use DimHandler for dimension management\n",
    "dim_handler = scitex.gen.DimHandler()\n",
    "\n",
    "# Analyze each array\n",
    "for name, arr in arrays.items():\n",
    "    print(f\"\\n{name} Array Analysis:\")\n",
    "    print(f\"  Shape: {arr.shape}\")\n",
    "    print(f\"  Dimensions: {arr.ndim}\")\n",
    "    print(f\"  Total size: {arr.size}\")\n",
    "    print(f\"  Data type: {arr.dtype}\")\n",
    "    print(f\"  Memory usage: {arr.nbytes} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Transpose operations\nmatrix = np.random.randn(5, 3)\nprint(f\"Original matrix shape: {matrix.shape}\")\nprint(f\"Original matrix:\\n{matrix}\")\n\n# Use numpy transpose (scitex.gen.transpose is for dimension reordering with named dims)\ntransposed = matrix.T  # or np.transpose(matrix)\nprint(f\"\\nTransposed matrix shape: {transposed.shape}\")\nprint(f\"Transposed matrix:\\n{transposed}\")\n\n# Verify transpose property\ndouble_transposed = transposed.T\nprint(f\"\\nDouble transpose equals original: {np.allclose(matrix, double_transposed)}\")\n\n# Example of scitex.gen.transpose with named dimensions\n# This function is useful when you have meaningful dimension names\nprint(\"\\n\\nExample of scitex.gen.transpose with named dimensions:\")\n# Create a 3D tensor with dimensions: batch, time, features\ntensor_3d = np.random.randn(2, 10, 5)  # 2 batches, 10 time steps, 5 features\nsrc_dims = np.array(['batch', 'time', 'features'])\ntgt_dims = np.array(['time', 'batch', 'features'])  # Swap batch and time\n\ntransposed_3d = scitex.gen.transpose(tensor_3d, src_dims, tgt_dims)\nprint(f\"Original shape (batch, time, features): {tensor_3d.shape}\")\nprint(f\"Transposed shape (time, batch, features): {transposed_3d.shape}\")\n\n# Visualize transpose operation\nfig, axes = plt.subplots(1, 2, figsize=(10, 4))\n\nim1 = axes[0].imshow(matrix, cmap='viridis', aspect='auto')\naxes[0].set_title(f'Original Matrix {matrix.shape}')\naxes[0].set_xlabel('Columns')\naxes[0].set_ylabel('Rows')\nplt.colorbar(im1, ax=axes[0])\n\nim2 = axes[1].imshow(transposed, cmap='viridis', aspect='auto')\naxes[1].set_title(f'Transposed Matrix {transposed.shape}')\naxes[1].set_xlabel('Columns')\naxes[1].set_ylabel('Rows')\nplt.colorbar(im2, ax=axes[1])\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Type Checking and Variable Information\n",
    "\n",
    "### 3.1 Variable Information System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create various data types for testing\n",
    "test_variables = {\n",
    "    'integer': 42,\n",
    "    'float': 3.14159,\n",
    "    'string': \"Hello, SciTeX!\",\n",
    "    'list': [1, 2, 3, 4, 5],\n",
    "    'dict': {'a': 1, 'b': 2, 'c': 3},\n",
    "    'numpy_array': np.array([1, 2, 3, 4, 5]),\n",
    "    'pandas_series': pd.Series([1, 2, 3, 4, 5]),\n",
    "    'pandas_dataframe': pd.DataFrame({'x': [1, 2, 3], 'y': [4, 5, 6]}),\n",
    "    'complex': 3 + 4j,\n",
    "    'boolean': True,\n",
    "    'none_type': None\n",
    "}\n",
    "\n",
    "print(\"Variable Information Analysis:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for name, var in test_variables.items():\n",
    "    try:\n",
    "        var_details = scitex.gen.var_info(var)\n",
    "        print(f\"\\n{name.upper()}:\")\n",
    "        print(f\"  Value: {var}\")\n",
    "        print(f\"  Type: {type(var).__name__}\")\n",
    "        if hasattr(var, 'shape'):\n",
    "            print(f\"  Shape: {var.shape}\")\n",
    "        if hasattr(var, '__len__') and not isinstance(var, str):\n",
    "            print(f\"  Length: {len(var)}\")\n",
    "        if hasattr(var, 'dtype'):\n",
    "            print(f\"  Data type: {var.dtype}\")\n",
    "        if hasattr(var, 'nbytes'):\n",
    "            print(f\"  Memory: {var.nbytes} bytes\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n{name.upper()}: Error getting info - {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 ArrayLike Type Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test ArrayLike type checking\n",
    "array_like_candidates = [\n",
    "    np.array([1, 2, 3]),\n",
    "    [1, 2, 3],\n",
    "    (1, 2, 3),\n",
    "    pd.Series([1, 2, 3]),\n",
    "    pd.DataFrame({'x': [1, 2, 3]}),\n",
    "    \"not array-like\",\n",
    "    42,\n",
    "    {'a': 1, 'b': 2}\n",
    "]\n",
    "\n",
    "print(\"ArrayLike Type Checking:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "for i, candidate in enumerate(array_like_candidates):\n",
    "    try:\n",
    "        # Check if it's array-like\n",
    "        is_array_like = isinstance(candidate, (np.ndarray, list, tuple, pd.Series, pd.DataFrame))\n",
    "        print(f\"\\nCandidate {i + 1}: {type(candidate).__name__}\")\n",
    "        print(f\"  Value: {candidate}\")\n",
    "        print(f\"  Is array-like: {is_array_like}\")\n",
    "        \n",
    "        if is_array_like:\n",
    "            if hasattr(candidate, 'shape'):\n",
    "                print(f\"  Shape: {candidate.shape}\")\n",
    "            elif hasattr(candidate, '__len__'):\n",
    "                print(f\"  Length: {len(candidate)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Environment and Configuration\n",
    "\n",
    "### 4.1 Environment Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check environment\n",
    "print(\"Environment Detection:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Check if running in IPython/Jupyter\n",
    "is_ipython = scitex.gen.is_ipython()\n",
    "is_script = scitex.gen.is_script()\n",
    "\n",
    "print(f\"Running in IPython/Jupyter: {is_ipython}\")\n",
    "print(f\"Running as script: {is_script}\")\n",
    "\n",
    "# Host checking\n",
    "try:\n",
    "    hostname = scitex.gen.check_host()\n",
    "    print(f\"\\nHost information:\")\n",
    "    print(f\"  Hostname: {hostname}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nCould not get host info: {e}\")\n",
    "\n",
    "# List installed packages\n",
    "print(\"\\nInstalled packages (first 10):\")\n",
    "try:\n",
    "    packages = scitex.gen.list_packages()\n",
    "    if packages:\n",
    "        for pkg in packages[:10]:\n",
    "            print(f\"  {pkg}\")\n",
    "        if len(packages) > 10:\n",
    "            print(f\"  ... and {len(packages) - 10} more packages\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not list packages: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Configuration Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print configuration\n",
    "print(\"System Configuration:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "try:\n",
    "    scitex.gen.print_config()\n",
    "except Exception as e:\n",
    "    print(f\"Could not print config: {e}\")\n",
    "\n",
    "# Module inspection\n",
    "print(\"\\nModule Inspection - SciTeX Gen:\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "try:\n",
    "    gen_info = scitex.gen.inspect_module(scitex.gen)\n",
    "    print(f\"Module: {scitex.gen.__name__}\")\n",
    "    print(f\"Available functions: {len(scitex.gen.__all__)}\")\n",
    "    print(f\"First 10 functions: {scitex.gen.__all__[:10]}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not inspect module: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: File Operations and Utilities\n",
    "\n",
    "### 5.1 Symlink Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test files for symlink operations\n",
    "test_file = data_dir / \"test_original.txt\"\n",
    "test_content = \"This is a test file for symlink operations.\\nLine 2\\nLine 3\"\n",
    "\n",
    "# Write test file\n",
    "with open(test_file, 'w') as f:\n",
    "    f.write(test_content)\n",
    "\n",
    "print(f\"Created test file: {test_file}\")\n",
    "print(f\"File exists: {test_file.exists()}\")\n",
    "print(f\"File size: {test_file.stat().st_size} bytes\")\n",
    "\n",
    "# Create symlink\n",
    "symlink_path = data_dir / \"test_symlink.txt\"\n",
    "try:\n",
    "    scitex.gen.symlink(test_file, symlink_path)\n",
    "    print(f\"\\nCreated symlink: {symlink_path}\")\n",
    "    print(f\"Symlink exists: {symlink_path.exists()}\")\n",
    "    print(f\"Is symlink: {symlink_path.is_symlink()}\")\n",
    "    \n",
    "    # Read through symlink\n",
    "    with open(symlink_path, 'r') as f:\n",
    "        symlink_content = f.read()\n",
    "    \n",
    "    print(f\"Content matches: {symlink_content == test_content}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Symlink operation failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Text Processing Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Title case conversion\n",
    "test_titles = [\n",
    "    \"hello world\",\n",
    "    \"THE QUICK BROWN FOX\",\n",
    "    \"machine learning algorithms\",\n",
    "    \"data science and AI\",\n",
    "    \"python programming\"\n",
    "]\n",
    "\n",
    "print(\"Title Case Conversion:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "for title in test_titles:\n",
    "    try:\n",
    "        title_cased = scitex.gen.title_case(title)\n",
    "        print(f\"'{title}' -> '{title_cased}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"'{title}' -> Error: {e}\")\n",
    "\n",
    "# Title to path conversion\n",
    "print(\"\\nTitle to Path Conversion:\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "for title in test_titles:\n",
    "    try:\n",
    "        path_name = scitex.gen.title2path(title)\n",
    "        print(f\"'{title}' -> '{path_name}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"'{title}' -> Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Caching Mechanisms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate caching with simple computation\n",
    "import time\n",
    "\n",
    "def simple_computation(n):\n",
    "    \"\"\"Simulate a computation that takes some time.\"\"\"\n",
    "    print(f\"Computing sum of squares up to {n}...\")\n",
    "    time.sleep(0.1)  # Simulate computation time (reduced from 0.5)\n",
    "    \n",
    "    result = sum(i**2 for i in range(n))\n",
    "    return result\n",
    "\n",
    "# Use caching\n",
    "cached_computation = scitex.gen.cache(simple_computation)\n",
    "\n",
    "print(\"Caching Demonstration:\")\n",
    "print(\"=\" * 25)\n",
    "\n",
    "# First call - will compute\n",
    "start_time = time.time()\n",
    "result1 = cached_computation(1000)\n",
    "first_time = time.time() - start_time\n",
    "print(f\"First call result: {result1}\")\n",
    "print(f\"First call time: {first_time:.2f} seconds\")\n",
    "\n",
    "# Second call - should be cached\n",
    "start_time = time.time()\n",
    "result2 = cached_computation(1000)\n",
    "second_time = time.time() - start_time\n",
    "print(f\"\nSecond call result: {result2}\")\n",
    "print(f\"Second call time: {second_time:.4f} seconds\")\n",
    "if second_time > 0:\n",
    "    print(f\"Speedup: {first_time/second_time:.1f}x\")\n",
    "else:\n",
    "    print(\"Speedup: Instant (cached)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Advanced Features\n",
    "\n",
    "### 6.1 Shell Command Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute shell commands safely\n",
    "print(\"Shell Command Execution:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Simple commands\n",
    "commands = [\n",
    "    \"echo 'Hello from shell'\",\n",
    "    \"date\",\n",
    "    \"pwd\",\n",
    "    \"ls -la | head -5\"\n",
    "]\n",
    "\n",
    "for cmd in commands:\n",
    "    try:\n",
    "        print(f\"\\nExecuting: {cmd}\")\n",
    "        result = scitex.gen.run_shellcommand(cmd)\n",
    "        print(f\"Result: {result}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing '{cmd}': {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 XML and Data Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XML to dictionary conversion\n",
    "sample_xml = '''\n",
    "<experiment>\n",
    "    <name>Test Experiment</name>\n",
    "    <parameters>\n",
    "        <param name=\"alpha\">0.05</param>\n",
    "        <param name=\"beta\">0.1</param>\n",
    "        <param name=\"samples\">1000</param>\n",
    "    </parameters>\n",
    "    <results>\n",
    "        <accuracy>0.95</accuracy>\n",
    "        <precision>0.92</precision>\n",
    "        <recall>0.88</recall>\n",
    "    </results>\n",
    "</experiment>\n",
    "'''\n",
    "\n",
    "print(\"XML to Dictionary Conversion:\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "try:\n",
    "    # Convert XML to dictionary\n",
    "    xml_dict = scitex.gen.xml2dict(sample_xml)\n",
    "    print(f\"Converted XML to dictionary:\")\n",
    "    print(xml_dict)\n",
    "    \n",
    "    # Pretty print the structure\n",
    "    import json\n",
    "    print(f\"\\nFormatted structure:\")\n",
    "    print(json.dumps(xml_dict, indent=2))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"XML conversion failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Time Stamping and Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TimeStamper for tracking operations\n",
    "print(\"TimeStamper Demonstration:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "try:\n",
    "    # Create timestamp handler\n",
    "    timestamper = scitex.gen.TimeStamper()\n",
    "    \n",
    "    # Perform some operations with timestamps\n",
    "    operations = [\n",
    "        \"Data loading\",\n",
    "        \"Preprocessing\",\n",
    "        \"Model training\",\n",
    "        \"Evaluation\",\n",
    "        \"Results saving\"\n",
    "    ]\n",
    "    \n",
    "    for i, operation in enumerate(operations):\n",
    "        print(f\"\\n{i+1}. {operation}\")\n",
    "        time.sleep(0.01)  # Simulate operation time\n",
    "        \n",
    "        # Add timestamp (if method exists)\n",
    "        if hasattr(timestamper, 'add_timestamp'):\n",
    "            timestamper.add_timestamp(operation)\n",
    "            print(f\"   Timestamp added for: {operation}\")\n",
    "        else:\n",
    "            # Manual timestamp\n",
    "            current_time = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            print(f\"   Completed at: {current_time}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"TimeStamper error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Output Redirection and Logging\n",
    "\n",
    "### 7.1 Tee Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tee functionality - output to multiple destinations\n",
    "print(\"Tee Functionality:\")\n",
    "print(\"=\" * 20)\n",
    "\n",
    "log_file = data_dir / \"output.log\"\n",
    "\n",
    "try:\n",
    "    # Create Tee object\n",
    "    tee = scitex.gen.Tee(str(log_file))\n",
    "    \n",
    "    # Redirect output\n",
    "    original_stdout = sys.stdout\n",
    "    sys.stdout = tee\n",
    "    \n",
    "    # Print some messages\n",
    "    print(\"This message goes to both console and file\")\n",
    "    print(\"Line 2 of output\")\n",
    "    print(\"Line 3 with timestamp:\", time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    \n",
    "    # Restore original stdout\n",
    "    sys.stdout = original_stdout\n",
    "    tee.close()\n",
    "    \n",
    "    print(\"\\nOutput redirection complete.\")\n",
    "    \n",
    "    # Read back the log file\n",
    "    if log_file.exists():\n",
    "        with open(log_file, 'r') as f:\n",
    "            log_content = f.read()\n",
    "        print(f\"\\nLog file contents:\")\n",
    "        print(log_content)\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Tee operation failed: {e}\")\n",
    "    # Ensure stdout is restored\n",
    "    sys.stdout = original_stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Best Practices\n",
    "\n",
    "This tutorial demonstrated the comprehensive capabilities of the SciTeX gen module:\n",
    "\n",
    "### Key Features Covered:\n",
    "1. **Data Normalization**: `to_01()`, `to_z()`, `unbias()`, `clip_perc()`\n",
    "2. **Array Operations**: `DimHandler`, `transpose()`, dimension management\n",
    "3. **Type Checking**: `var_info()`, `ArrayLike` validation\n",
    "4. **Environment Detection**: `is_ipython()`, `is_script()`, `check_host()`\n",
    "5. **File Operations**: `symlink()`, path utilities\n",
    "6. **Text Processing**: `title_case()`, `title2path()`\n",
    "7. **Caching**: `cache()` decorator for expensive operations\n",
    "8. **System Integration**: Shell commands, configuration management\n",
    "9. **Data Conversion**: `xml2dict()` for structured data\n",
    "10. **Output Management**: `Tee` for logging and redirection\n",
    "\n",
    "### Best Practices:\n",
    "- Use **normalization functions** for consistent data preprocessing\n",
    "- Apply **caching** for expensive computations\n",
    "- Use **environment detection** for conditional execution\n",
    "- Implement **proper error handling** for robust applications\n",
    "- Use **symlinks** for efficient file management\n",
    "- Apply **type checking** for data validation\n",
    "- Use **Tee** for comprehensive logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "import shutil\n",
    "\n",
    "cleanup = input(\"Clean up example files? (y/n): \").lower().startswith('y')\n",
    "if cleanup:\n",
    "    shutil.rmtree(data_dir)\n",
    "    print(\"\u2713 Example files cleaned up\")\n",
    "else:\n",
    "    print(f\"Example files preserved in: {data_dir}\")\n",
    "    print(f\"Files created: {len(list(data_dir.rglob('*')))}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}