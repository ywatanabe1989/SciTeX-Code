{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SciTeX Neural Network Module Tutorial\n",
    "\n",
    "This notebook demonstrates the specialized neural network layers and components in SciTeX, particularly focused on signal processing and neuroscience applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scitex as stx\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Signal Processing Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Frequency Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample signal with multiple frequency components\n",
    "fs = 1000  # Sampling frequency\n",
    "t = np.linspace(0, 1, fs)\n",
    "signal_clean = np.sin(2 * np.pi * 10 * t)  # 10 Hz signal\n",
    "noise = 0.5 * np.sin(2 * np.pi * 100 * t)  # 100 Hz noise\n",
    "signal_noisy = signal_clean + noise\n",
    "\n",
    "# Convert to torch tensor\n",
    "x = torch.tensor(signal_noisy, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "print(f\"Input shape: {x.shape}  # [batch, channels, time]\")\n",
    "\n",
    "# Apply different filters\n",
    "# Low-pass filter to remove high frequency noise\n",
    "lowpass = stx.nn.LowPassFilter(cutoff_freq=30, sample_rate=fs, filter_length=51)\n",
    "x_lowpass = lowpass(x)\n",
    "\n",
    "# Band-pass filter for specific frequency range\n",
    "bandpass = stx.nn.BandPassFilter(low_freq=8, high_freq=12, sample_rate=fs, filter_length=51)\n",
    "x_bandpass = bandpass(x)\n",
    "\n",
    "# High-pass filter\n",
    "highpass = stx.nn.HighPassFilter(cutoff_freq=50, sample_rate=fs, filter_length=51)\n",
    "x_highpass = highpass(x)\n",
    "\n",
    "# Plot results\n",
    "fig, axes = plt.subplots(4, 1, figsize=(12, 10))\n",
    "\n",
    "axes[0].plot(t, signal_noisy)\n",
    "axes[0].set_title('Original Noisy Signal (10 Hz + 100 Hz)')\n",
    "axes[0].set_ylabel('Amplitude')\n",
    "\n",
    "axes[1].plot(t, x_lowpass.squeeze().numpy())\n",
    "axes[1].set_title('Low-Pass Filtered (< 30 Hz)')\n",
    "axes[1].set_ylabel('Amplitude')\n",
    "\n",
    "axes[2].plot(t, x_bandpass.squeeze().numpy())\n",
    "axes[2].set_title('Band-Pass Filtered (8-12 Hz)')\n",
    "axes[2].set_ylabel('Amplitude')\n",
    "\n",
    "axes[3].plot(t, x_highpass.squeeze().numpy())\n",
    "axes[3].set_title('High-Pass Filtered (> 50 Hz)')\n",
    "axes[3].set_ylabel('Amplitude')\n",
    "axes[3].set_xlabel('Time (s)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Spectral Analysis Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate multi-channel signal\n",
    "n_channels = 4\n",
    "n_samples = 2000\n",
    "fs = 500\n",
    "t = np.linspace(0, n_samples/fs, n_samples)\n",
    "\n",
    "# Create signals with different frequency content\n",
    "signals = []\n",
    "for i in range(n_channels):\n",
    "    freq = 10 + i * 5  # 10, 15, 20, 25 Hz\n",
    "    signal_ch = np.sin(2 * np.pi * freq * t) + 0.3 * np.random.randn(n_samples)\n",
    "    signals.append(signal_ch)\n",
    "\n",
    "x = torch.tensor(np.array(signals), dtype=torch.float32).unsqueeze(0)\n",
    "print(f\"Multi-channel input shape: {x.shape}  # [batch, channels, time]\")\n",
    "\n",
    "# Compute spectrogram\n",
    "spectrogram_layer = stx.nn.Spectrogram(\n",
    "    n_fft=256,\n",
    "    hop_length=64,\n",
    "    power=2.0,\n",
    "    normalized=True\n",
    ")\n",
    "spec = spectrogram_layer(x)\n",
    "print(f\"Spectrogram shape: {spec.shape}  # [batch, channels, freq, time]\")\n",
    "\n",
    "# Compute PSD (Power Spectral Density)\n",
    "psd_layer = stx.nn.PSD(n_fft=512, fs=fs)\n",
    "psd = psd_layer(x)\n",
    "print(f\"PSD shape: {psd.shape}  # [batch, channels, freq_bins]\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "# Plot spectrograms for first two channels\n",
    "for i in range(2):\n",
    "    im = axes[0, i].imshow(spec[0, i].numpy(), aspect='auto', origin='lower',\n",
    "                          extent=[0, t[-1], 0, fs/2])\n",
    "    axes[0, i].set_title(f'Channel {i+1} Spectrogram')\n",
    "    axes[0, i].set_xlabel('Time (s)')\n",
    "    axes[0, i].set_ylabel('Frequency (Hz)')\n",
    "    plt.colorbar(im, ax=axes[0, i])\n",
    "\n",
    "# Plot PSD for all channels\n",
    "freqs = np.fft.rfftfreq(512, 1/fs)\n",
    "for i in range(n_channels):\n",
    "    axes[1, 0].semilogy(freqs, psd[0, i].numpy(), label=f'Ch {i+1} ({10+i*5} Hz)')\n",
    "axes[1, 0].set_xlabel('Frequency (Hz)')\n",
    "axes[1, 0].set_ylabel('Power')\n",
    "axes[1, 0].set_title('Power Spectral Density')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True)\n",
    "axes[1, 0].set_xlim([0, 50])\n",
    "\n",
    "# Hide unused subplot\n",
    "axes[1, 1].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Advanced Signal Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Hilbert Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate amplitude-modulated signal\n",
    "fs = 1000\n",
    "t = np.linspace(0, 2, 2*fs)\n",
    "carrier_freq = 50  # Hz\n",
    "modulation_freq = 5  # Hz\n",
    "\n",
    "# Create AM signal\n",
    "carrier = np.sin(2 * np.pi * carrier_freq * t)\n",
    "modulation = 1 + 0.5 * np.sin(2 * np.pi * modulation_freq * t)\n",
    "am_signal = modulation * carrier\n",
    "\n",
    "x = torch.tensor(am_signal, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "# Apply Hilbert transform\n",
    "hilbert_layer = stx.nn.Hilbert()\n",
    "analytic_signal = hilbert_layer(x)\n",
    "\n",
    "# Extract amplitude envelope and instantaneous phase\n",
    "amplitude = torch.abs(analytic_signal)\n",
    "phase = torch.angle(analytic_signal)\n",
    "\n",
    "# Plot results\n",
    "fig, axes = plt.subplots(3, 1, figsize=(12, 8))\n",
    "\n",
    "axes[0].plot(t[:500], am_signal[:500])\n",
    "axes[0].set_title('Original AM Signal')\n",
    "axes[0].set_ylabel('Amplitude')\n",
    "\n",
    "axes[1].plot(t[:500], amplitude.squeeze().numpy()[:500], 'r', linewidth=2)\n",
    "axes[1].plot(t[:500], am_signal[:500], 'b', alpha=0.5)\n",
    "axes[1].set_title('Amplitude Envelope (red) vs Original Signal (blue)')\n",
    "axes[1].set_ylabel('Amplitude')\n",
    "\n",
    "axes[2].plot(t[:500], phase.squeeze().numpy()[:500])\n",
    "axes[2].set_title('Instantaneous Phase')\n",
    "axes[2].set_ylabel('Phase (radians)')\n",
    "axes[2].set_xlabel('Time (s)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Phase-Amplitude Coupling (PAC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic signal with PAC\n",
    "fs = 1000\n",
    "duration = 5\n",
    "t = np.linspace(0, duration, duration * fs)\n",
    "\n",
    "# Low frequency phase signal (theta: 6 Hz)\n",
    "phase_freq = 6\n",
    "phase_signal = np.sin(2 * np.pi * phase_freq * t)\n",
    "\n",
    "# High frequency amplitude signal (gamma: 60 Hz)\n",
    "amp_freq = 60\n",
    "# Modulate gamma amplitude by theta phase\n",
    "modulation = 1 + 0.5 * (phase_signal + 1) / 2  # Normalize to 0.5-1.5\n",
    "amp_signal = modulation * np.sin(2 * np.pi * amp_freq * t)\n",
    "\n",
    "# Combine signals\n",
    "combined_signal = phase_signal + 0.3 * amp_signal + 0.1 * np.random.randn(len(t))\n",
    "\n",
    "# Convert to tensor\n",
    "x = torch.tensor(combined_signal, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "# Compute PAC\n",
    "pac_layer = stx.nn.PAC(\n",
    "    phase_freq_band=(4, 8),    # Theta band\n",
    "    amp_freq_band=(50, 70),    # Gamma band\n",
    "    fs=fs,\n",
    "    method='tort'              # Tort's modulation index\n",
    ")\n",
    "\n",
    "pac_value = pac_layer(x)\n",
    "print(f\"PAC Modulation Index: {pac_value.item():.4f}\")\n",
    "\n",
    "# Visualize PAC\n",
    "fig, axes = plt.subplots(3, 1, figsize=(12, 8))\n",
    "\n",
    "# Time window for visualization\n",
    "t_win = slice(0, 1000)  # First second\n",
    "\n",
    "# Original signal\n",
    "axes[0].plot(t[t_win], combined_signal[t_win])\n",
    "axes[0].set_title('Combined Signal with PAC')\n",
    "axes[0].set_ylabel('Amplitude')\n",
    "\n",
    "# Phase signal (filtered)\n",
    "phase_filter = stx.nn.BandPassFilter(4, 8, fs, filter_length=101)\n",
    "phase_filtered = phase_filter(x).squeeze().numpy()\n",
    "axes[1].plot(t[t_win], phase_filtered[t_win], 'b')\n",
    "axes[1].set_title('Theta Phase (4-8 Hz)')\n",
    "axes[1].set_ylabel('Amplitude')\n",
    "\n",
    "# Amplitude signal (filtered)\n",
    "amp_filter = stx.nn.BandPassFilter(50, 70, fs, filter_length=101)\n",
    "amp_filtered = amp_filter(x).squeeze().numpy()\n",
    "amp_envelope = np.abs(signal.hilbert(amp_filtered))\n",
    "axes[2].plot(t[t_win], amp_filtered[t_win], 'r', alpha=0.5)\n",
    "axes[2].plot(t[t_win], amp_envelope[t_win], 'r', linewidth=2)\n",
    "axes[2].set_title('Gamma Amplitude (50-70 Hz) and Envelope')\n",
    "axes[2].set_ylabel('Amplitude')\n",
    "axes[2].set_xlabel('Time (s)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Wavelet Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate signal with time-varying frequency\n",
    "fs = 1000\n",
    "t = np.linspace(0, 2, 2*fs)\n",
    "\n",
    "# Chirp signal (frequency increases over time)\n",
    "f0, f1 = 10, 50  # Start and end frequencies\n",
    "chirp = signal.chirp(t, f0, t[-1], f1, method='linear')\n",
    "\n",
    "# Add transient burst\n",
    "burst_time = 1.0\n",
    "burst_idx = int(burst_time * fs)\n",
    "burst = np.zeros_like(t)\n",
    "burst[burst_idx:burst_idx+50] = 0.5 * np.sin(2 * np.pi * 30 * t[:50])\n",
    "\n",
    "test_signal = chirp + burst + 0.1 * np.random.randn(len(t))\n",
    "\n",
    "x = torch.tensor(test_signal, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "# Apply wavelet transform\n",
    "wavelet_layer = stx.nn.Wavelet(\n",
    "    wavelet='morlet',\n",
    "    scales=np.logspace(0, 2, 50),  # Scales from 1 to 100\n",
    "    fs=fs\n",
    ")\n",
    "\n",
    "cwt_coeffs = wavelet_layer(x)\n",
    "print(f\"CWT shape: {cwt_coeffs.shape}  # [batch, channels, scales, time]\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 8))\n",
    "\n",
    "# Original signal\n",
    "axes[0].plot(t, test_signal)\n",
    "axes[0].set_title('Signal with Linear Chirp and Transient Burst')\n",
    "axes[0].set_ylabel('Amplitude')\n",
    "axes[0].axvline(burst_time, color='r', linestyle='--', alpha=0.5, label='Burst')\n",
    "axes[0].legend()\n",
    "\n",
    "# Wavelet scalogram\n",
    "scales = wavelet_layer.scales.numpy()\n",
    "frequencies = fs / (2 * scales)  # Approximate frequency for each scale\n",
    "\n",
    "im = axes[1].imshow(\n",
    "    np.abs(cwt_coeffs[0, 0].numpy()),\n",
    "    aspect='auto',\n",
    "    extent=[t[0], t[-1], frequencies[-1], frequencies[0]],\n",
    "    cmap='hot',\n",
    "    interpolation='bilinear'\n",
    ")\n",
    "axes[1].set_title('Continuous Wavelet Transform (Scalogram)')\n",
    "axes[1].set_xlabel('Time (s)')\n",
    "axes[1].set_ylabel('Frequency (Hz)')\n",
    "axes[1].set_ylim([5, 80])\n",
    "plt.colorbar(im, ax=axes[1], label='Magnitude')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Specialized Neural Network Architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 ResNet1D for Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ResNet1D for time series classification\n",
    "resnet1d = stx.nn.ResNet1D(\n",
    "    in_channels=8,      # Number of input channels\n",
    "    num_classes=4,      # Number of output classes\n",
    "    block_sizes=[2, 2, 2, 2],  # Number of blocks in each layer\n",
    "    hidden_sizes=[64, 128, 256, 512],  # Hidden dimensions\n",
    "    kernel_size=3\n",
    ")\n",
    "\n",
    "# Example input\n",
    "batch_size = 16\n",
    "n_channels = 8\n",
    "seq_length = 1000\n",
    "x = torch.randn(batch_size, n_channels, seq_length)\n",
    "\n",
    "# Forward pass\n",
    "output = resnet1d(x)\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"\\nModel architecture:\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in resnet1d.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 BNet - Brain Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BNet configuration for EEG/MEG data\n",
    "config = stx.nn.BNet_config(\n",
    "    n_channels=64,          # EEG channels\n",
    "    n_timepoints=1000,      # Time points\n",
    "    n_classes=5,            # Classification classes\n",
    "    conv_channels=[32, 64, 128],\n",
    "    kernel_sizes=[5, 5, 3],\n",
    "    dropout_rate=0.5\n",
    ")\n",
    "\n",
    "# Create BNet model\n",
    "bnet = stx.nn.BNet(config)\n",
    "\n",
    "# Example EEG-like input\n",
    "x = torch.randn(8, 64, 1000)  # [batch, channels, time]\n",
    "output = bnet(x)\n",
    "\n",
    "print(f\"BNet Configuration:\")\n",
    "print(f\"  Input: {config.n_channels} channels × {config.n_timepoints} timepoints\")\n",
    "print(f\"  Output: {config.n_classes} classes\")\n",
    "print(f\"  Architecture: {config.conv_channels}\")\n",
    "print(f\"\\nOutput shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Attention Mechanisms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spatial Attention for multi-channel data\n",
    "spatial_attention = stx.nn.SpatialAttention(\n",
    "    n_channels=32,\n",
    "    reduction_ratio=4\n",
    ")\n",
    "\n",
    "# Create multi-channel time series data\n",
    "batch_size = 8\n",
    "n_channels = 32\n",
    "seq_length = 500\n",
    "x = torch.randn(batch_size, n_channels, seq_length)\n",
    "\n",
    "# Apply spatial attention\n",
    "x_attended, attention_weights = spatial_attention(x)\n",
    "\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "print(f\"Output shape: {x_attended.shape}\")\n",
    "print(f\"Attention weights shape: {attention_weights.shape}\")\n",
    "\n",
    "# Visualize attention weights for first sample\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "im = ax.imshow(attention_weights[0].detach().numpy().reshape(1, -1), \n",
    "               aspect='auto', cmap='hot')\n",
    "ax.set_xlabel('Channel')\n",
    "ax.set_title('Spatial Attention Weights')\n",
    "ax.set_yticks([])\n",
    "plt.colorbar(im, ax=ax)\n",
    "plt.show()\n",
    "\n",
    "# Show which channels get most attention\n",
    "avg_attention = attention_weights.mean(dim=0).squeeze()\n",
    "top_channels = torch.argsort(avg_attention, descending=True)[:5]\n",
    "print(f\"\\nTop 5 attended channels: {top_channels.tolist()}\")\n",
    "print(f\"Their attention weights: {avg_attention[top_channels].tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Data Augmentation Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate various augmentation layers\n",
    "\n",
    "# 1. Channel Dropout\n",
    "channel_dropout = stx.nn.DropoutChannels(p=0.2)\n",
    "\n",
    "# 2. Channel Gain Changer\n",
    "gain_changer = stx.nn.ChannelGainChanger(gain_range=(0.8, 1.2))\n",
    "\n",
    "# 3. Frequency Gain Changer\n",
    "freq_gain = stx.nn.FreqGainChanger(\n",
    "    freq_bands=[(8, 12), (13, 30), (30, 100)],  # Alpha, Beta, Gamma\n",
    "    gain_range=(0.9, 1.1),\n",
    "    fs=1000\n",
    ")\n",
    "\n",
    "# 4. Channel Swapping\n",
    "channel_swap = stx.nn.SwapChannels(p=0.3)\n",
    "\n",
    "# Create sample data\n",
    "x = torch.randn(4, 8, 1000)  # [batch, channels, time]\n",
    "\n",
    "# Apply augmentations\n",
    "print(\"Data Augmentation Examples:\")\n",
    "print(f\"Original shape: {x.shape}\")\n",
    "\n",
    "# Apply channel dropout\n",
    "x_dropped = channel_dropout(x)\n",
    "dropped_channels = (x_dropped[0].sum(dim=1) == 0).sum().item()\n",
    "print(f\"\\nChannel Dropout: {dropped_channels} channels dropped\")\n",
    "\n",
    "# Apply gain changes\n",
    "x_gain = gain_changer(x)\n",
    "gain_factors = (x_gain[0] / (x[0] + 1e-8)).mean(dim=1)\n",
    "print(f\"\\nChannel gains applied: {gain_factors[:4].tolist()}\")\n",
    "\n",
    "# Apply frequency-specific gain\n",
    "x_freq = freq_gain(x)\n",
    "print(f\"\\nFrequency gain applied to alpha, beta, gamma bands\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Custom Layer Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Create a custom layer for computing running statistics\n",
    "class RunningStatsLayer(nn.Module):\n",
    "    \"\"\"Computes running mean and std over time dimension.\"\"\"\n",
    "    \n",
    "    def __init__(self, window_size=100, dim=-1):\n",
    "        super().__init__()\n",
    "        self.window_size = window_size\n",
    "        self.dim = dim\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: [batch, channels, time]\n",
    "        if self.dim == -1:\n",
    "            # Unfold to create sliding windows\n",
    "            x_unfold = x.unfold(dimension=2, size=self.window_size, step=1)\n",
    "            # x_unfold shape: [batch, channels, n_windows, window_size]\n",
    "            \n",
    "            # Compute statistics\n",
    "            mean = x_unfold.mean(dim=-1)\n",
    "            std = x_unfold.std(dim=-1)\n",
    "            \n",
    "            # Combine mean and std as new channels\n",
    "            output = torch.cat([mean, std], dim=1)\n",
    "            return output\n",
    "        \n",
    "# Use the custom layer\n",
    "stats_layer = RunningStatsLayer(window_size=50)\n",
    "x = torch.randn(4, 3, 200)  # [batch, channels, time]\n",
    "\n",
    "output = stats_layer(x)\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "print(f\"Output shape: {output.shape}  # [batch, 2*channels, time-window+1]\")\n",
    "print(\"\\nOutput contains running mean and std for each channel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Building Complete Neural Network Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a complete signal processing neural network\n",
    "class SignalProcessingNet(nn.Module):\n",
    "    \"\"\"Complete pipeline for EEG/biosignal classification.\"\"\"\n",
    "    \n",
    "    def __init__(self, n_channels=32, n_classes=4, fs=250):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Preprocessing layers\n",
    "        self.bandpass = stx.nn.BandPassFilter(1, 40, fs, filter_length=51)\n",
    "        self.spatial_filter = stx.nn.SpatialAttention(n_channels, reduction_ratio=4)\n",
    "        \n",
    "        # Feature extraction\n",
    "        self.conv1 = nn.Conv1d(n_channels, 64, kernel_size=25, stride=2)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.activation = nn.ELU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        # Temporal attention\n",
    "        self.conv2 = nn.Conv1d(64, 128, kernel_size=15, stride=2)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        \n",
    "        # Global pooling and classification\n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.classifier = nn.Linear(128, n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Input shape: [batch, channels, time]\n",
    "        \n",
    "        # Preprocessing\n",
    "        x = self.bandpass(x)\n",
    "        x, attention = self.spatial_filter(x)\n",
    "        \n",
    "        # Feature extraction\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        # Classification\n",
    "        x = self.global_pool(x).squeeze(-1)\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x, attention\n",
    "\n",
    "# Create and test the network\n",
    "model = SignalProcessingNet(n_channels=32, n_classes=4, fs=250)\n",
    "x = torch.randn(8, 32, 1000)  # 4 seconds at 250 Hz\n",
    "\n",
    "output, attention = model(x)\n",
    "print(f\"Model output shape: {output.shape}\")\n",
    "print(f\"Attention weights shape: {attention.shape}\")\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# Visualize model predictions\n",
    "with torch.no_grad():\n",
    "    probs = torch.softmax(output, dim=1)\n",
    "    predictions = torch.argmax(probs, dim=1)\n",
    "    \n",
    "print(f\"\\nPredictions: {predictions.tolist()}\")\n",
    "print(f\"Confidence: {probs.max(dim=1)[0].tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary and Best Practices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Takeaways\n",
    "\n",
    "1. **Signal Processing Integration**: SciTeX seamlessly integrates signal processing with deep learning\n",
    "2. **Domain-Specific Layers**: Specialized layers for neuroscience and biosignal analysis\n",
    "3. **Differentiable Operations**: All operations are differentiable for end-to-end training\n",
    "4. **Modular Design**: Easy to combine layers for custom architectures\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "1. **Preprocessing in the Network**:\n",
    "   ```python\n",
    "   # Include preprocessing as network layers\n",
    "   self.preprocess = nn.Sequential(\n",
    "       stx.nn.BandPassFilter(1, 40, fs),\n",
    "       stx.nn.ChannelGainChanger(gain_range=(0.9, 1.1))\n",
    "   )\n",
    "   ```\n",
    "\n",
    "2. **Attention for Channel Selection**:\n",
    "   ```python\n",
    "   # Use spatial attention to learn important channels\n",
    "   self.attention = stx.nn.SpatialAttention(n_channels)\n",
    "   ```\n",
    "\n",
    "3. **Multi-Scale Analysis**:\n",
    "   ```python\n",
    "   # Combine different frequency bands\n",
    "   self.multi_scale = nn.ModuleList([\n",
    "       stx.nn.BandPassFilter(low, high, fs)\n",
    "       for low, high in [(1,4), (4,8), (8,12), (13,30)]\n",
    "   ])\n",
    "   ```\n",
    "\n",
    "4. **Data Augmentation**:\n",
    "   ```python\n",
    "   # Apply augmentation during training only\n",
    "   if self.training:\n",
    "       x = self.channel_dropout(x)\n",
    "       x = self.freq_gain_changer(x)\n",
    "   ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nNeural Network module tutorial completed!\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Experiment with different filter parameters for your signals\")\n",
    "print(\"2. Combine multiple layers for complex architectures\")\n",
    "print(\"3. Use PAC and other neuroscience-specific analyses\")\n",
    "print(\"4. Integrate with PyTorch training loops for end-to-end learning\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}